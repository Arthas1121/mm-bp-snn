

*******************CONFIG*******************
Is Gradient Checking : 0
Allow Dynamic Threshold : 0
Has Boost Weight Train: 1
Use Effect Ratio      : 1
Use Optimizer         : adam
lambda                : 0.000000
beta                  : 0.000000
weight limit          : 8.000000
batch Size            : 1
channels              : 1
crop                  : -1
scale                 : 12.000000
rotation              : 12.000000
distortion            : 3.400000
imageShow             : 0
HORIZONTAL            : 0
Test_Epoch            : 200
White Noise           : 0.000000
Spike end time        : 400
Train data path       : NULL
Test data path        : NULL
Train samples         : 60000
Test samples          : 10000
Train samples per class : -1
Test samples per class  : -1


********data spiking Layer********
NAME          : data
INPUT_NEURONS : 784


********ConvSpiking layer********
NAME          : conv1
INPUT         : data
KERNEL_SIZE   : 5
KERNEL_AMOUNT : 15
PADDING       : 0
initW         : 0.500000
VTH           : 5.000000
T_REFRAC      : 2
TAU_M         : 64.000000
TAU_S         : 8.000000
refWeightPath : NULL
refOuputTrainPath  : NULL
refOutputTestPath  : NULL


*****Pooling Spiking layer*****
NAME          : pooling1
INPUT         : conv1
size          : 2
skip          : 2
VTH           : 2.000000
T_REFRAC      : 2
TAU_M         : 64.000000
TAU_S         : 8.000000
refOuputTrainPath  : NULL
refOutputTestPath  : NULL


********ConvSpiking layer********
NAME          : conv2
INPUT         : pooling1
KERNEL_SIZE   : 5
KERNEL_AMOUNT : 40
PADDING       : 0
initW         : 0.500000
VTH           : 12.000000
T_REFRAC      : 2
TAU_M         : 64.000000
TAU_S         : 8.000000
refWeightPath : NULL
refOuputTrainPath  : NULL
refOutputTestPath  : NULL


*****Pooling Spiking layer*****
NAME          : pooling2
INPUT         : conv2
size          : 2
skip          : 2
VTH           : 4.000000
T_REFRAC      : 2
TAU_M         : 64.000000
TAU_S         : 8.000000
refOuputTrainPath  : NULL
refOutputTestPath  : NULL


********SPIKING Layer********
NAME               : hidden_0
NUM_NEURONS        : 300
INPUT              : pooling2
VTH                : 10.000000
T_REFRAC           : 2
TAU_M              : 64.000000
TAU_S              : 8.000000
initW              : 1.000000
weightConnect      : 0
initType           : Bernoulli
weightPath         : NULL
lweightPath        : NULL
laterialType       : NULL
reservoirDim       : NULL
localInbStrength   : 0.000000
UNDESIRED_LEVEL    : 0.000000
DESIRED_LEVEL      : 0.000000
MARGIN             : 0.000000
refWeightPath      : NULL
refLWeightPath     : NULL
refOuputTrainPath  : NULL
refOutputTestPath  : NULL
ADD_BIAS           : 0
BIAS_FREQ          : 100000


********SPIKING Layer********
NAME               : output
NUM_NEURONS        : 10
INPUT              : hidden_0
VTH                : 10.000000
T_REFRAC           : 2
TAU_M              : 64.000000
TAU_S              : 8.000000
initW              : 1.000000
weightConnect      : 0
initType           : Bernoulli
weightPath         : NULL
lweightPath        : NULL
laterialType       : LOCAL_INHIBITION
reservoirDim       : NULL
localInbStrength   : 1.000000
UNDESIRED_LEVEL    : 5.000000
DESIRED_LEVEL      : 35.000000
MARGIN             : 5.000000
refWeightPath      : NULL
refLWeightPath     : NULL
refOuputTrainPath  : NULL
refOutputTestPath  : NULL
ADD_BIAS           : 0
BIAS_FREQ          : 100000





******************layer nexts start********************
layer            data:conv1 
layer           conv1:pooling1 
layer        pooling1:conv2 
layer           conv2:pooling2 
layer        pooling2:hidden_0 
layer        hidden_0:output 
layer          output:


******************layer nexts end********************
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 6, 3, 0, 0;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
output:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
time spent on test : time=63.253s
correct is 980
epoch=0 time=1099.653s cost=99.698997 Momentum=0.900000 lrate=0.00100000
train performance: 95.09%
===================weight value================
conv1:
weight:-1.050590, -0.843763, -0.836516;
bias  :0.000000 0.000000
conv2:
weight:-0.502023, -0.497813, -0.630641;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.586885, 0.778106, 0.165761;
bias  :0.000000
===================test Result================
test 95.74%/95.74%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 5, 16, 10, 16, 35;
conv2:
fire count: 0, 0, 0, 0, 0, 12, 15, 6, 0, 0;
pooling2:
fire count: 0, 0, 3, 2, 0, 0, 0, 0, 10, 5;
hidden_0:
fire count: 0, 3, 28, 0, 0, 17, 16, 0, 1, 9;
output:
fire count: 0, 0, 1, 1, 0, 0, 32, 0, 2, 0;
epoch=1 time=1023.816s cost=52.089783 Momentum=0.900000 lrate=0.00070711
train performance: 97.76%
===================weight value================
conv1:
weight:-0.924802, -0.780807, -0.705447;
bias  :0.000000 0.000000
conv2:
weight:-0.083435, -0.127126, -0.410738;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, -0.000000;
bias  :0.000000
output:
weight:-0.564423, 0.742352, 0.095805;
bias  :0.000000
===================test Result================
test 97.34%/97.34%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 14, 35, 41, 48, 56;
conv2:
fire count: 0, 0, 0, 0, 0, 3, 7, 1, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 7, 3;
hidden_0:
fire count: 0, 5, 26, 0, 0, 25, 14, 0, 0, 11;
output:
fire count: 0, 0, 4, 1, 1, 1, 29, 0, 1, 0;
epoch=2 time=1028.682s cost=41.385517 Momentum=0.900000 lrate=0.00057735
train performance: 98.12%
===================weight value================
conv1:
weight:-0.883544, -0.806779, -0.702573;
bias  :0.000000 0.000000
conv2:
weight:-0.339070, -0.141404, -0.312606;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.546086, 0.688860, 0.099562;
bias  :0.000000
===================test Result================
test 97.40%/97.40%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 2, 1, 11, 39;
conv2:
fire count: 0, 0, 0, 0, 0, 11, 19, 9, 0, 0;
pooling2:
fire count: 0, 0, 2, 3, 0, 0, 0, 0, 3, 6;
hidden_0:
fire count: 0, 2, 22, 0, 0, 19, 12, 2, 1, 9;
output:
fire count: 1, 1, 1, 2, 1, 0, 27, 0, 2, 0;
epoch=3 time=1043.347s cost=47.996399 Momentum=0.900000 lrate=0.00050000
train performance: 97.69%
===================weight value================
conv1:
weight:-1.051260, -0.863847, -0.677035;
bias  :0.000000 0.000000
conv2:
weight:-0.376368, 0.052128, -0.268306;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, -0.000023, 0.000074;
bias  :0.000000
output:
weight:-0.546086, 0.550873, 0.170827;
bias  :0.000000
===================test Result================
test 95.64%/97.40%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 1, 27;
conv2:
fire count: 0, 0, 0, 0, 0, 4, 10, 3, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 2, 1;
hidden_0:
fire count: 0, 11, 25, 0, 0, 32, 15, 0, 1, 2;
output:
fire count: 0, 1, 1, 1, 1, 2, 31, 1, 1, 0;
epoch=4 time=1093.425s cost=32.222332 Momentum=0.900000 lrate=0.00044721
train performance: 98.50%
===================weight value================
conv1:
weight:-1.052207, -0.802040, -0.427266;
bias  :0.000000 0.000000
conv2:
weight:-0.553516, 0.050657, -0.187595;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.560291, 0.538972, 0.085764;
bias  :0.000000
===================test Result================
test 96.42%/97.40%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 24;
conv2:
fire count: 0, 0, 0, 0, 0, 11, 19, 9, 0, 0;
pooling2:
fire count: 0, 0, 1, 3, 0, 0, 0, 0, 3, 4;
hidden_0:
fire count: 0, 1, 25, 0, 0, 24, 17, 0, 1, 0;
output:
fire count: 1, 1, 1, 1, 2, 1, 28, 0, 1, 1;
epoch=5 time=1143.673s cost=29.886150 Momentum=0.900000 lrate=0.00040825
train performance: 98.66%
===================weight value================
conv1:
weight:-1.180232, -0.968060, -0.589423;
bias  :0.000000 0.000000
conv2:
weight:-0.372548, 0.027527, -0.337162;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, -0.000000, 0.000003;
bias  :0.000000
output:
weight:-0.560291, 0.551578, -0.020928;
bias  :0.000000
===================test Result================
test 98.62%/98.62%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 4, 34;
conv2:
fire count: 0, 0, 0, 0, 0, 3, 15, 6, 0, 0;
pooling2:
fire count: 0, 0, 0, 1, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 13, 7, 0, 25, 14, 0, 0, 0;
output:
fire count: 0, 0, 2, 1, 2, 1, 32, 0, 1, 0;
epoch=6 time=1136.389s cost=28.501883 Momentum=0.900000 lrate=0.00037796
train performance: 98.67%
===================weight value================
conv1:
weight:-1.310692, -0.990989, -0.464654;
bias  :0.000000 0.000000
conv2:
weight:-0.421062, 0.073400, -0.292458;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, 0.000000, -0.000000;
bias  :0.000000
output:
weight:-0.559902, 0.562333, -0.032303;
bias  :0.000000
===================test Result================
test 97.92%/98.62%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 24;
conv2:
fire count: 0, 0, 0, 0, 0, 10, 16, 6, 0, 0;
pooling2:
fire count: 0, 0, 0, 2, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 22, 3, 0, 25, 16, 0, 1, 0;
output:
fire count: 0, 1, 1, 1, 3, 1, 32, 1, 1, 1;
epoch=7 time=1101.513s cost=25.478350 Momentum=0.900000 lrate=0.00035355
train performance: 98.79%
===================weight value================
conv1:
weight:-1.254121, -1.003399, -0.547453;
bias  :0.000000 0.000000
conv2:
weight:-0.543559, -0.101152, -0.499511;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000002;
bias  :0.000000
output:
weight:-0.559902, 0.551308, -0.020391;
bias  :0.000000
===================test Result================
test 97.76%/98.62%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 1, 30;
conv2:
fire count: 0, 0, 0, 0, 0, 3, 11, 2, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 22, 3, 0, 31, 14, 1, 0, 0;
output:
fire count: 0, 1, 3, 1, 4, 1, 28, 0, 1, 1;
epoch=8 time=1151.072s cost=21.286917 Momentum=0.900000 lrate=0.00033333
train performance: 99.05%
===================weight value================
conv1:
weight:-1.348487, -1.060354, -0.551684;
bias  :0.000000 0.000000
conv2:
weight:-0.523766, -0.106448, -0.524494;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.559902, 0.559785, -0.022567;
bias  :0.000000
===================test Result================
test 98.51%/98.62%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 2, 33;
conv2:
fire count: 0, 0, 0, 0, 0, 8, 15, 5, 0, 0;
pooling2:
fire count: 0, 0, 0, 1, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 22, 8, 0, 33, 15, 5, 0, 0;
output:
fire count: 0, 1, 2, 1, 2, 1, 30, 1, 1, 1;
epoch=9 time=1174.940s cost=25.757017 Momentum=0.900000 lrate=0.00031623
train performance: 98.78%
===================weight value================
conv1:
weight:-1.430395, -1.103843, -0.491809;
bias  :0.000000 0.000000
conv2:
weight:-0.608091, 0.058973, -0.428423;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.559902, 0.560393, -0.072620;
bias  :0.000000
===================test Result================
test 98.24%/98.62%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 1, 32;
conv2:
fire count: 0, 0, 0, 0, 0, 11, 18, 9, 0, 0;
pooling2:
fire count: 0, 0, 4, 3, 0, 0, 0, 0, 7, 5;
hidden_0:
fire count: 0, 0, 29, 1, 0, 30, 23, 0, 1, 0;
output:
fire count: 0, 1, 1, 1, 1, 1, 31, 1, 2, 1;
epoch=10 time=1266.865s cost=20.384634 Momentum=0.900000 lrate=0.00030151
train performance: 98.96%
===================weight value================
conv1:
weight:-1.582430, -1.296620, -0.616380;
bias  :0.000000 0.000000
conv2:
weight:-0.507495, 0.191376, -0.336709;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, -0.000000, -0.000000;
bias  :0.000000
output:
weight:-0.569480, 0.428443, -0.061461;
bias  :0.000000
===================test Result================
test 98.20%/98.62%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 2, 32;
conv2:
fire count: 0, 0, 0, 0, 0, 6, 13, 5, 0, 0;
pooling2:
fire count: 0, 0, 1, 0, 0, 0, 0, 0, 6, 1;
hidden_0:
fire count: 0, 0, 32, 6, 0, 24, 21, 0, 0, 0;
output:
fire count: 0, 2, 1, 1, 2, 1, 30, 1, 1, 0;
epoch=11 time=1392.617s cost=31.623301 Momentum=0.900000 lrate=0.00028868
train performance: 98.42%
===================weight value================
conv1:
weight:-1.732115, -1.285512, -0.701836;
bias  :0.000000 0.000000
conv2:
weight:-0.440517, 0.303666, -0.272084;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.559293, 0.285909, 0.007597;
bias  :0.000000
===================test Result================
test 98.70%/98.70%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 21;
conv2:
fire count: 0, 0, 0, 0, 0, 7, 18, 10, 0, 0;
pooling2:
fire count: 0, 0, 2, 3, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 27, 17, 0, 35, 12, 0, 0, 1;
output:
fire count: 0, 1, 1, 0, 2, 1, 28, 1, 1, 0;
epoch=12 time=1341.788s cost=21.341650 Momentum=0.900000 lrate=0.00027735
train performance: 98.97%
===================weight value================
conv1:
weight:-1.724057, -1.180146, -0.682986;
bias  :0.000000 0.000000
conv2:
weight:-0.435492, 0.268555, -0.270234;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, 0.000000, -0.000000;
bias  :0.000000
output:
weight:-0.559293, 0.323619, 0.000342;
bias  :0.000000
===================test Result================
test 98.96%/98.96%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 22;
conv2:
fire count: 0, 0, 0, 0, 0, 6, 18, 12, 0, 0;
pooling2:
fire count: 0, 0, 3, 4, 0, 0, 0, 0, 2, 1;
hidden_0:
fire count: 0, 0, 25, 16, 0, 41, 15, 0, 0, 0;
output:
fire count: 0, 1, 1, 1, 2, 2, 29, 1, 1, 1;
epoch=13 time=1328.441s cost=19.656584 Momentum=0.900000 lrate=0.00026726
train performance: 99.05%
===================weight value================
conv1:
weight:-1.675898, -1.100930, -0.694446;
bias  :0.000000 0.000000
conv2:
weight:-0.471247, 0.240517, -0.342042;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.559293, 0.270070, 0.048679;
bias  :0.000000
===================test Result================
test 99.04%/99.04%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 19;
conv2:
fire count: 0, 0, 0, 0, 0, 3, 16, 9, 0, 0;
pooling2:
fire count: 0, 0, 0, 2, 0, 0, 0, 0, 3, 0;
hidden_0:
fire count: 0, 0, 30, 19, 0, 45, 14, 0, 0, 0;
output:
fire count: 0, 1, 2, 1, 2, 2, 28, 1, 1, 1;
epoch=14 time=1353.986s cost=21.049950 Momentum=0.900000 lrate=0.00025820
train performance: 98.98%
===================weight value================
conv1:
weight:-1.628439, -1.013457, -0.705715;
bias  :0.000000 0.000000
conv2:
weight:-0.505034, 0.228228, -0.290660;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.559293, 0.210221, 0.026934;
bias  :0.000000
===================test Result================
test 98.19%/99.04%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 23;
conv2:
fire count: 0, 0, 0, 0, 0, 4, 14, 8, 0, 0;
pooling2:
fire count: 0, 0, 1, 1, 0, 0, 0, 0, 3, 1;
hidden_0:
fire count: 0, 0, 33, 24, 0, 47, 8, 0, 0, 0;
output:
fire count: 1, 1, 1, 1, 2, 2, 28, 1, 1, 1;
epoch=15 time=1354.009s cost=18.883533 Momentum=0.900000 lrate=0.00025000
train performance: 99.14%
===================weight value================
conv1:
weight:-1.600632, -0.951304, -0.686785;
bias  :0.000000 0.000000
conv2:
weight:-0.462233, 0.180574, -0.381369;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, -0.000000, -0.000000;
bias  :0.000000
output:
weight:-0.559293, 0.213391, 0.014081;
bias  :0.000000
===================test Result================
test 98.79%/99.04%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 24;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 12, 7, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 3, 0;
hidden_0:
fire count: 0, 0, 24, 21, 0, 50, 14, 0, 1, 0;
output:
fire count: 1, 1, 2, 1, 1, 3, 32, 2, 2, 1;
epoch=16 time=1380.862s cost=19.311001 Momentum=0.900000 lrate=0.00024254
train performance: 99.06%
===================weight value================
conv1:
weight:-1.586425, -0.908206, -0.645085;
bias  :0.000000 0.000000
conv2:
weight:-0.475354, 0.094856, -0.424565;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, -0.000000, -0.000000;
bias  :0.000000
output:
weight:-0.559293, 0.260437, 0.002059;
bias  :0.000000
===================test Result================
test 98.03%/99.04%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 27;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 10, 5, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 6, 1;
hidden_0:
fire count: 0, 0, 22, 18, 0, 48, 11, 0, 0, 0;
output:
fire count: 1, 1, 2, 2, 2, 3, 28, 1, 1, 1;
epoch=17 time=1477.290s cost=19.073366 Momentum=0.900000 lrate=0.00023570
train performance: 99.01%
===================weight value================
conv1:
weight:-1.671601, -0.926456, -0.590936;
bias  :0.000000 0.000000
conv2:
weight:-0.488638, 0.047404, -0.343320;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.559293, 0.252913, -0.005477;
bias  :0.000000
===================test Result================
test 99.10%/99.10%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 24;
conv2:
fire count: 0, 0, 0, 0, 0, 3, 14, 8, 0, 0;
pooling2:
fire count: 0, 0, 0, 2, 0, 0, 0, 0, 3, 1;
hidden_0:
fire count: 0, 0, 25, 12, 0, 53, 15, 0, 1, 0;
output:
fire count: 1, 1, 1, 2, 2, 2, 33, 1, 1, 1;
epoch=18 time=1461.901s cost=21.347816 Momentum=0.900000 lrate=0.00022942
train performance: 99.00%
===================weight value================
conv1:
weight:-1.622599, -0.900545, -0.524569;
bias  :0.000000 0.000000
conv2:
weight:-0.584241, 0.047744, -0.241533;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.559293, 0.259835, 0.012183;
bias  :0.000000
===================test Result================
test 98.79%/99.10%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 1, 32;
conv2:
fire count: 0, 0, 0, 0, 0, 1, 15, 8, 0, 0;
pooling2:
fire count: 0, 0, 0, 2, 0, 0, 0, 0, 2, 0;
hidden_0:
fire count: 0, 1, 24, 5, 0, 51, 18, 4, 0, 0;
output:
fire count: 1, 1, 2, 2, 2, 2, 31, 1, 1, 1;
epoch=19 time=1599.865s cost=15.293183 Momentum=0.900000 lrate=0.00022361
train performance: 99.25%
===================weight value================
conv1:
weight:-1.769582, -1.029194, -0.603035;
bias  :0.000000 0.000000
conv2:
weight:-0.650759, -0.005005, -0.191006;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.559293, 0.252335, -0.029910;
bias  :0.000000
===================test Result================
test 99.18%/99.18%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 27;
conv2:
fire count: 0, 0, 0, 0, 0, 3, 17, 11, 0, 0;
pooling2:
fire count: 0, 0, 0, 3, 0, 0, 0, 0, 5, 2;
hidden_0:
fire count: 0, 0, 25, 9, 0, 49, 23, 0, 0, 0;
output:
fire count: 0, 2, 1, 1, 2, 2, 31, 1, 1, 0;
epoch=20 time=1515.555s cost=13.646883 Momentum=0.900000 lrate=0.00021822
train performance: 99.32%
===================weight value================
conv1:
weight:-1.809705, -1.013773, -0.586754;
bias  :0.000000 0.000000
conv2:
weight:-0.639260, -0.071556, -0.188513;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.559293, 0.304508, -0.027761;
bias  :0.000000
===================test Result================
test 99.16%/99.18%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 25;
conv2:
fire count: 0, 0, 0, 0, 0, 5, 15, 8, 0, 0;
pooling2:
fire count: 0, 0, 1, 2, 0, 0, 0, 0, 5, 2;
hidden_0:
fire count: 0, 0, 18, 12, 0, 52, 19, 0, 1, 0;
output:
fire count: 1, 1, 1, 2, 2, 2, 31, 1, 1, 1;
epoch=21 time=1544.501s cost=13.847800 Momentum=0.900000 lrate=0.00021320
train performance: 99.29%
===================weight value================
conv1:
weight:-1.836450, -1.000533, -0.577283;
bias  :0.000000 0.000000
conv2:
weight:-0.680162, -0.114432, -0.204227;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000001, -0.000018, 0.000309;
bias  :0.000000
output:
weight:-0.559293, 0.321505, -0.022682;
bias  :0.000000
===================test Result================
test 99.16%/99.18%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 23;
conv2:
fire count: 0, 0, 0, 0, 0, 7, 18, 10, 0, 0;
pooling2:
fire count: 0, 0, 3, 3, 0, 0, 0, 0, 4, 2;
hidden_0:
fire count: 0, 0, 30, 15, 0, 53, 27, 0, 0, 0;
output:
fire count: 1, 1, 2, 1, 2, 1, 34, 1, 1, 1;
epoch=22 time=1536.981s cost=16.346767 Momentum=0.900000 lrate=0.00020851
train performance: 99.20%
===================weight value================
conv1:
weight:-1.714223, -0.971404, -0.637411;
bias  :0.000000 0.000000
conv2:
weight:-0.665193, -0.139296, -0.297132;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.559293, 0.358071, 0.036534;
bias  :0.000000
===================test Result================
test 99.16%/99.18%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 25;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 3, 1, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 2, 0;
hidden_0:
fire count: 0, 0, 24, 20, 0, 55, 23, 0, 0, 0;
output:
fire count: 0, 1, 2, 1, 2, 2, 32, 1, 1, 1;
epoch=23 time=1531.267s cost=17.719433 Momentum=0.900000 lrate=0.00020412
train performance: 99.13%
===================weight value================
conv1:
weight:-1.745604, -0.986465, -0.603465;
bias  :0.000000 0.000000
conv2:
weight:-0.637748, -0.083789, -0.242200;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, -0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.552808, 0.353585, 0.037155;
bias  :0.000000
===================test Result================
test 99.19%/99.19%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 23;
conv2:
fire count: 0, 0, 0, 0, 0, 1, 10, 4, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 1, 0;
hidden_0:
fire count: 0, 0, 29, 15, 0, 56, 27, 0, 1, 0;
output:
fire count: 0, 1, 1, 1, 2, 2, 34, 1, 1, 1;
epoch=24 time=1516.429s cost=18.908567 Momentum=0.900000 lrate=0.00020000
train performance: 99.06%
===================weight value================
conv1:
weight:-1.709974, -1.007662, -0.680352;
bias  :0.000000 0.000000
conv2:
weight:-0.631788, -0.056185, -0.257812;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.552808, 0.377345, 0.091320;
bias  :0.000000
===================test Result================
test 98.48%/99.19%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 28;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 8, 4, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 2, 0;
hidden_0:
fire count: 0, 0, 22, 19, 0, 58, 16, 0, 1, 0;
output:
fire count: 0, 1, 2, 1, 1, 3, 30, 2, 1, 2;
epoch=25 time=1577.615s cost=15.654433 Momentum=0.900000 lrate=0.00019612
train performance: 99.24%
===================weight value================
conv1:
weight:-1.748921, -0.979671, -0.628149;
bias  :0.000000 0.000000
conv2:
weight:-0.688937, -0.128519, -0.277100;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, 0.000120, -0.000070;
bias  :0.000000
output:
weight:-0.552808, 0.386744, 0.058825;
bias  :0.000000
===================test Result================
test 98.83%/99.19%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 21;
conv2:
fire count: 0, 0, 0, 0, 0, 4, 13, 6, 0, 0;
pooling2:
fire count: 0, 0, 1, 1, 0, 0, 0, 0, 5, 2;
hidden_0:
fire count: 0, 1, 15, 22, 0, 59, 20, 0, 2, 0;
output:
fire count: 0, 1, 1, 2, 1, 3, 31, 1, 1, 2;
epoch=26 time=1574.269s cost=14.713467 Momentum=0.900000 lrate=0.00019245
train performance: 99.31%
===================weight value================
conv1:
weight:-1.767255, -0.962092, -0.601125;
bias  :0.000000 0.000000
conv2:
weight:-0.731796, -0.160579, -0.272568;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.552808, 0.399171, 0.061813;
bias  :0.000000
===================test Result================
test 98.40%/99.19%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 24;
conv2:
fire count: 0, 0, 0, 0, 0, 3, 11, 5, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 4, 1;
hidden_0:
fire count: 0, 1, 16, 18, 0, 58, 17, 0, 1, 0;
output:
fire count: 0, 1, 2, 1, 1, 3, 26, 2, 1, 2;
epoch=27 time=1579.299s cost=24.808701 Momentum=0.900000 lrate=0.00018898
train performance: 98.73%
===================weight value================
conv1:
weight:-1.726234, -1.017662, -0.632917;
bias  :0.000000 0.000000
conv2:
weight:-0.806726, -0.208964, -0.322004;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.552808, 0.381794, 0.031701;
bias  :0.000000
===================test Result================
test 98.19%/99.19%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 23;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 5, 3, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 1, 0;
hidden_0:
fire count: 0, 0, 20, 15, 0, 56, 25, 5, 0, 0;
output:
fire count: 0, 1, 1, 2, 2, 2, 33, 1, 1, 1;
epoch=28 time=1622.974s cost=19.931967 Momentum=0.900000 lrate=0.00018570
train performance: 99.06%
===================weight value================
conv1:
weight:-1.668477, -0.989225, -0.620230;
bias  :0.000000 0.000000
conv2:
weight:-0.890228, -0.268247, -0.304213;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, 0.000000, 0.000136;
bias  :0.000000
output:
weight:-0.541042, 0.330113, 0.063222;
bias  :0.000000
===================test Result================
test 98.88%/99.19%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 30;
conv2:
fire count: 0, 0, 0, 0, 0, 2, 12, 8, 0, 0;
pooling2:
fire count: 0, 0, 0, 1, 0, 0, 0, 0, 5, 4;
hidden_0:
fire count: 0, 1, 14, 13, 0, 57, 22, 0, 1, 0;
output:
fire count: 0, 1, 1, 2, 1, 2, 35, 1, 1, 1;
epoch=29 time=1673.204s cost=22.383101 Momentum=0.900000 lrate=0.00018257
train performance: 98.89%
===================weight value================
conv1:
weight:-1.683394, -0.925689, -0.643230;
bias  :0.000000 0.000000
conv2:
weight:-0.959327, -0.314786, -0.309265;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.541042, 0.274496, 0.101203;
bias  :0.000000
===================test Result================
test 99.01%/99.19%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 26;
conv2:
fire count: 0, 0, 0, 0, 0, 3, 13, 10, 0, 0;
pooling2:
fire count: 0, 0, 0, 2, 0, 0, 0, 0, 1, 0;
hidden_0:
fire count: 0, 1, 16, 9, 0, 59, 25, 0, 1, 0;
output:
fire count: 0, 0, 1, 1, 1, 3, 32, 2, 1, 0;
epoch=30 time=1689.219s cost=14.428450 Momentum=0.900000 lrate=0.00017961
train performance: 99.27%
===================weight value================
conv1:
weight:-1.741511, -0.973721, -0.651860;
bias  :0.000000 0.000000
conv2:
weight:-0.943337, -0.305710, -0.324224;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000002, 0.000014, 0.000048;
bias  :0.000000
output:
weight:-0.535336, 0.294618, 0.050167;
bias  :0.000000
===================test Result================
test 98.89%/99.19%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 25;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 8, 5, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 2, 1;
hidden_0:
fire count: 0, 1, 20, 12, 0, 58, 26, 2, 0, 0;
output:
fire count: 0, 1, 1, 1, 1, 2, 31, 1, 1, 1;
epoch=31 time=1668.198s cost=13.139334 Momentum=0.900000 lrate=0.00017678
train performance: 99.36%
===================weight value================
conv1:
weight:-1.738699, -0.922741, -0.591435;
bias  :0.000000 0.000000
conv2:
weight:-0.932186, -0.311408, -0.349481;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, 0.000001, -0.000125;
bias  :0.000000
output:
weight:-0.524106, 0.301255, 0.068886;
bias  :0.000000
===================test Result================
test 98.93%/99.19%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 27;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 5, 4, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 18, 16, 0, 60, 19, 0, 0, 0;
output:
fire count: 0, 1, 1, 1, 1, 3, 32, 1, 1, 1;
epoch=32 time=1687.282s cost=19.022533 Momentum=0.900000 lrate=0.00017408
train performance: 99.02%
===================weight value================
conv1:
weight:-1.734121, -0.992652, -0.643414;
bias  :0.000000 0.000000
conv2:
weight:-1.025105, -0.360405, -0.297652;
bias  :0.000000 0.000000
hidden_0:
weight:0.000003, -0.000000, -0.000000;
bias  :0.000000
output:
weight:-0.554381, 0.300806, 0.065094;
bias  :0.000000
===================test Result================
test 98.89%/99.19%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 28;
conv2:
fire count: 0, 0, 0, 0, 0, 2, 13, 9, 0, 0;
pooling2:
fire count: 0, 0, 0, 2, 0, 0, 0, 0, 3, 1;
hidden_0:
fire count: 0, 1, 11, 5, 0, 57, 23, 0, 1, 0;
output:
fire count: 0, 1, 1, 1, 1, 1, 32, 2, 1, 0;
epoch=33 time=1745.777s cost=16.274851 Momentum=0.900000 lrate=0.00017150
train performance: 99.17%
===================weight value================
conv1:
weight:-1.712117, -1.022743, -0.672045;
bias  :0.000000 0.000000
conv2:
weight:-1.109739, -0.427892, -0.367052;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, -0.000157, -0.000000;
bias  :0.000000
output:
weight:-0.586543, 0.279716, 0.095215;
bias  :0.000000
===================test Result================
test 99.05%/99.19%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 29;
conv2:
fire count: 0, 0, 0, 0, 0, 5, 15, 10, 0, 0;
pooling2:
fire count: 0, 0, 0, 2, 0, 0, 0, 0, 5, 4;
hidden_0:
fire count: 0, 1, 12, 6, 0, 57, 30, 0, 1, 0;
output:
fire count: 0, 2, 1, 0, 1, 1, 34, 2, 1, 1;
epoch=34 time=1741.341s cost=12.540983 Momentum=0.900000 lrate=0.00016903
train performance: 99.37%
===================weight value================
conv1:
weight:-1.785686, -1.052585, -0.736536;
bias  :0.000000 0.000000
conv2:
weight:-1.091073, -0.412258, -0.298818;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000002, -0.000001, -0.000000;
bias  :0.000000
output:
weight:-0.589667, 0.311766, 0.115301;
bias  :0.000000
===================test Result================
test 99.13%/99.19%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 21;
conv2:
fire count: 0, 0, 0, 0, 0, 3, 12, 8, 0, 0;
pooling2:
fire count: 0, 0, 0, 1, 0, 0, 0, 0, 5, 1;
hidden_0:
fire count: 0, 1, 16, 9, 0, 59, 27, 0, 1, 0;
output:
fire count: 0, 1, 1, 0, 1, 3, 33, 2, 0, 1;
epoch=35 time=1769.857s cost=17.172684 Momentum=0.900000 lrate=0.00016667
train performance: 99.08%
===================weight value================
conv1:
weight:-1.717381, -1.018198, -0.767036;
bias  :0.000000 0.000000
conv2:
weight:-1.121014, -0.441099, -0.285882;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, -0.000038, -0.000067;
bias  :0.000000
output:
weight:-0.609496, 0.303773, 0.085269;
bias  :0.000000
===================test Result================
test 99.00%/99.19%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 24;
conv2:
fire count: 0, 0, 0, 0, 0, 9, 17, 9, 0, 0;
pooling2:
fire count: 0, 0, 0, 3, 0, 0, 0, 0, 3, 0;
hidden_0:
fire count: 0, 1, 24, 5, 0, 59, 28, 0, 1, 0;
output:
fire count: 0, 1, 1, 0, 1, 1, 31, 2, 0, 1;
epoch=36 time=1719.955s cost=16.399450 Momentum=0.900000 lrate=0.00016440
train performance: 99.18%
===================weight value================
conv1:
weight:-1.700176, -0.990928, -0.784128;
bias  :0.000000 0.000000
conv2:
weight:-1.105648, -0.440471, -0.249131;
bias  :0.000000 0.000000
hidden_0:
weight:0.000256, 0.000098, -0.000229;
bias  :0.000000
output:
weight:-0.609496, 0.305945, 0.112196;
bias  :0.000000
===================test Result================
test 98.93%/99.19%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 23;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 7, 3, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 2, 0;
hidden_0:
fire count: 0, 1, 18, 21, 0, 60, 30, 0, 0, 0;
output:
fire count: 0, 1, 1, 0, 1, 1, 30, 1, 0, 1;
epoch=37 time=1818.870s cost=18.166883 Momentum=0.900000 lrate=0.00016222
train performance: 99.05%
===================weight value================
conv1:
weight:-1.689055, -0.947902, -0.768861;
bias  :0.000000 0.000000
conv2:
weight:-1.119317, -0.411672, -0.137368;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, 0.000000, -0.000154;
bias  :0.000000
output:
weight:-0.624743, 0.280508, 0.190841;
bias  :0.000000
===================test Result================
test 99.11%/99.19%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 25;
conv2:
fire count: 0, 0, 0, 0, 0, 9, 14, 7, 0, 0;
pooling2:
fire count: 0, 0, 0, 1, 0, 0, 0, 0, 2, 0;
hidden_0:
fire count: 0, 1, 21, 8, 0, 62, 31, 0, 1, 0;
output:
fire count: 0, 2, 1, 0, 1, 1, 36, 2, 0, 1;
epoch=38 time=1766.298s cost=16.475834 Momentum=0.900000 lrate=0.00016013
train performance: 99.17%
===================weight value================
conv1:
weight:-1.696378, -0.981197, -0.774941;
bias  :0.000000 0.000000
conv2:
weight:-1.049255, -0.370348, -0.070185;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.625352, 0.272411, 0.235730;
bias  :0.000000
===================test Result================
test 99.08%/99.19%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 26;
conv2:
fire count: 0, 0, 0, 0, 1, 17, 20, 12, 0, 0;
pooling2:
fire count: 0, 0, 3, 4, 0, 0, 0, 0, 8, 4;
hidden_0:
fire count: 0, 1, 16, 8, 0, 65, 35, 0, 1, 0;
output:
fire count: 0, 1, 1, 0, 1, 2, 38, 1, 0, 1;
epoch=39 time=1701.339s cost=15.309916 Momentum=0.900000 lrate=0.00015811
train performance: 99.25%
===================weight value================
conv1:
weight:-1.688565, -0.972092, -0.784406;
bias  :0.000000 0.000000
conv2:
weight:-0.982846, -0.357095, -0.064445;
bias  :0.000000 0.000000
hidden_0:
weight:0.000046, 0.000006, -0.000119;
bias  :0.000000
output:
weight:-0.630744, 0.279499, 0.214335;
bias  :0.000000
===================test Result================
test 98.72%/99.19%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 28;
conv2:
fire count: 0, 0, 0, 0, 0, 8, 14, 9, 0, 0;
pooling2:
fire count: 0, 0, 0, 2, 0, 0, 0, 0, 5, 1;
hidden_0:
fire count: 0, 1, 17, 14, 0, 66, 30, 0, 1, 0;
output:
fire count: 0, 1, 1, 0, 1, 3, 33, 1, 0, 1;
epoch=40 time=1709.965s cost=13.842733 Momentum=0.900000 lrate=0.00015617
train performance: 99.31%
===================weight value================
conv1:
weight:-1.686869, -1.013992, -0.864158;
bias  :0.000000 0.000000
conv2:
weight:-1.063107, -0.433857, -0.077792;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, 0.000000, -0.000021;
bias  :0.000000
output:
weight:-0.682142, 0.299609, 0.198903;
bias  :0.000000
===================test Result================
test 99.17%/99.19%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 31;
conv2:
fire count: 0, 0, 0, 0, 0, 5, 15, 11, 0, 0;
pooling2:
fire count: 0, 0, 0, 2, 0, 0, 0, 0, 4, 1;
hidden_0:
fire count: 0, 1, 25, 6, 0, 64, 29, 0, 1, 0;
output:
fire count: 1, 2, 1, 0, 2, 1, 34, 2, 0, 1;
epoch=41 time=1706.283s cost=13.695700 Momentum=0.900000 lrate=0.00015430
train performance: 99.33%
===================weight value================
conv1:
weight:-1.699429, -1.040047, -0.896591;
bias  :0.000000 0.000000
conv2:
weight:-1.106190, -0.470835, -0.098414;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, -0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.720047, 0.284064, 0.221115;
bias  :0.000000
===================test Result================
test 99.13%/99.19%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 32;
conv2:
fire count: 0, 0, 0, 0, 0, 2, 12, 9, 0, 0;
pooling2:
fire count: 0, 0, 0, 1, 0, 0, 0, 0, 5, 1;
hidden_0:
fire count: 0, 1, 27, 10, 0, 64, 33, 0, 0, 0;
output:
fire count: 0, 2, 1, 1, 1, 2, 36, 1, 0, 1;
epoch=42 time=1687.818s cost=12.339817 Momentum=0.900000 lrate=0.00015250
train performance: 99.39%
===================weight value================
conv1:
weight:-1.712262, -1.025937, -0.936145;
bias  :0.000000 0.000000
conv2:
weight:-1.123334, -0.497309, -0.106083;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, -0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.706259, 0.288860, 0.258603;
bias  :0.000000
===================test Result================
test 99.28%/99.28%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 32;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 8, 7, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 2, 0;
hidden_0:
fire count: 0, 1, 31, 9, 0, 66, 27, 0, 0, 0;
output:
fire count: 0, 2, 1, 0, 1, 1, 31, 1, 1, 1;
epoch=43 time=1689.031s cost=14.422816 Momentum=0.900000 lrate=0.00015076
train performance: 99.31%
===================weight value================
conv1:
weight:-1.705499, -1.035493, -0.995722;
bias  :0.000000 0.000000
conv2:
weight:-1.120668, -0.477528, -0.118656;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.637984, 0.275387, 0.274958;
bias  :0.000000
===================test Result================
test 99.03%/99.28%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 29;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 1, 3, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 27, 11, 0, 68, 25, 0, 0, 0;
output:
fire count: 0, 2, 2, 1, 1, 2, 30, 1, 0, 1;
epoch=44 time=1660.903s cost=12.926233 Momentum=0.900000 lrate=0.00014907
train performance: 99.37%
===================weight value================
conv1:
weight:-1.650220, -0.956074, -0.975689;
bias  :0.000000 0.000000
conv2:
weight:-1.126168, -0.449566, -0.139413;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, -0.000000, -0.000000;
bias  :0.000000
output:
weight:-0.615442, 0.264252, 0.309541;
bias  :0.000000
===================test Result================
test 98.93%/99.28%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 31;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 0, 2, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 27, 12, 0, 69, 22, 0, 0, 0;
output:
fire count: 0, 2, 2, 0, 1, 2, 31, 1, 0, 1;
epoch=45 time=1620.533s cost=14.007584 Momentum=0.900000 lrate=0.00014744
train performance: 99.32%
===================weight value================
conv1:
weight:-1.650449, -0.950517, -0.953281;
bias  :0.000000 0.000000
conv2:
weight:-1.120985, -0.459530, -0.086365;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, -0.000000, -0.000000;
bias  :0.000000
output:
weight:-0.646392, 0.259329, 0.295559;
bias  :0.000000
===================test Result================
test 99.26%/99.28%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 34;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 4, 5, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 25, 7, 0, 67, 23, 0, 1, 0;
output:
fire count: 0, 2, 1, 0, 2, 1, 37, 1, 0, 1;
epoch=46 time=1622.983s cost=10.550867 Momentum=0.900000 lrate=0.00014586
train performance: 99.47%
===================weight value================
conv1:
weight:-1.630936, -0.941834, -1.010404;
bias  :0.000000 0.000000
conv2:
weight:-1.146472, -0.482947, -0.127156;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.670929, 0.230986, 0.299007;
bias  :0.000000
===================test Result================
test 99.18%/99.28%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 1, 34;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 1, 2, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 25, 7, 0, 69, 25, 0, 0, 0;
output:
fire count: 0, 1, 2, 0, 1, 2, 36, 1, 1, 1;
epoch=47 time=1592.795s cost=11.385366 Momentum=0.900000 lrate=0.00014434
train performance: 99.45%
===================weight value================
conv1:
weight:-1.656902, -0.950068, -1.003476;
bias  :0.000000 0.000000
conv2:
weight:-1.168213, -0.502871, -0.154199;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.662520, 0.236908, 0.290104;
bias  :0.000000
===================test Result================
test 99.07%/99.28%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 33;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 0, 1, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 22, 8, 0, 70, 23, 0, 0, 0;
output:
fire count: 0, 2, 1, 0, 1, 3, 36, 1, 0, 1;
epoch=48 time=1578.123s cost=18.906050 Momentum=0.900000 lrate=0.00014286
train performance: 99.08%
===================weight value================
conv1:
weight:-1.714832, -1.030264, -1.101022;
bias  :0.000000 0.000000
conv2:
weight:-1.224672, -0.518788, -0.196084;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, -0.000000, -0.000000;
bias  :0.000000
output:
weight:-0.713316, 0.261852, 0.322982;
bias  :0.000000
===================test Result================
test 98.41%/99.28%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 26;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 0, 2, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 30, 8, 0, 71, 24, 3, 0, 0;
output:
fire count: 0, 2, 2, 0, 1, 1, 31, 1, 0, 1;
epoch=49 time=1656.521s cost=14.469633 Momentum=0.900000 lrate=0.00014142
train performance: 99.26%
===================weight value================
conv1:
weight:-1.713794, -0.994934, -1.079390;
bias  :0.000000 0.000000
conv2:
weight:-1.227555, -0.516948, -0.235750;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000002, 0.000003, 0.000000;
bias  :0.000000
output:
weight:-0.735156, 0.243834, 0.340220;
bias  :0.000000
===================test Result================
test 99.20%/99.28%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 29;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 0, 1, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 28, 5, 0, 66, 25, 2, 0, 0;
output:
fire count: 0, 2, 1, 0, 1, 1, 34, 1, 0, 1;
epoch=50 time=1643.512s cost=12.821466 Momentum=0.900000 lrate=0.00014003
train performance: 99.39%
===================weight value================
conv1:
weight:-1.760746, -1.018351, -1.057277;
bias  :0.000000 0.000000
conv2:
weight:-1.255287, -0.512487, -0.239032;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, -0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.709790, 0.309984, 0.318375;
bias  :0.000000
===================test Result================
test 98.67%/99.28%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 30;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 0, 2, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 25, 6, 0, 69, 25, 0, 0, 0;
output:
fire count: 0, 2, 2, 0, 1, 2, 34, 1, 0, 1;
epoch=51 time=1675.207s cost=11.617033 Momentum=0.900000 lrate=0.00013868
train performance: 99.43%
===================weight value================
conv1:
weight:-1.682923, -0.988352, -1.062128;
bias  :0.000000 0.000000
conv2:
weight:-1.238145, -0.546060, -0.228018;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.702795, 0.268255, 0.334764;
bias  :0.000000
===================test Result================
test 99.08%/99.28%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 32;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 1, 3, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 33, 3, 0, 71, 26, 0, 0, 0;
output:
fire count: 0, 1, 1, 0, 1, 2, 33, 1, 0, 1;
epoch=52 time=1709.842s cost=9.571850 Momentum=0.900000 lrate=0.00013736
train performance: 99.54%
===================weight value================
conv1:
weight:-1.648844, -0.966900, -1.091543;
bias  :0.000000 0.000000
conv2:
weight:-1.230529, -0.536936, -0.231918;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, -0.000000, -0.000000;
bias  :0.000000
output:
weight:-0.703602, 0.265584, 0.333452;
bias  :0.000000
===================test Result================
test 99.12%/99.28%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 34;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 31, 6, 0, 70, 27, 1, 0, 0;
output:
fire count: 0, 1, 1, 0, 1, 2, 32, 0, 1, 1;
epoch=53 time=1677.369s cost=10.510550 Momentum=0.900000 lrate=0.00013608
train performance: 99.50%
===================weight value================
conv1:
weight:-1.677267, -0.983939, -1.107526;
bias  :0.000000 0.000000
conv2:
weight:-1.242339, -0.531384, -0.227759;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, 0.000000, -0.000000;
bias  :0.000000
output:
weight:-0.693257, 0.259901, 0.336216;
bias  :0.000000
===================test Result================
test 99.05%/99.28%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 33;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 0, 1, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 27, 7, 0, 71, 20, 0, 0, 0;
output:
fire count: 0, 1, 1, 0, 2, 2, 34, 1, 0, 1;
epoch=54 time=1725.735s cost=18.563168 Momentum=0.900000 lrate=0.00013484
train performance: 99.03%
===================weight value================
conv1:
weight:-1.672847, -0.983667, -1.082704;
bias  :0.000000 0.000000
conv2:
weight:-1.202784, -0.535132, -0.224339;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, 0.000006, -0.000000;
bias  :0.000000
output:
weight:-0.712951, 0.265559, 0.347807;
bias  :0.000000
===================test Result================
test 99.19%/99.28%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 30;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 2, 2, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 1, 0;
hidden_0:
fire count: 0, 0, 30, 4, 0, 70, 31, 0, 0, 0;
output:
fire count: 0, 2, 0, 0, 1, 2, 36, 1, 0, 1;
epoch=55 time=1682.465s cost=18.281033 Momentum=0.900000 lrate=0.00013363
train performance: 99.11%
===================weight value================
conv1:
weight:-1.633625, -0.959706, -1.063260;
bias  :0.000000 0.000000
conv2:
weight:-1.119359, -0.510166, -0.187116;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000001, -0.000004, 0.000000;
bias  :0.000000
output:
weight:-0.845893, 0.269880, 0.361060;
bias  :0.000000
===================test Result================
test 99.29%/99.29%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 1, 37;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 6, 7, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 26, 3, 0, 70, 29, 0, 0, 0;
output:
fire count: 0, 2, 1, 0, 1, 2, 35, 1, 0, 2;
epoch=56 time=1689.362s cost=13.298634 Momentum=0.900000 lrate=0.00013245
train performance: 99.34%
===================weight value================
conv1:
weight:-1.698667, -0.984269, -1.092087;
bias  :0.000000 0.000000
conv2:
weight:-1.079899, -0.489209, -0.189368;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, -0.000000;
bias  :0.000000
output:
weight:-0.804055, 0.260232, 0.347343;
bias  :0.000000
===================test Result================
test 99.10%/99.29%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 31;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 2, 4, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 2, 0;
hidden_0:
fire count: 0, 1, 30, 2, 0, 70, 26, 0, 0, 0;
output:
fire count: 0, 1, 1, 0, 1, 3, 29, 1, 0, 1;
epoch=57 time=1747.034s cost=22.575350 Momentum=0.900000 lrate=0.00013131
train performance: 98.81%
===================weight value================
conv1:
weight:-1.595360, -0.900704, -1.042404;
bias  :0.000000 0.000000
conv2:
weight:-1.130591, -0.500618, -0.120329;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000006, -0.000005, -0.000001;
bias  :0.000000
output:
weight:-0.824069, 0.269875, 0.352776;
bias  :0.000000
===================test Result================
test 99.22%/99.29%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 1, 35;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 7, 7, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 3, 0;
hidden_0:
fire count: 0, 0, 36, 0, 0, 70, 38, 0, 0, 0;
output:
fire count: 0, 2, 0, 0, 1, 1, 34, 1, 0, 1;
epoch=58 time=1715.683s cost=10.591350 Momentum=0.900000 lrate=0.00013019
train performance: 99.50%
===================weight value================
conv1:
weight:-1.658765, -0.924298, -1.027385;
bias  :0.000000 0.000000
conv2:
weight:-1.103242, -0.496526, -0.125114;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, -0.000027, -0.000000;
bias  :0.000000
output:
weight:-0.839898, 0.264284, 0.350985;
bias  :0.000000
===================test Result================
test 99.14%/99.29%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 1, 35;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 3, 4, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 1, 0;
hidden_0:
fire count: 0, 0, 35, 4, 0, 72, 31, 0, 0, 0;
output:
fire count: 0, 2, 1, 0, 1, 1, 33, 1, 0, 1;
epoch=59 time=1677.451s cost=10.645383 Momentum=0.900000 lrate=0.00012910
train performance: 99.46%
===================weight value================
conv1:
weight:-1.677385, -0.939596, -1.041571;
bias  :0.000000 0.000000
conv2:
weight:-1.114795, -0.530225, -0.111635;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, -0.000000, -0.000001;
bias  :0.000000
output:
weight:-0.882127, 0.267022, 0.365597;
bias  :0.000000
===================test Result================
test 99.14%/99.29%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 1, 34;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 5, 7, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 36, 5, 0, 71, 30, 0, 1, 0;
output:
fire count: 0, 2, 1, 0, 1, 1, 33, 1, 0, 1;
epoch=60 time=1704.542s cost=12.807767 Momentum=0.900000 lrate=0.00012804
train performance: 99.36%
===================weight value================
conv1:
weight:-1.683609, -0.935753, -1.061723;
bias  :0.000000 0.000000
conv2:
weight:-1.077069, -0.520923, -0.139433;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000028, -0.000000, -0.000000;
bias  :0.000000
output:
weight:-0.852656, 0.263482, 0.387609;
bias  :0.000000
===================test Result================
test 99.13%/99.29%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 1, 34;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 2, 5, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 33, 16, 0, 73, 28, 0, 1, 0;
output:
fire count: 0, 2, 1, 0, 1, 2, 33, 1, 0, 1;
epoch=61 time=1698.021s cost=12.180950 Momentum=0.900000 lrate=0.00012700
train performance: 99.42%
===================weight value================
conv1:
weight:-1.689852, -0.960292, -1.100251;
bias  :0.000000 0.000000
conv2:
weight:-1.024175, -0.520619, -0.109965;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, -0.000000;
bias  :0.000000
output:
weight:-0.862195, 0.258837, 0.394366;
bias  :0.000000
===================test Result================
test 99.35%/99.35%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 33;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 5, 8, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 29, 10, 0, 73, 29, 0, 0, 0;
output:
fire count: 0, 1, 1, 0, 1, 2, 36, 1, 0, 1;
epoch=62 time=1715.143s cost=10.395383 Momentum=0.900000 lrate=0.00012599
train performance: 99.53%
===================weight value================
conv1:
weight:-1.651300, -0.931047, -1.110515;
bias  :0.000000 0.000000
conv2:
weight:-1.015316, -0.524799, -0.126887;
bias  :0.000000 0.000000
hidden_0:
weight:0.000010, 0.000053, 0.000000;
bias  :0.000000
output:
weight:-0.874701, 0.264833, 0.395298;
bias  :0.000000
===================test Result================
test 99.27%/99.35%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 1, 34;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 3, 7, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 28, 10, 0, 72, 32, 0, 1, 0;
output:
fire count: 0, 1, 1, 0, 1, 2, 35, 1, 0, 1;
epoch=63 time=1718.747s cost=9.889800 Momentum=0.900000 lrate=0.00012500
train performance: 99.51%
===================weight value================
conv1:
weight:-1.683703, -0.966299, -1.130091;
bias  :0.000000 0.000000
conv2:
weight:-1.017970, -0.519861, -0.100933;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, -0.000000, -0.000000;
bias  :0.000000
output:
weight:-0.892703, 0.277542, 0.371857;
bias  :0.000000
===================test Result================
test 99.29%/99.35%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 32;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 3, 7, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 28, 7, 0, 72, 29, 0, 0, 0;
output:
fire count: 1, 2, 0, 0, 1, 2, 33, 1, 0, 1;
epoch=64 time=1685.905s cost=8.949850 Momentum=0.900000 lrate=0.00012403
train performance: 99.58%
===================weight value================
conv1:
weight:-1.700033, -0.976821, -1.121284;
bias  :0.000000 0.000000
conv2:
weight:-1.010597, -0.530621, -0.112078;
bias  :0.000000 0.000000
hidden_0:
weight:0.000037, -0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.904120, 0.256323, 0.357877;
bias  :0.000000
===================test Result================
test 99.34%/99.35%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 32;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 3, 7, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 33, 8, 0, 72, 28, 0, 1, 0;
output:
fire count: 0, 2, 1, 0, 1, 1, 35, 1, 0, 1;
epoch=65 time=1690.444s cost=10.875517 Momentum=0.900000 lrate=0.00012309
train performance: 99.53%
===================weight value================
conv1:
weight:-1.730734, -0.986721, -1.110539;
bias  :0.000000 0.000000
conv2:
weight:-1.008718, -0.534996, -0.128000;
bias  :0.000000 0.000000
hidden_0:
weight:0.000001, -0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.855466, 0.245264, 0.345453;
bias  :0.000000
===================test Result================
test 99.35%/99.35%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 32;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 2, 6, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 2, 1;
hidden_0:
fire count: 0, 1, 32, 8, 0, 72, 29, 0, 0, 0;
output:
fire count: 1, 1, 1, 0, 1, 2, 35, 1, 1, 1;
epoch=66 time=1719.362s cost=14.266216 Momentum=0.900000 lrate=0.00012217
train performance: 99.28%
===================weight value================
conv1:
weight:-1.673234, -0.932366, -1.065563;
bias  :0.000000 0.000000
conv2:
weight:-1.015902, -0.540854, -0.116322;
bias  :0.000000 0.000000
hidden_0:
weight:0.000008, -0.000000, -0.000000;
bias  :0.000000
output:
weight:-0.856121, 0.251985, 0.379187;
bias  :0.000000
===================test Result================
test 99.39%/99.39%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 36;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 2, 5, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 29, 10, 0, 72, 31, 0, 0, 0;
output:
fire count: 0, 2, 0, 0, 1, 2, 36, 1, 0, 1;
epoch=67 time=1674.043s cost=9.508950 Momentum=0.900000 lrate=0.00012127
train performance: 99.56%
===================weight value================
conv1:
weight:-1.674875, -0.929607, -1.064789;
bias  :0.000000 0.000000
conv2:
weight:-1.005002, -0.552239, -0.104937;
bias  :0.000000 0.000000
hidden_0:
weight:0.000017, 0.000000, -0.000001;
bias  :0.000000
output:
weight:-0.867612, 0.234827, 0.349172;
bias  :0.000000
===================test Result================
test 99.32%/99.39%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 35;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 2, 7, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 1, 0;
hidden_0:
fire count: 0, 1, 29, 8, 0, 72, 28, 0, 0, 0;
output:
fire count: 0, 2, 1, 0, 1, 2, 36, 1, 0, 1;
epoch=68 time=1673.355s cost=11.152267 Momentum=0.900000 lrate=0.00012039
train performance: 99.48%
===================weight value================
conv1:
weight:-1.656440, -0.920039, -1.081931;
bias  :0.000000 0.000000
conv2:
weight:-1.000693, -0.558249, -0.064591;
bias  :0.000000 0.000000
hidden_0:
weight:0.000104, -0.000000, 0.000200;
bias  :0.000000
output:
weight:-0.907870, 0.243015, 0.340516;
bias  :0.000000
===================test Result================
test 99.40%/99.40%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 1, 37;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 6, 9, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 31, 4, 0, 72, 31, 1, 0, 0;
output:
fire count: 1, 2, 1, 1, 1, 1, 36, 1, 1, 1;
epoch=69 time=1698.488s cost=10.032233 Momentum=0.900000 lrate=0.00011952
train performance: 99.52%
===================weight value================
conv1:
weight:-1.658403, -0.910241, -1.081003;
bias  :0.000000 0.000000
conv2:
weight:-1.021289, -0.568271, -0.074255;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, -0.000004, -0.000005;
bias  :0.000000
output:
weight:-0.850411, 0.215935, 0.348594;
bias  :0.000000
===================test Result================
test 99.36%/99.40%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 1, 36;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 3, 5, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 6, 2;
hidden_0:
fire count: 0, 0, 31, 9, 0, 74, 28, 0, 0, 0;
output:
fire count: 0, 1, 1, 0, 1, 2, 37, 1, 0, 1;
epoch=70 time=1712.833s cost=8.826000 Momentum=0.900000 lrate=0.00011868
train performance: 99.62%
===================weight value================
conv1:
weight:-1.690668, -0.940438, -1.108714;
bias  :0.000000 0.000000
conv2:
weight:-1.009678, -0.561962, -0.070335;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, 0.000000, -0.000000;
bias  :0.000000
output:
weight:-0.830133, 0.220200, 0.353607;
bias  :0.000000
===================test Result================
test 99.43%/99.43%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 1, 37;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 2, 5, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 2, 1;
hidden_0:
fire count: 0, 1, 26, 12, 0, 72, 22, 0, 0, 0;
output:
fire count: 0, 1, 1, 0, 1, 3, 34, 1, 1, 1;
epoch=71 time=1706.082s cost=9.542500 Momentum=0.900000 lrate=0.00011785
train performance: 99.54%
===================weight value================
conv1:
weight:-1.702606, -0.951142, -1.099672;
bias  :0.000000 0.000000
conv2:
weight:-1.005684, -0.570901, -0.081051;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, -0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.820792, 0.218069, 0.360029;
bias  :0.000000
===================test Result================
test 99.36%/99.43%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 1, 38;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 2, 3, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 5, 2;
hidden_0:
fire count: 0, 0, 27, 11, 0, 72, 26, 0, 0, 0;
output:
fire count: 1, 1, 1, 1, 1, 2, 36, 1, 1, 1;
epoch=72 time=1706.033s cost=12.072634 Momentum=0.900000 lrate=0.00011704
train performance: 99.46%
===================weight value================
conv1:
weight:-1.693943, -0.923597, -1.059273;
bias  :0.000000 0.000000
conv2:
weight:-1.045573, -0.591098, -0.111191;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, -0.000000;
bias  :0.000000
output:
weight:-0.793479, 0.196149, 0.328590;
bias  :0.000000
===================test Result================
test 99.32%/99.43%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 1, 39;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 1, 2, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 3, 1;
hidden_0:
fire count: 0, 0, 23, 9, 0, 73, 22, 0, 0, 0;
output:
fire count: 0, 1, 1, 0, 1, 3, 36, 1, 0, 1;
epoch=73 time=1729.159s cost=18.666216 Momentum=0.900000 lrate=0.00011625
train performance: 99.06%
===================weight value================
conv1:
weight:-1.688326, -0.905229, -1.048970;
bias  :0.000000 0.000000
conv2:
weight:-1.012230, -0.568103, -0.102725;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, -0.000000, -0.000000;
bias  :0.000000
output:
weight:-0.838464, 0.223601, 0.316489;
bias  :0.000000
===================test Result================
test 98.77%/99.43%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 1, 41;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 4, 4, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 28, 3, 0, 73, 32, 5, 0, 0;
output:
fire count: 0, 1, 1, 0, 2, 1, 32, 1, 0, 1;
epoch=74 time=1702.158s cost=10.460667 Momentum=0.900000 lrate=0.00011547
train performance: 99.50%
===================weight value================
conv1:
weight:-1.718496, -0.903970, -1.026141;
bias  :0.000000 0.000000
conv2:
weight:-0.978530, -0.543676, -0.073999;
bias  :0.000000 0.000000
hidden_0:
weight:0.000004, 0.000000, -0.000000;
bias  :0.000000
output:
weight:-0.825235, 0.165606, 0.303424;
bias  :0.000000
===================test Result================
test 99.38%/99.43%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 1, 39;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 1, 2, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 4, 2;
hidden_0:
fire count: 0, 0, 27, 8, 0, 74, 30, 0, 0, 0;
output:
fire count: 1, 1, 1, 1, 1, 3, 35, 1, 0, 1;
epoch=75 time=1676.583s cost=12.637350 Momentum=0.900000 lrate=0.00011471
train performance: 99.41%
===================weight value================
conv1:
weight:-1.773137, -0.958531, -1.082224;
bias  :0.000000 0.000000
conv2:
weight:-1.005104, -0.532762, -0.066514;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.821274, 0.142437, 0.318229;
bias  :0.000000
===================test Result================
test 99.35%/99.43%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 36;
conv2:
fire count: 0, 0, 0, 0, 0, 1, 7, 5, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 5, 2;
hidden_0:
fire count: 0, 1, 33, 9, 0, 76, 29, 0, 0, 0;
output:
fire count: 0, 2, 1, 0, 1, 2, 35, 1, 0, 1;
epoch=76 time=1744.544s cost=14.688717 Momentum=0.900000 lrate=0.00011396
train performance: 99.31%
===================weight value================
conv1:
weight:-1.778491, -0.946998, -1.070616;
bias  :0.000000 0.000000
conv2:
weight:-1.019841, -0.546470, -0.057136;
bias  :0.000000 0.000000
hidden_0:
weight:0.000002, 0.000009, -0.000000;
bias  :0.000000
output:
weight:-0.785301, 0.112416, 0.330122;
bias  :0.000000
===================test Result================
test 99.29%/99.43%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 35;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 6, 5, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 26, 11, 0, 76, 26, 0, 0, 0;
output:
fire count: 0, 1, 1, 0, 2, 2, 36, 1, 0, 1;
epoch=77 time=1734.836s cost=15.860000 Momentum=0.900000 lrate=0.00011323
train performance: 99.23%
===================weight value================
conv1:
weight:-1.764420, -0.973864, -1.106329;
bias  :0.000000 0.000000
conv2:
weight:-0.997623, -0.508305, -0.040788;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.783663, 0.139208, 0.343830;
bias  :0.000000
===================test Result================
test 99.14%/99.43%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 36;
conv2:
fire count: 0, 0, 0, 0, 0, 1, 9, 8, 0, 0;
pooling2:
fire count: 0, 0, 0, 1, 0, 0, 0, 0, 3, 1;
hidden_0:
fire count: 0, 1, 27, 13, 0, 73, 28, 0, 0, 0;
output:
fire count: 0, 2, 0, 0, 2, 1, 38, 1, 0, 1;
epoch=78 time=1699.545s cost=19.591583 Momentum=0.900000 lrate=0.00011251
train performance: 99.05%
===================weight value================
conv1:
weight:-1.789516, -0.977040, -1.125996;
bias  :0.000000 0.000000
conv2:
weight:-0.988143, -0.491048, -0.036974;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000001, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.747492, 0.116284, 0.355825;
bias  :0.000000
===================test Result================
test 98.13%/99.43%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 35;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 6, 9, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 32, 14, 0, 74, 29, 0, 0, 0;
output:
fire count: 0, 1, 1, 0, 1, 1, 38, 1, 0, 1;
epoch=79 time=1705.157s cost=11.490200 Momentum=0.900000 lrate=0.00011180
train performance: 99.44%
===================weight value================
conv1:
weight:-1.812309, -0.987017, -1.120735;
bias  :0.000000 0.000000
conv2:
weight:-0.973866, -0.486822, -0.043202;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000008, -0.000000;
bias  :0.000000
output:
weight:-0.748477, 0.097088, 0.353007;
bias  :0.000000
===================test Result================
test 99.39%/99.43%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 34;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 7, 9, 0, 0;
pooling2:
fire count: 0, 0, 0, 1, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 30, 15, 0, 75, 30, 0, 0, 0;
output:
fire count: 0, 1, 1, 0, 1, 2, 36, 1, 0, 1;
epoch=80 time=1740.268s cost=19.325251 Momentum=0.900000 lrate=0.00011111
train performance: 99.09%
===================weight value================
conv1:
weight:-1.795160, -0.996114, -1.126875;
bias  :0.000000 0.000000
conv2:
weight:-0.946248, -0.472539, -0.029004;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000002, 0.000001;
bias  :0.000000
output:
weight:-0.839358, 0.093603, 0.377176;
bias  :0.000000
===================test Result================
test 98.95%/99.43%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 1, 38;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 9, 9, 0, 0;
pooling2:
fire count: 0, 0, 0, 1, 0, 0, 0, 0, 2, 2;
hidden_0:
fire count: 0, 1, 22, 13, 0, 73, 24, 0, 0, 0;
output:
fire count: 0, 1, 0, 0, 1, 2, 36, 1, 0, 1;
epoch=81 time=1730.495s cost=13.726900 Momentum=0.900000 lrate=0.00011043
train performance: 99.37%
===================weight value================
conv1:
weight:-1.805386, -0.991744, -1.083780;
bias  :0.000000 0.000000
conv2:
weight:-1.007356, -0.520905, -0.041480;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, -0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.855167, 0.122246, 0.382186;
bias  :0.000000
===================test Result================
test 99.16%/99.43%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 1, 39;
conv2:
fire count: 0, 0, 0, 0, 0, 1, 12, 9, 0, 0;
pooling2:
fire count: 0, 0, 0, 1, 0, 0, 0, 0, 5, 5;
hidden_0:
fire count: 0, 1, 28, 8, 0, 73, 29, 3, 0, 0;
output:
fire count: 1, 1, 1, 1, 1, 2, 33, 1, 0, 1;
epoch=82 time=1748.230s cost=14.485733 Momentum=0.900000 lrate=0.00010976
train performance: 99.28%
===================weight value================
conv1:
weight:-1.785826, -0.984337, -1.099193;
bias  :0.000000 0.000000
conv2:
weight:-0.982764, -0.511886, -0.030460;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, -0.000000;
bias  :0.000000
output:
weight:-0.811735, 0.100499, 0.353287;
bias  :0.000000
===================test Result================
test 99.03%/99.43%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 1, 40;
conv2:
fire count: 0, 0, 0, 0, 0, 3, 11, 7, 0, 0;
pooling2:
fire count: 0, 0, 0, 1, 0, 0, 0, 0, 6, 4;
hidden_0:
fire count: 0, 1, 30, 7, 0, 75, 33, 0, 1, 0;
output:
fire count: 1, 2, 1, 0, 1, 1, 37, 1, 0, 1;
epoch=83 time=1761.067s cost=14.247550 Momentum=0.900000 lrate=0.00010911
train performance: 99.30%
===================weight value================
conv1:
weight:-1.785104, -0.981075, -1.091547;
bias  :0.000000 0.000000
conv2:
weight:-0.959918, -0.488721, -0.017715;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000002, 0.000008;
bias  :0.000000
output:
weight:-0.800883, 0.054955, 0.374090;
bias  :0.000000
===================test Result================
test 99.31%/99.43%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 2, 40;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 7, 5, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 4, 2;
hidden_0:
fire count: 0, 1, 27, 14, 0, 73, 29, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 2, 36, 1, 1, 1;
epoch=84 time=1725.710s cost=11.482317 Momentum=0.900000 lrate=0.00010847
train performance: 99.50%
===================weight value================
conv1:
weight:-1.827481, -1.010583, -1.102673;
bias  :0.000000 0.000000
conv2:
weight:-0.915294, -0.487333, 0.002783;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, 0.000003, 0.000001;
bias  :0.000000
output:
weight:-0.816440, 0.062019, 0.347581;
bias  :0.000000
===================test Result================
test 99.47%/99.47%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 2, 41;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 6, 5, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 4, 2;
hidden_0:
fire count: 0, 1, 25, 14, 0, 74, 25, 0, 0, 0;
output:
fire count: 1, 1, 0, 0, 1, 3, 36, 1, 0, 1;
epoch=85 time=1740.374s cost=14.722616 Momentum=0.900000 lrate=0.00010783
train performance: 99.23%
===================weight value================
conv1:
weight:-1.856017, -1.060552, -1.159461;
bias  :0.000000 0.000000
conv2:
weight:-0.925454, -0.500103, 0.017206;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.821699, 0.055705, 0.351979;
bias  :0.000000
===================test Result================
test 99.03%/99.47%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 37;
conv2:
fire count: 0, 0, 0, 0, 0, 3, 12, 9, 0, 0;
pooling2:
fire count: 0, 0, 0, 1, 0, 0, 0, 0, 4, 4;
hidden_0:
fire count: 0, 0, 34, 7, 0, 74, 33, 2, 0, 0;
output:
fire count: 1, 1, 1, 0, 1, 2, 32, 1, 0, 1;
epoch=86 time=1753.645s cost=15.878034 Momentum=0.900000 lrate=0.00010721
train performance: 99.20%
===================weight value================
conv1:
weight:-1.858190, -1.059999, -1.160377;
bias  :0.000000 0.000000
conv2:
weight:-0.908993, -0.486563, 0.048414;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, 0.000013, -0.000004;
bias  :0.000000
output:
weight:-0.740953, 0.020102, 0.334427;
bias  :0.000000
===================test Result================
test 99.12%/99.47%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 1, 38;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 5, 4, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 5, 1;
hidden_0:
fire count: 0, 1, 27, 14, 0, 79, 26, 0, 0, 0;
output:
fire count: 1, 1, 0, 0, 1, 2, 37, 1, 0, 1;
epoch=87 time=1770.996s cost=13.359633 Momentum=0.900000 lrate=0.00010660
train performance: 99.34%
===================weight value================
conv1:
weight:-1.853285, -1.054148, -1.130429;
bias  :0.000000 0.000000
conv2:
weight:-0.934614, -0.493292, 0.025085;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.713401, 0.016228, 0.342793;
bias  :0.000000
===================test Result================
test 99.27%/99.47%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 1, 37;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 6, 5, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 3, 1;
hidden_0:
fire count: 0, 1, 28, 8, 0, 77, 26, 0, 1, 0;
output:
fire count: 1, 1, 0, 0, 2, 1, 37, 2, 0, 0;
epoch=88 time=1727.775s cost=17.929384 Momentum=0.900000 lrate=0.00010600
train performance: 99.12%
===================weight value================
conv1:
weight:-1.867131, -1.054726, -1.133317;
bias  :0.000000 0.000000
conv2:
weight:-0.937840, -0.497948, 0.003997;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, -0.000000, -0.000005;
bias  :0.000000
output:
weight:-0.707799, 0.028705, 0.349009;
bias  :0.000000
===================test Result================
test 99.08%/99.47%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 35;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 8, 8, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 32, 14, 0, 82, 23, 0, 0, 0;
output:
fire count: 1, 1, 0, 0, 1, 1, 32, 2, 0, 0;
epoch=89 time=1659.945s cost=10.810700 Momentum=0.900000 lrate=0.00010541
train performance: 99.49%
===================weight value================
conv1:
weight:-1.878522, -1.049328, -1.142099;
bias  :0.000000 0.000000
conv2:
weight:-0.942319, -0.467252, 0.035496;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, -0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.711373, 0.034883, 0.330517;
bias  :0.000000
===================test Result================
test 99.37%/99.47%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 34;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 8, 9, 0, 0;
pooling2:
fire count: 0, 0, 0, 1, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 31, 12, 0, 82, 24, 0, 0, 0;
output:
fire count: 1, 1, 1, 0, 1, 1, 34, 1, 0, 0;
epoch=90 time=1619.722s cost=12.608100 Momentum=0.900000 lrate=0.00010483
train performance: 99.41%
===================weight value================
conv1:
weight:-1.914507, -1.050846, -1.116836;
bias  :0.000000 0.000000
conv2:
weight:-0.952657, -0.507505, -0.001238;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, -0.000000, -0.000005;
bias  :0.000000
output:
weight:-0.720028, 0.045598, 0.332821;
bias  :0.000000
===================test Result================
test 99.23%/99.47%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 33;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 9, 9, 0, 0;
pooling2:
fire count: 0, 0, 0, 1, 0, 0, 0, 0, 0, 1;
hidden_0:
fire count: 0, 1, 28, 14, 0, 78, 23, 0, 0, 0;
output:
fire count: 1, 1, 1, 0, 2, 1, 32, 1, 0, 0;
epoch=91 time=1626.767s cost=11.737467 Momentum=0.900000 lrate=0.00010426
train performance: 99.44%
===================weight value================
conv1:
weight:-1.899276, -1.047185, -1.115818;
bias  :0.000000 0.000000
conv2:
weight:-0.936532, -0.517192, 0.005840;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, -0.000000, 0.000001;
bias  :0.000000
output:
weight:-0.732016, 0.016842, 0.334420;
bias  :0.000000
===================test Result================
test 99.33%/99.47%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 36;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 7, 6, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 25, 13, 0, 78, 24, 0, 1, 0;
output:
fire count: 1, 1, 0, 0, 1, 2, 34, 1, 1, 1;
epoch=92 time=1631.732s cost=10.168517 Momentum=0.900000 lrate=0.00010370
train performance: 99.52%
===================weight value================
conv1:
weight:-1.915495, -1.069793, -1.146200;
bias  :0.000000 0.000000
conv2:
weight:-0.942313, -0.512480, 0.045595;
bias  :0.000000 0.000000
hidden_0:
weight:0.000012, 0.000018, -0.000000;
bias  :0.000000
output:
weight:-0.717332, 0.001223, 0.329330;
bias  :0.000000
===================test Result================
test 99.33%/99.47%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 34;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 6, 5, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 4, 2;
hidden_0:
fire count: 0, 1, 25, 11, 0, 78, 24, 0, 0, 0;
output:
fire count: 1, 1, 1, 0, 2, 2, 37, 0, 1, 1;
epoch=93 time=1637.777s cost=11.743016 Momentum=0.900000 lrate=0.00010314
train performance: 99.41%
===================weight value================
conv1:
weight:-1.899327, -1.041624, -1.104808;
bias  :0.000000 0.000000
conv2:
weight:-0.956221, -0.522529, 0.037605;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, -0.000000, 0.000008;
bias  :0.000000
output:
weight:-0.704640, -0.008352, 0.333124;
bias  :0.000000
===================test Result================
test 99.30%/99.47%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 35;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 6, 5, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 2, 1;
hidden_0:
fire count: 0, 1, 27, 10, 0, 79, 24, 0, 1, 0;
output:
fire count: 1, 1, 0, 0, 1, 1, 37, 2, 1, 1;
epoch=94 time=1624.293s cost=16.114216 Momentum=0.900000 lrate=0.00010260
train performance: 99.25%
===================weight value================
conv1:
weight:-1.901386, -1.027637, -1.099722;
bias  :0.000000 0.000000
conv2:
weight:-0.931156, -0.515564, 0.043486;
bias  :0.000000 0.000000
hidden_0:
weight:0.000024, 0.000033, 0.000000;
bias  :0.000000
output:
weight:-0.699882, -0.039572, 0.333333;
bias  :0.000000
===================test Result================
test 99.17%/99.47%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 34;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 2, 3, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 2, 0;
hidden_0:
fire count: 0, 1, 25, 12, 0, 79, 18, 0, 1, 0;
output:
fire count: 1, 1, 0, 0, 2, 3, 34, 1, 1, 1;
epoch=95 time=1640.219s cost=12.530150 Momentum=0.900000 lrate=0.00010206
train performance: 99.40%
===================weight value================
conv1:
weight:-1.880770, -1.005076, -1.083937;
bias  :0.000000 0.000000
conv2:
weight:-0.938773, -0.505761, 0.036953;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, -0.000000, -0.000000;
bias  :0.000000
output:
weight:-0.727008, -0.064142, 0.322392;
bias  :0.000000
===================test Result================
test 99.10%/99.47%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 1, 36;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 5, 5, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 2, 0;
hidden_0:
fire count: 0, 1, 24, 9, 0, 81, 22, 0, 1, 0;
output:
fire count: 1, 1, 1, 0, 2, 2, 34, 1, 0, 1;
epoch=96 time=1634.255s cost=11.870550 Momentum=0.900000 lrate=0.00010153
train performance: 99.44%
===================weight value================
conv1:
weight:-1.933792, -1.067709, -1.110724;
bias  :0.000000 0.000000
conv2:
weight:-0.940877, -0.485453, 0.071140;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000005, 0.000000, -0.000001;
bias  :0.000000
output:
weight:-0.775520, -0.013102, 0.317218;
bias  :0.000000
===================test Result================
test 99.23%/99.47%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 35;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 7, 8, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 7, 2;
hidden_0:
fire count: 0, 1, 23, 8, 0, 79, 26, 0, 0, 0;
output:
fire count: 1, 1, 1, 0, 2, 2, 34, 0, 0, 1;
epoch=97 time=1667.219s cost=19.693016 Momentum=0.900000 lrate=0.00010102
train performance: 98.98%
===================weight value================
conv1:
weight:-1.929363, -1.044389, -1.065720;
bias  :0.000000 0.000000
conv2:
weight:-0.973688, -0.500645, 0.076845;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000166, -0.000020, 0.000005;
bias  :0.000000
output:
weight:-0.816724, -0.033095, 0.308370;
bias  :0.000000
===================test Result================
test 98.98%/99.47%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 1, 36;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 7, 8, 0, 0;
pooling2:
fire count: 0, 0, 0, 1, 0, 0, 0, 0, 5, 2;
hidden_0:
fire count: 0, 0, 24, 3, 0, 76, 26, 0, 1, 0;
output:
fire count: 1, 1, 0, 0, 1, 1, 34, 0, 1, 1;
epoch=98 time=1644.675s cost=20.329350 Momentum=0.900000 lrate=0.00010050
train performance: 98.95%
===================weight value================
conv1:
weight:-1.908675, -1.056839, -1.114414;
bias  :0.000000 0.000000
conv2:
weight:-0.993429, -0.526706, 0.051415;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000063, -0.000004, -0.000002;
bias  :0.000000
output:
weight:-0.740616, -0.134714, 0.324962;
bias  :0.000000
===================test Result================
test 98.49%/99.47%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 36;
conv2:
fire count: 0, 0, 0, 0, 0, 1, 10, 9, 0, 0;
pooling2:
fire count: 0, 0, 0, 1, 0, 0, 0, 0, 5, 1;
hidden_0:
fire count: 0, 0, 31, 5, 0, 88, 28, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 2, 35, 2, 0, 1;
epoch=99 time=1686.848s cost=11.972034 Momentum=0.900000 lrate=0.00010000
train performance: 99.41%
===================weight value================
conv1:
weight:-1.957015, -1.095936, -1.121886;
bias  :0.000000 0.000000
conv2:
weight:-1.003794, -0.541212, 0.034477;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, -0.000000, 0.000013;
bias  :0.000000
output:
weight:-0.789273, -0.055945, 0.318493;
bias  :0.000000
===================test Result================
test 99.37%/99.47%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 33;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 7, 6, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 2, 1;
hidden_0:
fire count: 0, 1, 29, 8, 0, 83, 28, 0, 1, 0;
output:
fire count: 1, 1, 0, 0, 2, 1, 34, 1, 0, 1;
epoch=100 time=1658.798s cost=9.554684 Momentum=0.900000 lrate=0.00009950
train performance: 99.52%
===================weight value================
conv1:
weight:-1.968358, -1.138378, -1.156276;
bias  :0.000000 0.000000
conv2:
weight:-0.997550, -0.535924, 0.071848;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000174, -0.000000, -0.000000;
bias  :0.000000
output:
weight:-0.830723, -0.064136, 0.313305;
bias  :0.000000
===================test Result================
test 99.33%/99.47%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 33;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 8, 9, 0, 0;
pooling2:
fire count: 0, 0, 0, 1, 0, 0, 0, 0, 3, 2;
hidden_0:
fire count: 0, 0, 29, 6, 0, 86, 25, 0, 1, 0;
output:
fire count: 1, 1, 0, 0, 1, 2, 35, 1, 0, 1;
epoch=101 time=1658.749s cost=10.238833 Momentum=0.900000 lrate=0.00009901
train performance: 99.49%
===================weight value================
conv1:
weight:-1.949948, -1.118010, -1.142526;
bias  :0.000000 0.000000
conv2:
weight:-1.018895, -0.579071, 0.050862;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, -0.000000, -0.000000;
bias  :0.000000
output:
weight:-0.863444, -0.014057, 0.337786;
bias  :0.000000
===================test Result================
test 99.27%/99.47%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 34;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 10, 9, 0, 0;
pooling2:
fire count: 0, 0, 0, 1, 0, 0, 0, 0, 4, 2;
hidden_0:
fire count: 0, 1, 29, 7, 0, 82, 23, 0, 1, 0;
output:
fire count: 1, 1, 1, 0, 1, 1, 34, 1, 0, 1;
epoch=102 time=1643.381s cost=11.523666 Momentum=0.900000 lrate=0.00009853
train performance: 99.44%
===================weight value================
conv1:
weight:-1.957872, -1.142465, -1.171404;
bias  :0.000000 0.000000
conv2:
weight:-1.050557, -0.602110, 0.056363;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000017;
bias  :0.000000
output:
weight:-0.911066, -0.002107, 0.345904;
bias  :0.000000
===================test Result================
test 99.48%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 35;
conv2:
fire count: 0, 0, 0, 0, 0, 3, 15, 13, 0, 0;
pooling2:
fire count: 0, 0, 0, 3, 0, 0, 0, 0, 3, 3;
hidden_0:
fire count: 0, 1, 26, 5, 0, 84, 22, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 1, 33, 2, 0, 1;
epoch=103 time=1662.140s cost=8.991200 Momentum=0.900000 lrate=0.00009806
train performance: 99.58%
===================weight value================
conv1:
weight:-1.963356, -1.156134, -1.172349;
bias  :0.000000 0.000000
conv2:
weight:-1.050965, -0.617164, 0.050287;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, -0.000000;
bias  :0.000000
output:
weight:-0.928981, 0.009043, 0.345024;
bias  :0.000000
===================test Result================
test 99.38%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 1, 35;
conv2:
fire count: 0, 0, 0, 0, 0, 2, 12, 11, 0, 0;
pooling2:
fire count: 0, 0, 0, 2, 0, 0, 0, 0, 4, 2;
hidden_0:
fire count: 0, 1, 31, 3, 0, 86, 24, 0, 1, 0;
output:
fire count: 1, 1, 1, 0, 1, 2, 34, 2, 0, 0;
epoch=104 time=1631.977s cost=8.800117 Momentum=0.900000 lrate=0.00009759
train performance: 99.61%
===================weight value================
conv1:
weight:-1.956857, -1.153267, -1.171597;
bias  :0.000000 0.000000
conv2:
weight:-1.032230, -0.606831, 0.056681;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, -0.000000;
bias  :0.000000
output:
weight:-0.941955, -0.014030, 0.321149;
bias  :0.000000
===================test Result================
test 99.29%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 1, 36;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 4, 6, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 26, 5, 0, 82, 20, 0, 1, 0;
output:
fire count: 1, 1, 0, 0, 1, 1, 36, 2, 0, 1;
epoch=105 time=1638.384s cost=12.601533 Momentum=0.900000 lrate=0.00009713
train performance: 99.41%
===================weight value================
conv1:
weight:-1.978533, -1.150509, -1.178764;
bias  :0.000000 0.000000
conv2:
weight:-1.036626, -0.615550, 0.039679;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000021, -0.000000, 0.000002;
bias  :0.000000
output:
weight:-0.932153, 0.009723, 0.317886;
bias  :0.000000
===================test Result================
test 99.37%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 32;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 5, 6, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 30, 7, 0, 86, 21, 0, 1, 0;
output:
fire count: 1, 1, 1, 0, 1, 1, 34, 2, 0, 1;
epoch=106 time=1653.178s cost=11.146466 Momentum=0.900000 lrate=0.00009667
train performance: 99.44%
===================weight value================
conv1:
weight:-1.976038, -1.153000, -1.188908;
bias  :0.000000 0.000000
conv2:
weight:-1.044717, -0.618880, 0.050153;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000078, 0.000033, -0.000000;
bias  :0.000000
output:
weight:-0.957613, -0.001784, 0.309824;
bias  :0.000000
===================test Result================
test 99.24%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 32;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 5, 7, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 1, 1;
hidden_0:
fire count: 0, 0, 33, 6, 0, 85, 23, 0, 1, 0;
output:
fire count: 1, 1, 1, 0, 1, 1, 32, 0, 0, 1;
epoch=107 time=1636.516s cost=15.888233 Momentum=0.900000 lrate=0.00009623
train performance: 99.20%
===================weight value================
conv1:
weight:-1.949852, -1.099401, -1.161578;
bias  :0.000000 0.000000
conv2:
weight:-1.048101, -0.639518, 0.024391;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000001, -0.000001, -0.000000;
bias  :0.000000
output:
weight:-0.945373, -0.025106, 0.306013;
bias  :0.000000
===================test Result================
test 98.89%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 33;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 4, 6, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 32, 8, 0, 84, 20, 0, 1, 0;
output:
fire count: 1, 1, 0, 0, 1, 1, 32, 2, 0, 1;
epoch=108 time=1644.577s cost=15.512167 Momentum=0.900000 lrate=0.00009578
train performance: 99.22%
===================weight value================
conv1:
weight:-1.965215, -1.097128, -1.171021;
bias  :0.000000 0.000000
conv2:
weight:-0.999011, -0.615933, 0.016330;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, -0.000017, -0.000033;
bias  :0.000000
output:
weight:-0.938334, -0.036994, 0.327177;
bias  :0.000000
===================test Result================
test 98.98%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 31;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 8, 10, 0, 0;
pooling2:
fire count: 0, 0, 0, 1, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 33, 10, 0, 86, 21, 0, 1, 0;
output:
fire count: 1, 1, 1, 0, 1, 0, 31, 2, 0, 1;
epoch=109 time=1674.789s cost=9.505417 Momentum=0.900000 lrate=0.00009535
train performance: 99.56%
===================weight value================
conv1:
weight:-1.963659, -1.093054, -1.172676;
bias  :0.000000 0.000000
conv2:
weight:-0.988241, -0.648971, 0.007704;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000153, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.975046, -0.051776, 0.342776;
bias  :0.000000
===================test Result================
test 99.31%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 32;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 1, 6, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 26, 9, 0, 84, 18, 0, 1, 0;
output:
fire count: 1, 1, 0, 0, 1, 1, 34, 2, 0, 1;
epoch=110 time=1630.880s cost=10.553033 Momentum=0.900000 lrate=0.00009492
train performance: 99.49%
===================weight value================
conv1:
weight:-1.996580, -1.142118, -1.197969;
bias  :0.000000 0.000000
conv2:
weight:-1.004495, -0.641148, 0.048898;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.996710, -0.015394, 0.348664;
bias  :0.000000
===================test Result================
test 99.38%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 31;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 1, 4, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 32, 7, 0, 84, 18, 0, 1, 0;
output:
fire count: 1, 1, 1, 0, 1, 1, 35, 1, 0, 1;
epoch=111 time=1642.578s cost=11.738067 Momentum=0.900000 lrate=0.00009449
train performance: 99.44%
===================weight value================
conv1:
weight:-1.997890, -1.151647, -1.193521;
bias  :0.000000 0.000000
conv2:
weight:-0.972932, -0.645820, 0.040838;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000017, 0.000000, -0.000000;
bias  :0.000000
output:
weight:-0.989456, -0.019038, 0.345135;
bias  :0.000000
===================test Result================
test 99.31%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 33;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 1, 5, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 3, 1;
hidden_0:
fire count: 0, 0, 31, 8, 0, 86, 22, 0, 1, 0;
output:
fire count: 1, 1, 1, 0, 1, 1, 34, 0, 0, 1;
epoch=112 time=1653.752s cost=11.758717 Momentum=0.900000 lrate=0.00009407
train performance: 99.47%
===================weight value================
conv1:
weight:-2.006959, -1.145432, -1.164038;
bias  :0.000000 0.000000
conv2:
weight:-0.951176, -0.632019, 0.068301;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000003, 0.000000, -0.000000;
bias  :0.000000
output:
weight:-1.059374, -0.002115, 0.337197;
bias  :0.000000
===================test Result================
test 99.16%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 35;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 0, 5, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 2, 0;
hidden_0:
fire count: 0, 0, 32, 8, 0, 84, 23, 0, 1, 0;
output:
fire count: 1, 1, 1, 0, 1, 1, 36, 0, 1, 1;
epoch=113 time=1650.360s cost=14.276466 Momentum=0.900000 lrate=0.00009366
train performance: 99.29%
===================weight value================
conv1:
weight:-2.054100, -1.171881, -1.169973;
bias  :0.000000 0.000000
conv2:
weight:-0.937198, -0.609701, 0.086881;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, -0.000000, -0.000000;
bias  :0.000000
output:
weight:-1.042726, 0.004860, 0.336771;
bias  :0.000000
===================test Result================
test 99.02%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 33;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 0, 4, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 3, 0;
hidden_0:
fire count: 0, 0, 30, 6, 0, 85, 25, 0, 1, 0;
output:
fire count: 1, 1, 1, 1, 1, 1, 35, 0, 0, 0;
epoch=114 time=1644.020s cost=10.980534 Momentum=0.900000 lrate=0.00009325
train performance: 99.50%
===================weight value================
conv1:
weight:-2.022738, -1.159698, -1.179827;
bias  :0.000000 0.000000
conv2:
weight:-0.927719, -0.600220, 0.110487;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-1.029232, -0.015840, 0.367822;
bias  :0.000000
===================test Result================
test 99.16%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 33;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 0, 3, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 34, 3, 0, 89, 24, 0, 1, 0;
output:
fire count: 1, 1, 0, 1, 1, 2, 35, 1, 0, 0;
epoch=115 time=1646.887s cost=11.997000 Momentum=0.900000 lrate=0.00009285
train performance: 99.42%
===================weight value================
conv1:
weight:-2.002143, -1.139910, -1.174536;
bias  :0.000000 0.000000
conv2:
weight:-0.882720, -0.558710, 0.118376;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, -0.000081, -0.000005;
bias  :0.000000
output:
weight:-1.009176, -0.035911, 0.374092;
bias  :0.000000
===================test Result================
test 99.08%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 33;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 0, 4, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 30, 9, 0, 88, 18, 0, 1, 0;
output:
fire count: 1, 1, 1, 0, 1, 0, 33, 1, 0, 0;
epoch=116 time=1694.777s cost=18.264967 Momentum=0.900000 lrate=0.00009245
train performance: 99.04%
===================weight value================
conv1:
weight:-1.993793, -1.150746, -1.175066;
bias  :0.000000 0.000000
conv2:
weight:-0.869112, -0.567355, 0.103196;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, -0.000000;
bias  :0.000000
output:
weight:-1.085114, -0.008229, 0.357041;
bias  :0.000000
===================test Result================
test 98.88%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 34;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 0, 7, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 2, 0;
hidden_0:
fire count: 0, 0, 30, 3, 0, 83, 21, 0, 1, 0;
output:
fire count: 1, 1, 1, 0, 1, 0, 35, 0, 0, 1;
epoch=117 time=1692.893s cost=13.633067 Momentum=0.900000 lrate=0.00009206
train performance: 99.33%
===================weight value================
conv1:
weight:-1.988402, -1.141804, -1.158152;
bias  :0.000000 0.000000
conv2:
weight:-0.911281, -0.597510, 0.103861;
bias  :0.000000 0.000000
hidden_0:
weight:0.000001, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-1.104166, 0.003616, 0.365844;
bias  :0.000000
===================test Result================
test 99.02%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 35;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 0, 7, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 1, 0;
hidden_0:
fire count: 0, 0, 35, 5, 0, 87, 28, 0, 1, 0;
output:
fire count: 1, 1, 0, 0, 1, 0, 36, 0, 0, 1;
epoch=118 time=1690.714s cost=13.871200 Momentum=0.900000 lrate=0.00009167
train performance: 99.36%
===================weight value================
conv1:
weight:-2.022967, -1.159010, -1.153198;
bias  :0.000000 0.000000
conv2:
weight:-0.946964, -0.629528, 0.091127;
bias  :0.000000 0.000000
hidden_0:
weight:0.000079, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-1.107494, -0.003521, 0.358744;
bias  :0.000000
===================test Result================
test 99.08%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 1, 35;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 2, 11, 0, 0;
pooling2:
fire count: 0, 0, 0, 1, 0, 0, 0, 0, 2, 0;
hidden_0:
fire count: 0, 0, 34, 7, 0, 90, 32, 0, 1, 0;
output:
fire count: 0, 0, 0, 1, 1, 2, 34, 1, 0, 0;
epoch=119 time=1680.294s cost=15.055600 Momentum=0.900000 lrate=0.00009129
train performance: 99.29%
===================weight value================
conv1:
weight:-2.070791, -1.179236, -1.152848;
bias  :0.000000 0.000000
conv2:
weight:-0.927816, -0.579418, 0.154734;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, -0.000000, -0.000000;
bias  :0.000000
output:
weight:-1.084499, 0.012079, 0.402268;
bias  :0.000000
===================test Result================
test 98.96%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 34;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 0, 10, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 38, 1, 0, 90, 32, 0, 1, 0;
output:
fire count: 1, 1, 0, 0, 1, 1, 36, 1, 0, 1;
epoch=120 time=1696.776s cost=15.671166 Momentum=0.900000 lrate=0.00009091
train performance: 99.23%
===================weight value================
conv1:
weight:-2.012175, -1.138903, -1.167708;
bias  :0.000000 0.000000
conv2:
weight:-0.948684, -0.634767, 0.102080;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, -0.000037, 0.000000;
bias  :0.000000
output:
weight:-1.025276, -0.021542, 0.422550;
bias  :0.000000
===================test Result================
test 98.78%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 33;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 0, 9, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 44, 1, 0, 90, 30, 0, 1, 0;
output:
fire count: 1, 1, 0, 0, 1, 0, 37, 1, 0, 0;
epoch=121 time=1678.131s cost=14.815800 Momentum=0.900000 lrate=0.00009054
train performance: 99.28%
===================weight value================
conv1:
weight:-2.027502, -1.178930, -1.221624;
bias  :0.000000 0.000000
conv2:
weight:-0.940743, -0.626253, 0.116581;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, -0.000000;
bias  :0.000000
output:
weight:-1.080477, -0.009575, 0.409212;
bias  :0.000000
===================test Result================
test 99.02%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 31;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 0, 8, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 44, 3, 0, 90, 26, 0, 1, 0;
output:
fire count: 1, 1, 1, 0, 1, 1, 35, 2, 0, 0;
epoch=122 time=1683.079s cost=10.131400 Momentum=0.900000 lrate=0.00009017
train performance: 99.50%
===================weight value================
conv1:
weight:-2.025955, -1.189039, -1.252753;
bias  :0.000000 0.000000
conv2:
weight:-0.933897, -0.608819, 0.163347;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-1.108181, -0.026232, 0.414514;
bias  :0.000000
===================test Result================
test 99.29%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 30;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 0, 9, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 44, 3, 0, 91, 33, 0, 1, 0;
output:
fire count: 1, 1, 0, 0, 1, 0, 37, 1, 0, 0;
epoch=123 time=1680.015s cost=10.184967 Momentum=0.900000 lrate=0.00008980
train performance: 99.53%
===================weight value================
conv1:
weight:-2.035609, -1.209350, -1.267239;
bias  :0.000000 0.000000
conv2:
weight:-0.944050, -0.622344, 0.151119;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, -0.000000, 0.000000;
bias  :0.000000
output:
weight:-1.168342, -0.038635, 0.414857;
bias  :0.000000
===================test Result================
test 99.27%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 31;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 0, 10, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 42, 5, 0, 90, 27, 0, 0, 0;
output:
fire count: 0, 1, 1, 0, 1, 1, 35, 1, 0, 0;
epoch=124 time=1672.741s cost=8.313534 Momentum=0.900000 lrate=0.00008944
train performance: 99.60%
===================weight value================
conv1:
weight:-2.048578, -1.234782, -1.291031;
bias  :0.000000 0.000000
conv2:
weight:-0.947236, -0.626706, 0.161530;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, -0.000000, 0.000001;
bias  :0.000000
output:
weight:-1.181588, -0.035350, 0.427277;
bias  :0.000000
===================test Result================
test 99.23%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 31;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 0, 8, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 42, 4, 0, 90, 29, 0, 0, 0;
output:
fire count: 1, 0, 1, 0, 1, 1, 36, 0, 0, 0;
epoch=125 time=1653.539s cost=11.122017 Momentum=0.900000 lrate=0.00008909
train performance: 99.46%
===================weight value================
conv1:
weight:-2.029925, -1.217785, -1.302689;
bias  :0.000000 0.000000
conv2:
weight:-0.951198, -0.662847, 0.105361;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000002, 0.000018, 0.000001;
bias  :0.000000
output:
weight:-1.174928, -0.045618, 0.404661;
bias  :0.000000
===================test Result================
test 98.66%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 30;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 0, 6, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 43, 6, 0, 90, 28, 0, 1, 0;
output:
fire count: 1, 1, 1, 0, 1, 0, 35, 1, 0, 0;
epoch=126 time=1669.038s cost=12.039733 Momentum=0.900000 lrate=0.00008874
train performance: 99.39%
===================weight value================
conv1:
weight:-1.999548, -1.199025, -1.278001;
bias  :0.000000 0.000000
conv2:
weight:-0.949369, -0.662030, 0.121243;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000002, 0.000002, 0.000001;
bias  :0.000000
output:
weight:-1.216365, -0.054752, 0.407918;
bias  :0.000000
===================test Result================
test 99.26%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 33;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 0, 7, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 36, 9, 0, 90, 28, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 0, 36, 1, 0, 0;
epoch=127 time=1635.271s cost=8.325666 Momentum=0.900000 lrate=0.00008839
train performance: 99.61%
===================weight value================
conv1:
weight:-2.029616, -1.229798, -1.307311;
bias  :0.000000 0.000000
conv2:
weight:-0.931125, -0.667327, 0.118108;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-1.205243, -0.054952, 0.410510;
bias  :0.000000
===================test Result================
test 99.03%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 33;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 0, 7, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 39, 5, 0, 90, 29, 0, 1, 0;
output:
fire count: 0, 1, 1, 0, 1, 0, 35, 1, 0, 0;
epoch=128 time=1653.457s cost=12.362467 Momentum=0.900000 lrate=0.00008805
train performance: 99.37%
===================weight value================
conv1:
weight:-2.029349, -1.232631, -1.295677;
bias  :0.000000 0.000000
conv2:
weight:-0.954656, -0.682879, 0.123053;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000001;
bias  :0.000000
output:
weight:-1.227868, -0.070823, 0.421165;
bias  :0.000000
===================test Result================
test 99.06%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 33;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 1, 10, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 40, 3, 0, 90, 29, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 0, 37, 1, 0, 0;
epoch=129 time=1648.214s cost=10.532650 Momentum=0.900000 lrate=0.00008771
train performance: 99.50%
===================weight value================
conv1:
weight:-2.039758, -1.247736, -1.309105;
bias  :0.000000 0.000000
conv2:
weight:-0.986377, -0.710277, 0.120354;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000006, 0.000001;
bias  :0.000000
output:
weight:-1.277908, -0.080571, 0.436846;
bias  :0.000000
===================test Result================
test 99.17%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 32;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 2, 11, 0, 0;
pooling2:
fire count: 0, 0, 0, 1, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 39, 7, 0, 90, 30, 0, 1, 0;
output:
fire count: 0, 0, 0, 0, 1, 0, 36, 1, 0, 0;
epoch=130 time=1627.521s cost=20.355301 Momentum=0.900000 lrate=0.00008737
train performance: 98.93%
===================weight value================
conv1:
weight:-2.032598, -1.229655, -1.311211;
bias  :0.000000 0.000000
conv2:
weight:-0.984280, -0.708120, 0.102015;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, -0.000000, -0.000003;
bias  :0.000000
output:
weight:-1.218356, -0.068568, 0.457321;
bias  :0.000000
===================test Result================
test 98.44%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 30;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 3, 12, 0, 0;
pooling2:
fire count: 0, 0, 0, 1, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 43, 6, 0, 90, 28, 0, 1, 0;
output:
fire count: 0, 1, 1, 0, 1, 0, 34, 2, 0, 0;
epoch=131 time=1633.911s cost=9.467750 Momentum=0.900000 lrate=0.00008704
train performance: 99.58%
===================weight value================
conv1:
weight:-2.018421, -1.194385, -1.296313;
bias  :0.000000 0.000000
conv2:
weight:-1.020620, -0.721703, 0.096946;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, -0.000000, 0.000000;
bias  :0.000000
output:
weight:-1.261382, -0.057675, 0.458171;
bias  :0.000000
===================test Result================
test 98.92%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 28;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 11, 15, 0, 0;
pooling2:
fire count: 0, 0, 0, 2, 0, 0, 0, 0, 0, 1;
hidden_0:
fire count: 0, 1, 44, 10, 0, 90, 29, 0, 1, 0;
output:
fire count: 0, 1, 1, 0, 1, 0, 36, 2, 0, 0;
epoch=132 time=1646.182s cost=8.058967 Momentum=0.900000 lrate=0.00008671
train performance: 99.64%
===================weight value================
conv1:
weight:-2.009063, -1.189338, -1.296320;
bias  :0.000000 0.000000
conv2:
weight:-1.035115, -0.719576, 0.114573;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-1.290660, -0.056895, 0.452908;
bias  :0.000000
===================test Result================
test 99.24%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 28;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 7, 14, 0, 0;
pooling2:
fire count: 0, 0, 0, 1, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 39, 11, 0, 90, 27, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 0, 35, 2, 0, 0;
epoch=133 time=1633.288s cost=8.280800 Momentum=0.900000 lrate=0.00008639
train performance: 99.64%
===================weight value================
conv1:
weight:-2.010571, -1.180725, -1.291316;
bias  :0.000000 0.000000
conv2:
weight:-1.035224, -0.722827, 0.124396;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-1.288806, -0.047014, 0.461682;
bias  :0.000000
===================test Result================
test 98.95%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 26;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 9, 15, 0, 0;
pooling2:
fire count: 0, 0, 0, 2, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 40, 10, 0, 90, 28, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 0, 1, 34, 2, 0, 0;
epoch=134 time=1628.160s cost=10.349850 Momentum=0.900000 lrate=0.00008607
train performance: 99.50%
===================weight value================
conv1:
weight:-2.018055, -1.188944, -1.286903;
bias  :0.000000 0.000000
conv2:
weight:-1.050558, -0.731167, 0.128149;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-1.333854, -0.041867, 0.484136;
bias  :0.000000
===================test Result================
test 99.22%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 24;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 11, 17, 0, 0;
pooling2:
fire count: 0, 0, 0, 3, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 42, 9, 0, 90, 29, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 0, 36, 1, 0, 0;
epoch=135 time=1659.781s cost=11.199166 Momentum=0.900000 lrate=0.00008575
train performance: 99.47%
===================weight value================
conv1:
weight:-2.061593, -1.228448, -1.285205;
bias  :0.000000 0.000000
conv2:
weight:-1.039521, -0.730618, 0.137788;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, -0.000000, 0.000000;
bias  :0.000000
output:
weight:-1.380239, -0.025184, 0.476579;
bias  :0.000000
===================test Result================
test 99.06%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 27;
conv2:
fire count: 0, 0, 0, 0, 0, 5, 22, 23, 0, 0;
pooling2:
fire count: 0, 0, 0, 7, 0, 0, 0, 0, 1, 7;
hidden_0:
fire count: 0, 1, 37, 7, 0, 90, 27, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 0, 33, 1, 0, 0;
epoch=136 time=1677.951s cost=14.197317 Momentum=0.900000 lrate=0.00008544
train performance: 99.32%
===================weight value================
conv1:
weight:-2.020169, -1.206823, -1.279732;
bias  :0.000000 0.000000
conv2:
weight:-1.073920, -0.745637, 0.112381;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, -0.000001, 0.000002;
bias  :0.000000
output:
weight:-1.364792, -0.018056, 0.466413;
bias  :0.000000
===================test Result================
test 98.91%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 28;
conv2:
fire count: 0, 0, 0, 0, 0, 7, 23, 23, 0, 0;
pooling2:
fire count: 0, 0, 1, 7, 0, 0, 0, 0, 0, 7;
hidden_0:
fire count: 0, 1, 39, 2, 0, 90, 23, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 0, 35, 1, 0, 0;
epoch=137 time=1673.708s cost=9.411333 Momentum=0.900000 lrate=0.00008513
train performance: 99.59%
===================weight value================
conv1:
weight:-2.027156, -1.234595, -1.302824;
bias  :0.000000 0.000000
conv2:
weight:-1.093191, -0.787325, 0.074523;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-1.387579, -0.003252, 0.464142;
bias  :0.000000
===================test Result================
test 99.32%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 28;
conv2:
fire count: 0, 0, 0, 0, 0, 6, 21, 22, 0, 0;
pooling2:
fire count: 0, 0, 0, 6, 0, 0, 0, 0, 0, 5;
hidden_0:
fire count: 0, 1, 35, 2, 0, 90, 27, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 0, 33, 1, 0, 0;
epoch=138 time=1649.508s cost=12.528500 Momentum=0.900000 lrate=0.00008482
train performance: 99.43%
===================weight value================
conv1:
weight:-2.037355, -1.236005, -1.298145;
bias  :0.000000 0.000000
conv2:
weight:-1.087001, -0.784006, 0.094336;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, -0.000000;
bias  :0.000000
output:
weight:-1.376957, 0.026292, 0.482274;
bias  :0.000000
===================test Result================
test 99.07%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 28;
conv2:
fire count: 0, 0, 0, 0, 0, 5, 22, 23, 0, 0;
pooling2:
fire count: 0, 0, 0, 7, 0, 0, 0, 0, 0, 1;
hidden_0:
fire count: 0, 1, 42, 5, 0, 91, 28, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 0, 31, 2, 0, 0;
epoch=139 time=1737.294s cost=13.594500 Momentum=0.900000 lrate=0.00008452
train performance: 99.34%
===================weight value================
conv1:
weight:-2.008830, -1.227945, -1.311689;
bias  :0.000000 0.000000
conv2:
weight:-1.102282, -0.817373, 0.053694;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-1.402179, 0.007764, 0.509024;
bias  :0.000000
===================test Result================
test 99.21%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 27;
conv2:
fire count: 0, 0, 0, 0, 0, 9, 25, 24, 0, 0;
pooling2:
fire count: 0, 0, 1, 8, 0, 0, 0, 0, 0, 3;
hidden_0:
fire count: 0, 1, 45, 5, 0, 91, 30, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 1, 36, 1, 0, 0;
epoch=140 time=1729.741s cost=10.905383 Momentum=0.900000 lrate=0.00008422
train performance: 99.51%
===================weight value================
conv1:
weight:-2.032144, -1.250203, -1.317996;
bias  :0.000000 0.000000
conv2:
weight:-1.098992, -0.844526, 0.030630;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-1.415414, 0.025710, 0.491944;
bias  :0.000000
===================test Result================
test 99.13%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 27;
conv2:
fire count: 0, 0, 0, 0, 0, 3, 20, 22, 0, 0;
pooling2:
fire count: 0, 0, 0, 6, 0, 0, 0, 0, 0, 1;
hidden_0:
fire count: 0, 1, 41, 14, 0, 91, 23, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 1, 31, 1, 0, 0;
epoch=141 time=1677.083s cost=12.903283 Momentum=0.900000 lrate=0.00008392
train performance: 99.42%
===================weight value================
conv1:
weight:-2.061133, -1.253111, -1.295573;
bias  :0.000000 0.000000
conv2:
weight:-1.115878, -0.874561, 0.009119;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, -0.000000, 0.000001;
bias  :0.000000
output:
weight:-1.431688, 0.028495, 0.480738;
bias  :0.000000
===================test Result================
test 99.13%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 25;
conv2:
fire count: 0, 0, 0, 0, 0, 1, 16, 19, 0, 0;
pooling2:
fire count: 0, 0, 0, 5, 0, 0, 0, 0, 0, 1;
hidden_0:
fire count: 0, 1, 38, 11, 0, 91, 27, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 0, 33, 1, 0, 0;
epoch=142 time=1663.418s cost=23.208384 Momentum=0.900000 lrate=0.00008362
train performance: 98.83%
===================weight value================
conv1:
weight:-2.097174, -1.234303, -1.268946;
bias  :0.000000 0.000000
conv2:
weight:-1.143621, -0.939305, -0.052136;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, -0.000003, -0.000001;
bias  :0.000000
output:
weight:-1.446722, 0.047454, 0.526052;
bias  :0.000000
===================test Result================
test 98.37%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 24;
conv2:
fire count: 0, 0, 0, 0, 0, 3, 19, 21, 0, 0;
pooling2:
fire count: 0, 0, 0, 6, 0, 0, 0, 0, 0, 2;
hidden_0:
fire count: 0, 1, 48, 10, 0, 91, 27, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 0, 30, 1, 0, 0;
epoch=143 time=1723.220s cost=16.965483 Momentum=0.900000 lrate=0.00008333
train performance: 99.19%
===================weight value================
conv1:
weight:-2.065214, -1.196853, -1.265119;
bias  :0.000000 0.000000
conv2:
weight:-1.179283, -0.982381, -0.072712;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-1.439645, 0.033216, 0.516946;
bias  :0.000000
===================test Result================
test 98.81%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 27;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 15, 19, 0, 0;
pooling2:
fire count: 0, 0, 0, 4, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 39, 16, 0, 91, 19, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 0, 29, 2, 0, 0;
epoch=144 time=1690.436s cost=11.482300 Momentum=0.900000 lrate=0.00008305
train performance: 99.50%
===================weight value================
conv1:
weight:-2.068834, -1.210018, -1.295375;
bias  :0.000000 0.000000
conv2:
weight:-1.186240, -0.985859, -0.076400;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000054, 0.000018;
bias  :0.000000
output:
weight:-1.461562, 0.034970, 0.518379;
bias  :0.000000
===================test Result================
test 99.08%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 25;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 13, 16, 0, 0;
pooling2:
fire count: 0, 0, 0, 3, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 40, 19, 0, 91, 22, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 0, 31, 2, 0, 0;
epoch=145 time=1694.712s cost=13.683300 Momentum=0.900000 lrate=0.00008276
train performance: 99.33%
===================weight value================
conv1:
weight:-2.077518, -1.228360, -1.301656;
bias  :0.000000 0.000000
conv2:
weight:-1.220237, -1.004037, -0.062002;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000007;
bias  :0.000000
output:
weight:-1.536941, 0.054003, 0.510557;
bias  :0.000000
===================test Result================
test 99.27%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 24;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 14, 18, 0, 0;
pooling2:
fire count: 0, 0, 0, 4, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 40, 19, 0, 91, 26, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 0, 35, 1, 0, 0;
epoch=146 time=1674.265s cost=10.269466 Momentum=0.900000 lrate=0.00008248
train performance: 99.54%
===================weight value================
conv1:
weight:-2.070183, -1.198939, -1.283613;
bias  :0.000000 0.000000
conv2:
weight:-1.230182, -1.018978, -0.067594;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, -0.000000, 0.000000;
bias  :0.000000
output:
weight:-1.529367, 0.047932, 0.504164;
bias  :0.000000
===================test Result================
test 99.03%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 24;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 12, 15, 0, 0;
pooling2:
fire count: 0, 0, 0, 3, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 2, 37, 20, 0, 91, 25, 0, 1, 0;
output:
fire count: 0, 1, 1, 0, 1, 0, 31, 1, 0, 0;
epoch=147 time=1702.871s cost=10.148334 Momentum=0.900000 lrate=0.00008220
train performance: 99.54%
===================weight value================
conv1:
weight:-2.044346, -1.169945, -1.268219;
bias  :0.000000 0.000000
conv2:
weight:-1.233784, -1.027906, -0.077311;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, -0.000000, -0.000000;
bias  :0.000000
output:
weight:-1.562562, 0.045966, 0.503660;
bias  :0.000000
===================test Result================
test 99.18%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 26;
conv2:
fire count: 0, 0, 0, 0, 0, 1, 19, 21, 0, 0;
pooling2:
fire count: 0, 0, 0, 6, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 41, 14, 0, 91, 28, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 0, 34, 1, 0, 0;
epoch=148 time=1693.712s cost=9.166433 Momentum=0.900000 lrate=0.00008192
train performance: 99.59%
===================weight value================
conv1:
weight:-2.033746, -1.164097, -1.272290;
bias  :0.000000 0.000000
conv2:
weight:-1.253097, -1.055520, -0.079954;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, -0.000000, -0.000001;
bias  :0.000000
output:
weight:-1.564806, 0.036143, 0.493712;
bias  :0.000000
===================test Result================
test 99.35%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 27;
conv2:
fire count: 0, 0, 0, 0, 0, 1, 18, 21, 0, 0;
pooling2:
fire count: 0, 0, 0, 5, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 40, 13, 0, 91, 29, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 0, 35, 2, 0, 0;
epoch=149 time=1656.652s cost=10.779200 Momentum=0.900000 lrate=0.00008165
train performance: 99.51%
===================weight value================
conv1:
weight:-2.021512, -1.151562, -1.256347;
bias  :0.000000 0.000000
conv2:
weight:-1.268158, -1.083918, -0.101397;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, 0.000000, -0.000000;
bias  :0.000000
output:
weight:-1.542460, 0.026616, 0.480035;
bias  :0.000000
===================test Result================
test 99.19%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 27;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 13, 16, 0, 0;
pooling2:
fire count: 0, 0, 0, 3, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 34, 17, 0, 91, 26, 0, 1, 0;
output:
fire count: 0, 2, 0, 0, 1, 0, 33, 1, 0, 0;
epoch=150 time=1688.207s cost=10.455600 Momentum=0.900000 lrate=0.00008138
train performance: 99.53%
===================weight value================
conv1:
weight:-2.007920, -1.153765, -1.253405;
bias  :0.000000 0.000000
conv2:
weight:-1.283470, -1.123775, -0.104232;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, 0.000000, 0.000004;
bias  :0.000000
output:
weight:-1.564722, 0.042504, 0.510290;
bias  :0.000000
===================test Result================
test 99.35%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 29;
conv2:
fire count: 0, 0, 0, 0, 0, 3, 19, 19, 0, 0;
pooling2:
fire count: 0, 0, 0, 5, 0, 0, 0, 0, 0, 1;
hidden_0:
fire count: 0, 1, 35, 15, 0, 91, 28, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 0, 32, 2, 0, 0;
epoch=151 time=1701.675s cost=17.877550 Momentum=0.900000 lrate=0.00008111
train performance: 99.12%
===================weight value================
conv1:
weight:-2.007631, -1.151837, -1.277062;
bias  :0.000000 0.000000
conv2:
weight:-1.255308, -1.101827, -0.087510;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000001, -0.000000;
bias  :0.000000
output:
weight:-1.564680, 0.009808, 0.547820;
bias  :0.000000
===================test Result================
test 98.91%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 26;
conv2:
fire count: 0, 0, 0, 0, 0, 4, 19, 22, 0, 0;
pooling2:
fire count: 0, 0, 0, 6, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 39, 18, 0, 91, 37, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 1, 32, 1, 0, 1;
epoch=152 time=1789.247s cost=19.780216 Momentum=0.900000 lrate=0.00008085
train performance: 98.98%
===================weight value================
conv1:
weight:-1.990097, -1.169760, -1.310222;
bias  :0.000000 0.000000
conv2:
weight:-1.267929, -1.130512, -0.096639;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000005;
bias  :0.000000
output:
weight:-1.661971, 0.018953, 0.568700;
bias  :0.000000
===================test Result================
test 99.00%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 30;
conv2:
fire count: 0, 0, 0, 0, 0, 13, 27, 28, 0, 0;
pooling2:
fire count: 0, 0, 5, 10, 0, 0, 0, 0, 0, 5;
hidden_0:
fire count: 0, 1, 34, 4, 0, 91, 33, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 1, 33, 1, 0, 1;
epoch=153 time=1761.706s cost=10.592750 Momentum=0.900000 lrate=0.00008058
train performance: 99.50%
===================weight value================
conv1:
weight:-2.012343, -1.166251, -1.277524;
bias  :0.000000 0.000000
conv2:
weight:-1.246858, -1.125634, -0.092092;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, -0.000000, 0.000007;
bias  :0.000000
output:
weight:-1.671676, 0.015267, 0.555272;
bias  :0.000000
===================test Result================
test 99.29%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 29;
conv2:
fire count: 0, 0, 0, 0, 0, 11, 24, 26, 0, 0;
pooling2:
fire count: 0, 0, 3, 9, 0, 0, 0, 0, 0, 2;
hidden_0:
fire count: 0, 1, 35, 13, 0, 91, 32, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 1, 32, 1, 0, 1;
epoch=154 time=1747.468s cost=11.348250 Momentum=0.900000 lrate=0.00008032
train performance: 99.47%
===================weight value================
conv1:
weight:-2.028321, -1.186028, -1.278846;
bias  :0.000000 0.000000
conv2:
weight:-1.254940, -1.135636, -0.096385;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000004;
bias  :0.000000
output:
weight:-1.695074, 0.048307, 0.552892;
bias  :0.000000
===================test Result================
test 99.27%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 32;
conv2:
fire count: 0, 0, 0, 0, 0, 9, 23, 23, 0, 0;
pooling2:
fire count: 0, 0, 1, 8, 0, 0, 0, 0, 0, 1;
hidden_0:
fire count: 0, 1, 35, 15, 0, 91, 30, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 0, 31, 1, 0, 0;
epoch=155 time=1707.164s cost=16.386517 Momentum=0.900000 lrate=0.00008006
train performance: 99.17%
===================weight value================
conv1:
weight:-2.029087, -1.168910, -1.248491;
bias  :0.000000 0.000000
conv2:
weight:-1.238108, -1.115264, -0.067104;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000009;
bias  :0.000000
output:
weight:-1.697966, 0.015098, 0.514320;
bias  :0.000000
===================test Result================
test 99.27%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 26;
conv2:
fire count: 0, 0, 0, 0, 0, 4, 20, 23, 0, 0;
pooling2:
fire count: 0, 0, 0, 7, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 39, 17, 0, 91, 31, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 0, 32, 1, 0, 1;
epoch=156 time=1720.238s cost=16.513334 Momentum=0.900000 lrate=0.00007981
train performance: 99.19%
===================weight value================
conv1:
weight:-2.004559, -1.150100, -1.227364;
bias  :0.000000 0.000000
conv2:
weight:-1.218864, -1.092649, -0.050974;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-1.742235, 0.014252, 0.491551;
bias  :0.000000
===================test Result================
test 98.98%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 26;
conv2:
fire count: 0, 0, 0, 0, 0, 5, 20, 24, 0, 0;
pooling2:
fire count: 0, 0, 0, 7, 0, 0, 0, 0, 0, 1;
hidden_0:
fire count: 0, 1, 45, 12, 0, 91, 32, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 0, 32, 1, 0, 1;
epoch=157 time=1750.188s cost=11.998584 Momentum=0.900000 lrate=0.00007956
train performance: 99.48%
===================weight value================
conv1:
weight:-1.986108, -1.155344, -1.252864;
bias  :0.000000 0.000000
conv2:
weight:-1.226144, -1.098744, -0.048982;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000007;
bias  :0.000000
output:
weight:-1.776024, 0.024286, 0.499236;
bias  :0.000000
===================test Result================
test 99.24%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 28;
conv2:
fire count: 0, 0, 0, 0, 0, 2, 18, 23, 0, 0;
pooling2:
fire count: 0, 0, 0, 6, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 45, 17, 0, 92, 35, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 0, 30, 1, 0, 0;
epoch=158 time=1745.289s cost=9.616167 Momentum=0.900000 lrate=0.00007931
train performance: 99.62%
===================weight value================
conv1:
weight:-1.983903, -1.144319, -1.220620;
bias  :0.000000 0.000000
conv2:
weight:-1.224808, -1.110365, -0.053002;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000006, 0.000000, 0.000002;
bias  :0.000000
output:
weight:-1.784363, 0.040892, 0.496819;
bias  :0.000000
===================test Result================
test 99.25%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 30;
conv2:
fire count: 0, 0, 0, 0, 0, 4, 19, 23, 0, 0;
pooling2:
fire count: 0, 0, 0, 7, 0, 0, 0, 0, 0, 2;
hidden_0:
fire count: 0, 1, 45, 21, 0, 92, 31, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 1, 30, 1, 0, 0;
epoch=159 time=1768.505s cost=10.966383 Momentum=0.900000 lrate=0.00007906
train performance: 99.50%
===================weight value================
conv1:
weight:-1.984401, -1.117513, -1.188492;
bias  :0.000000 0.000000
conv2:
weight:-1.219944, -1.127937, -0.071871;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, -0.000000, 0.000002;
bias  :0.000000
output:
weight:-1.792547, 0.034385, 0.506363;
bias  :0.000000
===================test Result================
test 99.19%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 29;
conv2:
fire count: 0, 0, 0, 0, 0, 8, 21, 24, 0, 0;
pooling2:
fire count: 0, 0, 1, 8, 0, 0, 0, 0, 0, 2;
hidden_0:
fire count: 0, 1, 43, 19, 0, 91, 29, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 0, 32, 1, 0, 0;
epoch=160 time=1761.329s cost=10.774117 Momentum=0.900000 lrate=0.00007881
train performance: 99.53%
===================weight value================
conv1:
weight:-2.004725, -1.128988, -1.207147;
bias  :0.000000 0.000000
conv2:
weight:-1.207456, -1.109592, -0.062931;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000017;
bias  :0.000000
output:
weight:-1.802852, 0.046336, 0.517750;
bias  :0.000000
===================test Result================
test 99.24%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 27;
conv2:
fire count: 0, 0, 0, 0, 0, 6, 18, 22, 0, 0;
pooling2:
fire count: 0, 0, 1, 6, 0, 0, 0, 0, 0, 2;
hidden_0:
fire count: 0, 1, 42, 20, 0, 91, 30, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 1, 30, 1, 0, 0;
epoch=161 time=1726.235s cost=13.884784 Momentum=0.900000 lrate=0.00007857
train performance: 99.36%
===================weight value================
conv1:
weight:-2.020318, -1.148450, -1.224517;
bias  :0.000000 0.000000
conv2:
weight:-1.213693, -1.134562, -0.056129;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000002;
bias  :0.000000
output:
weight:-1.796453, 0.058575, 0.513253;
bias  :0.000000
===================test Result================
test 99.36%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 27;
conv2:
fire count: 0, 0, 0, 0, 0, 3, 17, 21, 0, 0;
pooling2:
fire count: 0, 0, 0, 5, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 44, 23, 0, 93, 28, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 0, 32, 1, 0, 0;
epoch=162 time=1726.906s cost=10.056383 Momentum=0.900000 lrate=0.00007833
train performance: 99.58%
===================weight value================
conv1:
weight:-2.019149, -1.126262, -1.219990;
bias  :0.000000 0.000000
conv2:
weight:-1.214232, -1.154322, -0.073089;
bias  :0.000000 0.000000
hidden_0:
weight:0.000003, 0.000004, -0.000010;
bias  :0.000000
output:
weight:-1.776929, 0.064418, 0.500926;
bias  :0.000000
===================test Result================
test 99.28%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 24;
conv2:
fire count: 0, 0, 0, 0, 0, 3, 17, 20, 0, 0;
pooling2:
fire count: 0, 0, 0, 5, 0, 0, 0, 0, 0, 1;
hidden_0:
fire count: 0, 1, 42, 22, 0, 93, 26, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 0, 34, 1, 0, 0;
epoch=163 time=1721.369s cost=8.146717 Momentum=0.900000 lrate=0.00007809
train performance: 99.65%
===================weight value================
conv1:
weight:-2.000071, -1.113622, -1.217402;
bias  :0.000000 0.000000
conv2:
weight:-1.210855, -1.160821, -0.081667;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, -0.000000, -0.000033;
bias  :0.000000
output:
weight:-1.798663, 0.057016, 0.493605;
bias  :0.000000
===================test Result================
test 99.29%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 25;
conv2:
fire count: 0, 0, 0, 0, 0, 5, 17, 21, 0, 0;
pooling2:
fire count: 0, 0, 0, 6, 0, 0, 0, 0, 0, 1;
hidden_0:
fire count: 0, 1, 39, 19, 0, 92, 26, 0, 2, 0;
output:
fire count: 0, 1, 0, 0, 1, 0, 32, 1, 0, 0;
epoch=164 time=1724.645s cost=10.902634 Momentum=0.900000 lrate=0.00007785
train performance: 99.48%
===================weight value================
conv1:
weight:-1.976204, -1.109041, -1.203543;
bias  :0.000000 0.000000
conv2:
weight:-1.221265, -1.164886, -0.083871;
bias  :0.000000 0.000000
hidden_0:
weight:0.000004, 0.000000, -0.000000;
bias  :0.000000
output:
weight:-1.854846, 0.073348, 0.503500;
bias  :0.000000
===================test Result================
test 99.05%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 28;
conv2:
fire count: 0, 0, 0, 0, 0, 6, 19, 22, 0, 0;
pooling2:
fire count: 0, 0, 0, 6, 0, 0, 0, 0, 0, 2;
hidden_0:
fire count: 0, 1, 42, 18, 0, 92, 29, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 0, 32, 1, 0, 0;
epoch=165 time=1721.041s cost=14.801900 Momentum=0.900000 lrate=0.00007762
train performance: 99.32%
===================weight value================
conv1:
weight:-2.003626, -1.120234, -1.218313;
bias  :0.000000 0.000000
conv2:
weight:-1.227759, -1.174748, -0.090031;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-1.859027, 0.065816, 0.501741;
bias  :0.000000
===================test Result================
test 99.00%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 26;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 12, 18, 0, 0;
pooling2:
fire count: 0, 0, 0, 3, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 43, 22, 0, 92, 24, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 1, 31, 1, 0, 0;
epoch=166 time=1721.401s cost=10.411800 Momentum=0.900000 lrate=0.00007738
train performance: 99.54%
===================weight value================
conv1:
weight:-1.975026, -1.094989, -1.228244;
bias  :0.000000 0.000000
conv2:
weight:-1.227810, -1.176314, -0.099705;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, -0.000000, -0.000000;
bias  :0.000000
output:
weight:-1.866561, 0.062325, 0.514581;
bias  :0.000000
===================test Result================
test 99.08%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 27;
conv2:
fire count: 0, 0, 0, 0, 0, 1, 14, 18, 0, 0;
pooling2:
fire count: 0, 0, 0, 4, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 48, 22, 0, 94, 29, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 0, 33, 1, 0, 0;
epoch=167 time=1711.866s cost=19.702299 Momentum=0.900000 lrate=0.00007715
train performance: 98.98%
===================weight value================
conv1:
weight:-1.984341, -1.103511, -1.206256;
bias  :0.000000 0.000000
conv2:
weight:-1.252586, -1.195405, -0.112128;
bias  :0.000000 0.000000
hidden_0:
weight:0.000056, -0.000000, -0.000000;
bias  :0.000000
output:
weight:-1.899704, 0.084170, 0.524337;
bias  :0.000000
===================test Result================
test 98.93%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 29;
conv2:
fire count: 0, 0, 0, 0, 0, 1, 14, 20, 0, 0;
pooling2:
fire count: 0, 0, 0, 4, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 42, 19, 0, 92, 28, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 0, 31, 0, 0, 1;
epoch=168 time=1616.773s cost=11.149400 Momentum=0.900000 lrate=0.00007692
train performance: 99.50%
===================weight value================
conv1:
weight:-1.982364, -1.084962, -1.177797;
bias  :0.000000 0.000000
conv2:
weight:-1.241693, -1.204750, -0.109702;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, -0.000000, 0.000000;
bias  :0.000000
output:
weight:-1.923956, 0.077855, 0.502624;
bias  :0.000000
===================test Result================
test 99.28%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 30;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 12, 18, 0, 0;
pooling2:
fire count: 0, 0, 0, 4, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 45, 17, 0, 93, 26, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 0, 34, 0, 0, 1;
epoch=169 time=1608.286s cost=8.554750 Momentum=0.900000 lrate=0.00007670
train performance: 99.62%
===================weight value================
conv1:
weight:-1.974566, -1.065681, -1.164111;
bias  :0.000000 0.000000
conv2:
weight:-1.245022, -1.222693, -0.130373;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000009, -0.000001, -0.000000;
bias  :0.000000
output:
weight:-1.947538, 0.056849, 0.507452;
bias  :0.000000
===================test Result================
test 99.08%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 29;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 9, 16, 0, 0;
pooling2:
fire count: 0, 0, 0, 2, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 48, 21, 0, 93, 29, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 0, 30, 1, 0, 0;
epoch=170 time=1593.442s cost=12.412950 Momentum=0.900000 lrate=0.00007647
train performance: 99.47%
===================weight value================
conv1:
weight:-1.992144, -1.059850, -1.170709;
bias  :0.000000 0.000000
conv2:
weight:-1.239636, -1.227012, -0.121813;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, -0.000000, -0.000000;
bias  :0.000000
output:
weight:-1.922495, 0.058029, 0.517613;
bias  :0.000000
===================test Result================
test 98.86%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 28;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 8, 16, 0, 0;
pooling2:
fire count: 0, 0, 0, 2, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 45, 21, 0, 96, 26, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 2, 1, 28, 1, 0, 0;
epoch=171 time=1646.035s cost=16.645767 Momentum=0.900000 lrate=0.00007625
train performance: 99.22%
===================weight value================
conv1:
weight:-1.991222, -1.065307, -1.165618;
bias  :0.000000 0.000000
conv2:
weight:-1.245896, -1.232689, -0.127034;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, -0.000000, -0.000000;
bias  :0.000000
output:
weight:-2.011982, 0.060834, 0.531259;
bias  :0.000000
===================test Result================
test 99.16%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 28;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 10, 18, 0, 0;
pooling2:
fire count: 0, 0, 0, 3, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 38, 22, 0, 93, 25, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 0, 31, 1, 0, 1;
epoch=172 time=1633.485s cost=10.195250 Momentum=0.900000 lrate=0.00007603
train performance: 99.56%
===================weight value================
conv1:
weight:-1.983377, -1.063432, -1.164783;
bias  :0.000000 0.000000
conv2:
weight:-1.248102, -1.236697, -0.130227;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, -0.000000, 0.000000;
bias  :0.000000
output:
weight:-2.026482, 0.070207, 0.515299;
bias  :0.000000
===================test Result================
test 99.35%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 28;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 9, 16, 0, 0;
pooling2:
fire count: 0, 0, 0, 2, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 44, 27, 0, 93, 28, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 0, 31, 0, 0, 1;
epoch=173 time=1670.611s cost=14.119083 Momentum=0.900000 lrate=0.00007581
train performance: 99.34%
===================weight value================
conv1:
weight:-1.942519, -1.058690, -1.162457;
bias  :0.000000 0.000000
conv2:
weight:-1.238154, -1.245236, -0.133745;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, 0.000001, 0.000000;
bias  :0.000000
output:
weight:-2.029429, 0.045949, 0.514434;
bias  :0.000000
===================test Result================
test 99.22%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 31;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 10, 15, 0, 0;
pooling2:
fire count: 0, 0, 0, 2, 0, 0, 0, 0, 0, 1;
hidden_0:
fire count: 0, 1, 47, 27, 0, 94, 31, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 0, 30, 0, 0, 1;
epoch=174 time=1643.545s cost=12.709850 Momentum=0.900000 lrate=0.00007559
train performance: 99.42%
===================weight value================
conv1:
weight:-1.942699, -1.048365, -1.172036;
bias  :0.000000 0.000000
conv2:
weight:-1.233390, -1.226879, -0.134575;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, -0.000000, -0.000000;
bias  :0.000000
output:
weight:-1.994564, 0.055341, 0.518946;
bias  :0.000000
===================test Result================
test 99.07%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 32;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 4, 12, 0, 0;
pooling2:
fire count: 0, 0, 0, 1, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 45, 28, 0, 94, 29, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 0, 30, 0, 0, 0;
epoch=175 time=1611.137s cost=11.862933 Momentum=0.900000 lrate=0.00007538
train performance: 99.50%
===================weight value================
conv1:
weight:-1.934314, -1.040490, -1.178080;
bias  :0.000000 0.000000
conv2:
weight:-1.251156, -1.245604, -0.161226;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, -0.000000, -0.000000;
bias  :0.000000
output:
weight:-1.963357, 0.066832, 0.520576;
bias  :0.000000
===================test Result================
test 99.01%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 31;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 3, 12, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 44, 24, 0, 97, 24, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 2, 0, 32, 0, 0, 0;
epoch=176 time=1624.048s cost=10.655316 Momentum=0.900000 lrate=0.00007516
train performance: 99.53%
===================weight value================
conv1:
weight:-1.956197, -1.073319, -1.221528;
bias  :0.000000 0.000000
conv2:
weight:-1.252413, -1.260043, -0.134713;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, -0.000000, 0.000000;
bias  :0.000000
output:
weight:-1.988300, 0.054047, 0.525805;
bias  :0.000000
===================test Result================
test 99.17%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 29;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 4, 12, 0, 0;
pooling2:
fire count: 0, 0, 0, 1, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 37, 22, 0, 96, 22, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 0, 33, 1, 0, 0;
epoch=177 time=1592.230s cost=9.197516 Momentum=0.900000 lrate=0.00007495
train performance: 99.63%
===================weight value================
conv1:
weight:-1.980103, -1.091556, -1.219846;
bias  :0.000000 0.000000
conv2:
weight:-1.278520, -1.283451, -0.126762;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, -0.000000, -0.000000;
bias  :0.000000
output:
weight:-1.982375, 0.037344, 0.500610;
bias  :0.000000
===================test Result================
test 99.28%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 29;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 3, 11, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 38, 23, 0, 93, 21, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 0, 32, 1, 0, 0;
epoch=178 time=1615.200s cost=12.209267 Momentum=0.900000 lrate=0.00007474
train performance: 99.44%
===================weight value================
conv1:
weight:-2.001627, -1.101078, -1.211272;
bias  :0.000000 0.000000
conv2:
weight:-1.279404, -1.302060, -0.159181;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000001, 0.000000;
bias  :0.000000
output:
weight:-1.964126, 0.035825, 0.502248;
bias  :0.000000
===================test Result================
test 99.21%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 30;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 10, 13, 0, 0;
pooling2:
fire count: 0, 0, 0, 2, 0, 0, 0, 0, 0, 1;
hidden_0:
fire count: 0, 2, 39, 21, 0, 93, 22, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 1, 31, 0, 0, 1;
epoch=179 time=1620.509s cost=8.678617 Momentum=0.900000 lrate=0.00007454
train performance: 99.62%
===================weight value================
conv1:
weight:-1.986879, -1.088971, -1.212212;
bias  :0.000000 0.000000
conv2:
weight:-1.293551, -1.310848, -0.148555;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, -0.000000, -0.000000;
bias  :0.000000
output:
weight:-1.965984, 0.031425, 0.512953;
bias  :0.000000
===================test Result================
test 99.26%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 31;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 8, 12, 0, 0;
pooling2:
fire count: 0, 0, 0, 1, 0, 0, 0, 0, 0, 1;
hidden_0:
fire count: 0, 1, 37, 20, 0, 92, 23, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 0, 30, 1, 0, 1;
epoch=180 time=1615.069s cost=11.543167 Momentum=0.900000 lrate=0.00007433
train performance: 99.48%
===================weight value================
conv1:
weight:-2.012607, -1.114064, -1.208889;
bias  :0.000000 0.000000
conv2:
weight:-1.299174, -1.294654, -0.123055;
bias  :0.000000 0.000000
hidden_0:
weight:0.000001, -0.000000, -0.000000;
bias  :0.000000
output:
weight:-1.962762, 0.055304, 0.506225;
bias  :0.000000
===================test Result================
test 99.11%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 33;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 12, 15, 1, 1;
pooling2:
fire count: 0, 0, 0, 2, 0, 0, 0, 0, 1, 6;
hidden_0:
fire count: 0, 1, 32, 14, 0, 92, 21, 0, 1, 0;
output:
fire count: 0, 1, 1, 0, 1, 0, 34, 0, 0, 1;
epoch=181 time=1624.932s cost=11.984000 Momentum=0.900000 lrate=0.00007412
train performance: 99.48%
===================weight value================
conv1:
weight:-2.019009, -1.102193, -1.188797;
bias  :0.000000 0.000000
conv2:
weight:-1.283843, -1.284900, -0.137053;
bias  :0.000000 0.000000
hidden_0:
weight:0.000035, 0.000019, 0.000000;
bias  :0.000000
output:
weight:-1.967476, 0.025825, 0.490775;
bias  :0.000000
===================test Result================
test 99.25%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 32;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 4, 11, 3, 1;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 2;
hidden_0:
fire count: 0, 1, 32, 16, 0, 92, 23, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 0, 33, 0, 0, 1;
epoch=182 time=1607.074s cost=13.555333 Momentum=0.900000 lrate=0.00007392
train performance: 99.38%
===================weight value================
conv1:
weight:-1.996306, -1.073641, -1.204971;
bias  :0.000000 0.000000
conv2:
weight:-1.292184, -1.278640, -0.136328;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, -0.000000, 0.000000;
bias  :0.000000
output:
weight:-1.945549, -0.031472, 0.501086;
bias  :0.000000
===================test Result================
test 99.20%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 31;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 3, 8, 1, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 1;
hidden_0:
fire count: 0, 1, 37, 24, 0, 92, 23, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 0, 1, 32, 1, 0, 1;
epoch=183 time=1607.828s cost=12.691283 Momentum=0.900000 lrate=0.00007372
train performance: 99.42%
===================weight value================
conv1:
weight:-1.990865, -1.059432, -1.217732;
bias  :0.000000 0.000000
conv2:
weight:-1.284055, -1.268329, -0.124066;
bias  :0.000000 0.000000
hidden_0:
weight:0.000003, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-1.927259, -0.065919, 0.506600;
bias  :0.000000
===================test Result================
test 99.23%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 30;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 1, 8, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 41, 26, 0, 93, 25, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 1, 30, 1, 0, 0;
epoch=184 time=1673.822s cost=10.778033 Momentum=0.900000 lrate=0.00007352
train performance: 99.50%
===================weight value================
conv1:
weight:-1.989371, -1.064293, -1.226365;
bias  :0.000000 0.000000
conv2:
weight:-1.282602, -1.265185, -0.116492;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-1.952129, -0.070769, 0.503778;
bias  :0.000000
===================test Result================
test 99.26%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 30;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 4, 11, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 38, 21, 0, 94, 21, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 2, 0, 33, 0, 0, 0;
epoch=185 time=1680.277s cost=13.901883 Momentum=0.900000 lrate=0.00007332
train performance: 99.33%
===================weight value================
conv1:
weight:-1.983516, -1.048772, -1.191140;
bias  :0.000000 0.000000
conv2:
weight:-1.290694, -1.273675, -0.133039;
bias  :0.000000 0.000000
hidden_0:
weight:0.000033, -0.000000, 0.000000;
bias  :0.000000
output:
weight:-1.975305, -0.086840, 0.521297;
bias  :0.000000
===================test Result================
test 99.22%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 29;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 7, 13, 1, 0;
pooling2:
fire count: 0, 0, 0, 1, 0, 0, 0, 0, 1, 3;
hidden_0:
fire count: 0, 1, 41, 24, 0, 93, 23, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 0, 31, 0, 0, 1;
epoch=186 time=1658.388s cost=12.478050 Momentum=0.900000 lrate=0.00007313
train performance: 99.47%
===================weight value================
conv1:
weight:-2.020800, -1.082663, -1.193625;
bias  :0.000000 0.000000
conv2:
weight:-1.287876, -1.251211, -0.130409;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000017, 0.000021;
bias  :0.000000
output:
weight:-1.980007, -0.079795, 0.525027;
bias  :0.000000
===================test Result================
test 99.23%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 29;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 5, 11, 0, 0;
pooling2:
fire count: 0, 0, 0, 1, 0, 0, 0, 0, 0, 1;
hidden_0:
fire count: 0, 1, 41, 26, 0, 92, 23, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 2, 0, 29, 1, 0, 1;
epoch=187 time=1650.622s cost=10.736917 Momentum=0.900000 lrate=0.00007293
train performance: 99.52%
===================weight value================
conv1:
weight:-2.055375, -1.102759, -1.203500;
bias  :0.000000 0.000000
conv2:
weight:-1.298666, -1.259967, -0.108649;
bias  :0.000000 0.000000
hidden_0:
weight:0.000020, 0.000000, 0.000082;
bias  :0.000000
output:
weight:-1.961912, -0.096368, 0.520885;
bias  :0.000000
===================test Result================
test 99.41%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 28;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 2, 9, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 38, 23, 0, 94, 26, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 0, 31, 1, 0, 0;
epoch=188 time=1693.090s cost=12.705317 Momentum=0.900000 lrate=0.00007274
train performance: 99.38%
===================weight value================
conv1:
weight:-2.030593, -1.082483, -1.180221;
bias  :0.000000 0.000000
conv2:
weight:-1.313851, -1.302892, -0.137568;
bias  :0.000000 0.000000
hidden_0:
weight:0.000004, 0.000000, 0.000083;
bias  :0.000000
output:
weight:-1.963628, -0.097475, 0.549460;
bias  :0.000000
===================test Result================
test 99.38%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 31;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 4, 10, 0, 0;
pooling2:
fire count: 0, 0, 0, 1, 0, 0, 0, 0, 0, 1;
hidden_0:
fire count: 0, 1, 38, 26, 0, 94, 24, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 0, 30, 1, 0, 1;
epoch=189 time=1688.273s cost=11.036117 Momentum=0.900000 lrate=0.00007255
train performance: 99.49%
===================weight value================
conv1:
weight:-2.001720, -1.056403, -1.152722;
bias  :0.000000 0.000000
conv2:
weight:-1.313134, -1.285998, -0.142788;
bias  :0.000000 0.000000
hidden_0:
weight:0.000005, -0.000000, 0.000007;
bias  :0.000000
output:
weight:-1.941284, -0.091829, 0.545659;
bias  :0.000000
===================test Result================
test 99.32%/99.48%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 31;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 6, 12, 0, 0;
pooling2:
fire count: 0, 0, 0, 1, 0, 0, 0, 0, 0, 1;
hidden_0:
fire count: 0, 1, 47, 23, 0, 96, 25, 0, 1, 0;
output:
fire count: 0, 1, 0, 0, 1, 0, 31, 1, 0, 1;
epoch=190 time=1680.998s cost=8.785067 Momentum=0.900000 lrate=0.00007236
train performance: 99.58%
===================weight value================
conv1:
weight:-2.004278, -1.082421, -1.183149;
bias  :0.000000 0.000000
conv2:
weight:-1.321808, -1.288309, -0.121831;
bias  :0.000000 0.000000
hidden_0:
weight:0.000004, 0.000003, -0.000000;
bias  :0.000000
output:
weight:-1.956184, -0.079640, 0.559171;
bias  :0.000000
===================test Result================
test 99.49%/99.49%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 32;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 4, 11, 1, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 1;
hidden_0:
fire count: 0, 1, 41, 24, 0, 96, 23, 0, 1, 0;
output:
fire count: 0, 2, 0, 0, 1, 0, 30, 1, 0, 0;
epoch=191 time=1660.944s cost=8.109783 Momentum=0.900000 lrate=0.00007217
train performance: 99.66%
===================weight value================
conv1:
weight:-2.005906, -1.082249, -1.166813;
bias  :0.000000 0.000000
conv2:
weight:-1.309110, -1.295594, -0.151635;
bias  :0.000000 0.000000
hidden_0:
weight:0.000002, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-1.958667, -0.082022, 0.537391;
bias  :0.000000
===================test Result================
test 99.38%/99.49%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 33;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 4, 10, 2, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 2;
hidden_0:
fire count: 0, 1, 38, 21, 0, 92, 21, 0, 1, 0;
output:
fire count: 0, 1, 1, 0, 1, 0, 32, 0, 0, 0;
epoch=192 time=1652.425s cost=10.432100 Momentum=0.900000 lrate=0.00007198
train performance: 99.51%
===================weight value================
conv1:
weight:-2.025695, -1.086554, -1.175781;
bias  :0.000000 0.000000
conv2:
weight:-1.306321, -1.286310, -0.126786;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000010, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-1.943079, -0.077551, 0.548228;
bias  :0.000000
===================test Result================
test 99.21%/99.49%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 32;
conv2:
fire count: 1, 0, 0, 0, 0, 0, 0, 7, 2, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 34, 19, 0, 92, 22, 0, 1, 0;
output:
fire count: 0, 1, 1, 0, 1, 0, 31, 1, 0, 0;
epoch=193 time=1688.830s cost=18.428883 Momentum=0.900000 lrate=0.00007180
train performance: 99.10%
===================weight value================
conv1:
weight:-2.031230, -1.092533, -1.179942;
bias  :0.000000 0.000000
conv2:
weight:-1.323541, -1.328569, -0.152808;
bias  :0.000000 0.000000
hidden_0:
weight:0.000001, -0.000000, -0.000000;
bias  :0.000000
output:
weight:-1.987045, -0.091473, 0.557728;
bias  :0.000000
===================test Result================
test 99.20%/99.49%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 30;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 4, 10, 3, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 2, 4;
hidden_0:
fire count: 0, 1, 40, 19, 0, 94, 19, 0, 1, 0;
output:
fire count: 0, 2, 0, 0, 1, 0, 30, 0, 0, 1;
epoch=194 time=1669.169s cost=10.615583 Momentum=0.900000 lrate=0.00007161
train performance: 99.53%
===================weight value================
conv1:
weight:-2.051159, -1.090374, -1.181057;
bias  :0.000000 0.000000
conv2:
weight:-1.316752, -1.309792, -0.147310;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, -0.000000, -0.000000;
bias  :0.000000
output:
weight:-1.978404, -0.099952, 0.551197;
bias  :0.000000
===================test Result================
test 99.34%/99.49%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 31;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 1, 9, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 1;
hidden_0:
fire count: 0, 1, 42, 22, 0, 97, 21, 0, 1, 0;
output:
fire count: 0, 1, 1, 0, 1, 0, 30, 0, 0, 0;
epoch=195 time=1653.866s cost=10.082033 Momentum=0.900000 lrate=0.00007143
train performance: 99.53%
===================weight value================
conv1:
weight:-2.028413, -1.056919, -1.151987;
bias  :0.000000 0.000000
conv2:
weight:-1.337211, -1.309541, -0.147528;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, -0.000000, 0.000000;
bias  :0.000000
output:
weight:-1.937737, -0.113132, 0.552641;
bias  :0.000000
===================test Result================
test 99.34%/99.49%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 30;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 5, 11, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 1;
hidden_0:
fire count: 0, 1, 45, 21, 0, 100, 22, 0, 1, 0;
output:
fire count: 0, 1, 1, 0, 1, 0, 30, 0, 0, 0;
epoch=196 time=1667.662s cost=8.630767 Momentum=0.900000 lrate=0.00007125
train performance: 99.63%
===================weight value================
conv1:
weight:-2.075338, -1.086985, -1.165854;
bias  :0.000000 0.000000
conv2:
weight:-1.332396, -1.317370, -0.142312;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, -0.000000, -0.000000;
bias  :0.000000
output:
weight:-1.974346, -0.100599, 0.549280;
bias  :0.000000
===================test Result================
test 99.34%/99.49%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 28;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 0, 9, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 38, 17, 0, 95, 20, 0, 1, 0;
output:
fire count: 0, 1, 1, 0, 1, 0, 32, 0, 0, 0;
epoch=197 time=1631.486s cost=12.458883 Momentum=0.900000 lrate=0.00007107
train performance: 99.38%
===================weight value================
conv1:
weight:-2.052999, -1.059921, -1.178551;
bias  :0.000000 0.000000
conv2:
weight:-1.320850, -1.290393, -0.126602;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, 0.000000, -0.000000;
bias  :0.000000
output:
weight:-1.961295, -0.106269, 0.541421;
bias  :0.000000
===================test Result================
test 99.22%/99.49%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 27;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 0, 9, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 43, 21, 0, 102, 22, 0, 1, 0;
output:
fire count: 0, 1, 1, 0, 1, 0, 30, 0, 0, 0;
epoch=198 time=1711.276s cost=11.298217 Momentum=0.900000 lrate=0.00007089
train performance: 99.51%
===================weight value================
conv1:
weight:-2.037655, -1.078874, -1.188204;
bias  :0.000000 0.000000
conv2:
weight:-1.318916, -1.302963, -0.138159;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, 0.000000, -0.000081;
bias  :0.000000
output:
weight:-1.992279, -0.113940, 0.574662;
bias  :0.000000
===================test Result================
test 99.42%/99.49%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 30;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 3, 11, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 1, 39, 21, 0, 103, 17, 0, 1, 0;
output:
fire count: 0, 1, 1, 0, 1, 0, 31, 0, 0, 1;
epoch=199 time=1695.842s cost=8.887816 Momentum=0.900000 lrate=0.00007071
train performance: 99.63%
===================weight value================
conv1:
weight:-2.074441, -1.100267, -1.174582;
bias  :0.000000 0.000000
conv2:
weight:-1.335482, -1.311466, -0.134500;
bias  :0.000000 0.000000
hidden_0:
weight:0.000001, -0.000015, -0.000036;
bias  :0.000000
output:
weight:-1.996768, -0.092629, 0.563641;
bias  :0.000000
===================test Result================
test 99.27%/99.49%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 31;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 4, 12, 0, 0;
pooling2:
fire count: 0, 0, 0, 1, 0, 0, 0, 0, 0, 1;
hidden_0:
fire count: 0, 1, 36, 22, 0, 94, 16, 0, 1, 0;
output:
fire count: 0, 1, 1, 0, 1, 0, 32, 0, 0, 1;
training time hours = 94.815071
