

*******************CONFIG*******************
Is Gradient Checking : 0
Allow Dynamic Threshold : 0
Has Boost Weight Train: 1
Use Effect Ratio      : 1
Use Optimizer         : adam
lambda                : 0.000000
beta                  : 0.000000
weight limit          : 8.000000
batch Size            : 1
channels              : 1
crop                  : -1
scale                 : 12.000000
rotation              : 12.000000
distortion            : 3.400000
imageShow             : 0
HORIZONTAL            : 0
Test_Epoch            : 200
White Noise           : 0.000000
Spike end time        : 400
Train data path       : NULL
Test data path        : NULL
Train samples         : 60000
Test samples          : 10000
Train samples per class : -1
Test samples per class  : -1


********data spiking Layer********
NAME          : data
INPUT_NEURONS : 784


********ConvSpiking layer********
NAME          : conv1
INPUT         : data
KERNEL_SIZE   : 5
KERNEL_AMOUNT : 16
PADDING       : 0
initW         : 0.500000
VTH           : 5.000000
T_REFRAC      : 2
TAU_M         : 64.000000
TAU_S         : 8.000000
refWeightPath : NULL
refOuputTrainPath  : NULL
refOutputTestPath  : NULL


*****Pooling Spiking layer*****
NAME          : pooling1
INPUT         : conv1
size          : 2
skip          : 2
VTH           : 2.000000
T_REFRAC      : 2
TAU_M         : 64.000000
TAU_S         : 8.000000
refOuputTrainPath  : NULL
refOutputTestPath  : NULL


********ConvSpiking layer********
NAME          : conv2
INPUT         : pooling1
KERNEL_SIZE   : 5
KERNEL_AMOUNT : 40
PADDING       : 0
initW         : 0.500000
VTH           : 12.000000
T_REFRAC      : 2
TAU_M         : 64.000000
TAU_S         : 8.000000
refWeightPath : NULL
refOuputTrainPath  : NULL
refOutputTestPath  : NULL


*****Pooling Spiking layer*****
NAME          : pooling2
INPUT         : conv2
size          : 2
skip          : 2
VTH           : 4.000000
T_REFRAC      : 2
TAU_M         : 64.000000
TAU_S         : 8.000000
refOuputTrainPath  : NULL
refOutputTestPath  : NULL


********SPIKING Layer********
NAME               : hidden_0
NUM_NEURONS        : 300
INPUT              : pooling2
VTH                : 10.000000
T_REFRAC           : 2
TAU_M              : 64.000000
TAU_S              : 8.000000
initW              : 1.000000
weightConnect      : 0
initType           : Bernoulli
weightPath         : NULL
lweightPath        : NULL
laterialType       : NULL
reservoirDim       : NULL
localInbStrength   : 0.000000
UNDESIRED_LEVEL    : 0.000000
DESIRED_LEVEL      : 0.000000
MARGIN             : 0.000000
refWeightPath      : NULL
refLWeightPath     : NULL
refOuputTrainPath  : NULL
refOutputTestPath  : NULL
ADD_BIAS           : 0
BIAS_FREQ          : 100000


********SPIKING Layer********
NAME               : output
NUM_NEURONS        : 10
INPUT              : hidden_0
VTH                : 5.000000
T_REFRAC           : 2
TAU_M              : 64.000000
TAU_S              : 8.000000
initW              : 1.000000
weightConnect      : 0
initType           : Bernoulli
weightPath         : NULL
lweightPath        : NULL
laterialType       : LOCAL_INHIBITION
reservoirDim       : NULL
localInbStrength   : 1.000000
UNDESIRED_LEVEL    : 5.000000
DESIRED_LEVEL      : 35.000000
MARGIN             : 5.000000
refWeightPath      : NULL
refLWeightPath     : NULL
refOuputTrainPath  : NULL
refOutputTestPath  : NULL
ADD_BIAS           : 0
BIAS_FREQ          : 100000





******************layer nexts start********************
layer            data:conv1 
layer           conv1:pooling1 
layer        pooling1:conv2 
layer           conv2:pooling2 
layer        pooling2:hidden_0 
layer        hidden_0:output 
layer          output:


******************layer nexts end********************
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
output:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
time spent on test : time=63.335s
correct is 980
epoch=0 time=1135.474s cost=91.417847 Momentum=0.900000 lrate=0.00100000
train performance: 95.20%
===================weight value================
conv1:
weight:0.243612, 0.282281, 0.112449;
bias  :0.000000 0.000000
conv2:
weight:-0.480401, -0.052998, -0.496275;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, 0.422233;
bias  :0.000000
===================test Result================
test 93.56%/93.56%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 5, 9;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 3, 13, 0, 12, 0, 0, 0;
output:
fire count: 0, 0, 1, 1, 1, 1, 36, 0, 1, 0;
epoch=1 time=962.513s cost=50.205685 Momentum=0.900000 lrate=0.00070711
train performance: 97.83%
===================weight value================
conv1:
weight:0.219499, 0.183945, -0.091611;
bias  :0.000000 0.000000
conv2:
weight:-0.521310, -0.203835, -0.682197;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, 0.119952;
bias  :0.000000
===================test Result================
test 98.21%/98.21%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 7, 2, 0, 12, 0, 5, 0;
output:
fire count: 1, 1, 5, 1, 1, 1, 31, 0, 2, 0;
epoch=2 time=1011.341s cost=34.985085 Momentum=0.900000 lrate=0.00057735
train performance: 98.44%
===================weight value================
conv1:
weight:0.301638, 0.210079, -0.081521;
bias  :0.000000 0.000000
conv2:
weight:-0.521310, -0.203835, -0.682197;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -0.077797;
bias  :0.000000
===================test Result================
test 98.39%/98.39%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 8, 7;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 1, 5, 0, 4, 0, 6, 0;
output:
fire count: 0, 2, 2, 0, 2, 1, 31, 0, 2, 0;
epoch=3 time=1116.107s cost=28.313833 Momentum=0.900000 lrate=0.00050000
train performance: 98.69%
===================weight value================
conv1:
weight:0.485356, 0.343960, 0.013999;
bias  :0.000000 0.000000
conv2:
weight:-0.562779, -0.194574, -0.686152;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -0.194978;
bias  :0.000000
===================test Result================
test 98.18%/98.39%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 3, 28, 31;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 1, 6, 0, 12, 0, 0, 0;
output:
fire count: 0, 1, 2, 1, 1, 0, 31, 0, 2, 1;
epoch=4 time=1576.283s cost=33.903732 Momentum=0.900000 lrate=0.00044721
train performance: 98.35%
===================weight value================
conv1:
weight:0.222140, 0.080164, -0.248550;
bias  :0.000000 0.000000
conv2:
weight:-0.520784, -0.080012, -0.647455;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -0.217459;
bias  :0.000000
===================test Result================
test 97.52%/98.39%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 7, 7;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 3, 4, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 1, 19, 0, 7, 0, 0, 0;
output:
fire count: 0, 0, 1, 0, 1, 1, 34, 0, 2, 1;
epoch=5 time=1197.961s cost=34.248417 Momentum=0.900000 lrate=0.00040825
train performance: 98.35%
===================weight value================
conv1:
weight:0.288938, 0.088735, -0.301733;
bias  :0.000000 0.000000
conv2:
weight:-0.426425, 0.018856, -0.318987;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -0.383825;
bias  :0.000000
===================test Result================
test 97.56%/98.39%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 4, 1;
conv2:
fire count: 0, 0, 1, 0, 0, 7, 12, 9, 0, 0;
pooling2:
fire count: 0, 0, 0, 2, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 3, 1, 0, 13, 0, 0, 0;
output:
fire count: 0, 1, 1, 1, 1, 1, 37, 1, 1, 1;
epoch=6 time=1157.391s cost=24.137434 Momentum=0.900000 lrate=0.00037796
train performance: 98.85%
===================weight value================
conv1:
weight:0.346840, 0.092442, -0.323204;
bias  :0.000000 0.000000
conv2:
weight:-0.425520, 0.179282, -0.183198;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -0.439814;
bias  :0.000000
===================test Result================
test 98.62%/98.62%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 18, 18;
conv2:
fire count: 0, 0, 0, 0, 0, 6, 11, 11, 0, 0;
pooling2:
fire count: 0, 0, 0, 3, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 1, 6, 0, 13, 0, 0, 0;
output:
fire count: 0, 1, 1, 1, 1, 1, 36, 0, 2, 1;
epoch=7 time=1144.251s cost=21.756817 Momentum=0.900000 lrate=0.00035355
train performance: 98.98%
===================weight value================
conv1:
weight:0.181610, -0.096577, -0.486508;
bias  :0.000000 0.000000
conv2:
weight:-0.451021, 0.220578, -0.097712;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -0.495601;
bias  :0.000000
===================test Result================
test 98.58%/98.62%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 13, 7;
conv2:
fire count: 0, 0, 0, 0, 0, 3, 11, 13, 0, 1;
pooling2:
fire count: 0, 0, 0, 4, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 4, 1, 0, 18, 0, 0, 0;
output:
fire count: 0, 1, 2, 1, 1, 1, 31, 0, 2, 1;
epoch=8 time=1128.877s cost=23.034134 Momentum=0.900000 lrate=0.00033333
train performance: 98.93%
===================weight value================
conv1:
weight:0.173959, -0.117934, -0.508698;
bias  :0.000000 0.000000
conv2:
weight:-0.652338, 0.041962, -0.289090;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -0.566694;
bias  :0.000000
===================test Result================
test 98.69%/98.69%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 8, 5;
conv2:
fire count: 0, 0, 0, 0, 0, 0, 12, 12, 0, 1;
pooling2:
fire count: 0, 0, 0, 3, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 1, 1, 0, 8, 0, 0, 0;
output:
fire count: 0, 1, 1, 1, 1, 2, 34, 0, 2, 1;
epoch=9 time=1159.825s cost=21.045784 Momentum=0.900000 lrate=0.00031623
train performance: 99.04%
===================weight value================
conv1:
weight:0.244242, -0.100920, -0.531490;
bias  :0.000000 0.000000
conv2:
weight:-0.733457, -0.024478, -0.219804;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -0.623429;
bias  :0.000000
===================test Result================
test 98.99%/98.99%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 11, 9;
conv2:
fire count: 0, 0, 0, 0, 0, 3, 15, 14, 0, 0;
pooling2:
fire count: 0, 0, 0, 6, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 4, 6, 0, 11, 0, 1, 0;
output:
fire count: 0, 1, 1, 1, 1, 2, 28, 0, 3, 1;
epoch=10 time=1314.349s cost=22.236666 Momentum=0.900000 lrate=0.00030151
train performance: 98.94%
===================weight value================
conv1:
weight:0.355746, 0.003215, -0.471119;
bias  :0.000000 0.000000
conv2:
weight:-0.629275, 0.072236, -0.144495;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -0.644761;
bias  :0.000000
===================test Result================
test 98.60%/98.99%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 9, 33, 33;
conv2:
fire count: 0, 0, 0, 0, 0, 15, 20, 13, 0, 0;
pooling2:
fire count: 0, 0, 5, 5, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 1, 0, 0, 16, 0, 3, 0;
output:
fire count: 2, 1, 14, 1, 3, 1, 19, 0, 4, 1;
epoch=11 time=1470.026s cost=22.788866 Momentum=0.900000 lrate=0.00028868
train performance: 98.87%
===================weight value================
conv1:
weight:0.295440, -0.036996, -0.481283;
bias  :0.000000 0.000000
conv2:
weight:-0.639907, 0.082016, -0.137871;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -0.703447;
bias  :0.000000
===================test Result================
test 99.17%/99.17%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 18, 42, 39;
conv2:
fire count: 0, 0, 0, 0, 2, 19, 21, 14, 0, 0;
pooling2:
fire count: 0, 0, 7, 5, 0, 0, 0, 0, 4, 0;
hidden_0:
fire count: 0, 0, 0, 0, 3, 0, 14, 0, 1, 0;
output:
fire count: 0, 1, 1, 1, 1, 1, 32, 1, 3, 1;
epoch=12 time=1504.455s cost=19.469917 Momentum=0.900000 lrate=0.00027735
train performance: 99.02%
===================weight value================
conv1:
weight:0.331266, -0.048977, -0.545386;
bias  :0.000000 0.000000
conv2:
weight:-0.617738, 0.131487, -0.113734;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -0.685093;
bias  :0.000000
===================test Result================
test 98.36%/99.17%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 10, 36, 35;
conv2:
fire count: 0, 0, 0, 0, 0, 18, 20, 10, 0, 2;
pooling2:
fire count: 0, 0, 6, 4, 0, 0, 0, 0, 4, 0;
hidden_0:
fire count: 0, 0, 0, 0, 2, 0, 23, 0, 7, 0;
output:
fire count: 0, 0, 12, 2, 1, 2, 24, 0, 1, 1;
epoch=13 time=1510.862s cost=17.700899 Momentum=0.900000 lrate=0.00026726
train performance: 99.10%
===================weight value================
conv1:
weight:0.307056, -0.076929, -0.566129;
bias  :0.000000 0.000000
conv2:
weight:-0.690285, 0.152951, -0.013215;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, 0.000000, -0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -0.735669;
bias  :0.000000
===================test Result================
test 99.28%/99.28%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 10, 35, 36;
conv2:
fire count: 0, 2, 0, 0, 2, 26, 28, 14, 1, 4;
pooling2:
fire count: 0, 0, 12, 8, 0, 6, 1, 0, 7, 4;
hidden_0:
fire count: 0, 0, 0, 0, 9, 0, 20, 0, 5, 0;
output:
fire count: 0, 0, 1, 1, 1, 2, 33, 1, 2, 1;
epoch=14 time=1441.708s cost=21.794901 Momentum=0.900000 lrate=0.00025820
train performance: 98.85%
===================weight value================
conv1:
weight:0.332800, -0.063268, -0.565780;
bias  :0.000000 0.000000
conv2:
weight:-0.709423, 0.177109, 0.019661;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -0.787302;
bias  :0.000000
===================test Result================
test 98.60%/99.28%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 11, 36, 36;
conv2:
fire count: 0, 6, 2, 0, 9, 29, 27, 11, 3, 5;
pooling2:
fire count: 0, 0, 15, 7, 0, 9, 5, 0, 8, 9;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 17, 0, 8, 0;
output:
fire count: 0, 0, 1, 1, 1, 1, 34, 0, 2, 2;
epoch=15 time=1379.457s cost=16.064800 Momentum=0.900000 lrate=0.00025000
train performance: 99.17%
===================weight value================
conv1:
weight:0.306223, -0.063920, -0.516921;
bias  :0.000000 0.000000
conv2:
weight:-0.750029, 0.202052, 0.107936;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -0.803185;
bias  :0.000000
===================test Result================
test 99.23%/99.28%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 14, 40, 39;
conv2:
fire count: 0, 5, 2, 2, 16, 33, 31, 15, 3, 6;
pooling2:
fire count: 0, 2, 19, 9, 1, 13, 7, 0, 10, 11;
hidden_0:
fire count: 0, 0, 0, 0, 1, 0, 11, 0, 6, 0;
output:
fire count: 0, 1, 1, 1, 1, 1, 34, 1, 1, 2;
epoch=16 time=1388.628s cost=13.471867 Momentum=0.900000 lrate=0.00024254
train performance: 99.33%
===================weight value================
conv1:
weight:0.287063, -0.115556, -0.593333;
bias  :0.000000 0.000000
conv2:
weight:-0.760202, 0.206474, 0.119191;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -0.810889;
bias  :0.000000
===================test Result================
test 98.82%/99.28%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 8, 35, 34;
conv2:
fire count: 0, 6, 5, 3, 12, 29, 29, 14, 4, 9;
pooling2:
fire count: 2, 2, 16, 9, 2, 10, 7, 0, 7, 9;
hidden_0:
fire count: 0, 0, 0, 0, 3, 0, 18, 0, 9, 0;
output:
fire count: 0, 1, 1, 1, 1, 1, 32, 0, 1, 2;
epoch=17 time=1400.832s cost=16.269516 Momentum=0.900000 lrate=0.00023570
train performance: 99.20%
===================weight value================
conv1:
weight:0.205372, -0.170072, -0.591347;
bias  :0.000000 0.000000
conv2:
weight:-0.759250, 0.162634, 0.131726;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -0.818376;
bias  :0.000000
===================test Result================
test 98.99%/99.28%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 11, 37, 35;
conv2:
fire count: 0, 5, 7, 8, 16, 28, 27, 11, 4, 10;
pooling2:
fire count: 1, 6, 16, 7, 2, 11, 6, 0, 8, 9;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 4, 0, 4, 0;
output:
fire count: 0, 1, 1, 0, 1, 1, 33, 0, 2, 2;
epoch=18 time=1365.948s cost=14.374084 Momentum=0.900000 lrate=0.00022942
train performance: 99.33%
===================weight value================
conv1:
weight:0.220398, -0.145512, -0.570705;
bias  :0.000000 0.000000
conv2:
weight:-0.834084, 0.096474, 0.100261;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -0.825664;
bias  :0.000000
===================test Result================
test 99.15%/99.28%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 11, 38, 37;
conv2:
fire count: 0, 2, 3, 5, 12, 24, 23, 7, 1, 5;
pooling2:
fire count: 0, 3, 13, 4, 0, 8, 1, 0, 6, 5;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 6, 0, 6, 0;
output:
fire count: 0, 1, 1, 0, 1, 1, 35, 0, 2, 2;
epoch=19 time=1354.271s cost=18.659100 Momentum=0.900000 lrate=0.00022361
train performance: 99.06%
===================weight value================
conv1:
weight:0.181174, -0.189306, -0.608379;
bias  :0.000000 0.000000
conv2:
weight:-0.801013, 0.150281, 0.133107;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -0.792491;
bias  :0.000000
===================test Result================
test 98.69%/99.28%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 10, 36, 34;
conv2:
fire count: 0, 3, 5, 4, 7, 21, 24, 12, 1, 8;
pooling2:
fire count: 0, 2, 10, 6, 0, 5, 3, 0, 5, 5;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 11, 0, 10, 0;
output:
fire count: 0, 1, 9, 1, 1, 1, 22, 0, 2, 1;
epoch=20 time=1348.028s cost=15.036117 Momentum=0.900000 lrate=0.00021822
train performance: 99.27%
===================weight value================
conv1:
weight:0.193102, -0.166754, -0.589498;
bias  :0.000000 0.000000
conv2:
weight:-0.808343, 0.135763, 0.161444;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -0.799422;
bias  :0.000000
===================test Result================
test 99.21%/99.28%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 12, 38, 36;
conv2:
fire count: 0, 5, 10, 11, 17, 30, 30, 14, 3, 10;
pooling2:
fire count: 1, 8, 18, 8, 3, 13, 7, 0, 11, 12;
hidden_0:
fire count: 0, 0, 0, 0, 2, 0, 9, 0, 3, 0;
output:
fire count: 0, 1, 1, 1, 1, 2, 30, 0, 2, 1;
epoch=21 time=1346.099s cost=15.383333 Momentum=0.900000 lrate=0.00021320
train performance: 99.29%
===================weight value================
conv1:
weight:0.094884, -0.273458, -0.683152;
bias  :0.000000 0.000000
conv2:
weight:-0.848412, 0.136178, 0.161492;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -0.807749;
bias  :0.000000
===================test Result================
test 99.15%/99.28%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 11, 36, 34;
conv2:
fire count: 0, 3, 6, 7, 12, 25, 26, 11, 1, 6;
pooling2:
fire count: 0, 4, 14, 6, 0, 9, 3, 0, 8, 8;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 9, 0, 11, 0;
output:
fire count: 0, 1, 1, 1, 1, 2, 27, 0, 2, 1;
epoch=22 time=1292.784s cost=18.241917 Momentum=0.900000 lrate=0.00020851
train performance: 99.10%
===================weight value================
conv1:
weight:0.137131, -0.239374, -0.667801;
bias  :0.000000 0.000000
conv2:
weight:-0.873534, 0.128522, 0.170561;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -0.827616;
bias  :0.000000
===================test Result================
test 98.43%/99.28%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 15, 40, 37;
conv2:
fire count: 0, 4, 8, 10, 18, 32, 32, 14, 3, 7;
pooling2:
fire count: 0, 7, 19, 8, 1, 16, 7, 0, 12, 11;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 17, 0, 2, 0;
output:
fire count: 0, 1, 1, 1, 1, 1, 21, 0, 2, 2;
epoch=23 time=1393.291s cost=12.404433 Momentum=0.900000 lrate=0.00020412
train performance: 99.43%
===================weight value================
conv1:
weight:0.095035, -0.268263, -0.674072;
bias  :0.000000 0.000000
conv2:
weight:-0.921411, 0.104907, 0.144333;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -0.827616;
bias  :0.000000
===================test Result================
test 98.99%/99.28%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 17, 43, 37;
conv2:
fire count: 0, 2, 5, 8, 18, 32, 31, 13, 0, 5;
pooling2:
fire count: 0, 5, 19, 8, 0, 14, 6, 0, 12, 9;
hidden_0:
fire count: 0, 0, 0, 0, 1, 0, 11, 0, 8, 0;
output:
fire count: 0, 1, 1, 1, 1, 3, 26, 0, 2, 2;
epoch=24 time=1378.628s cost=19.174450 Momentum=0.900000 lrate=0.00020000
train performance: 99.06%
===================weight value================
conv1:
weight:0.066019, -0.301333, -0.709879;
bias  :0.000000 0.000000
conv2:
weight:-0.895368, 0.138178, 0.156567;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -0.846680;
bias  :0.000000
===================test Result================
test 98.73%/99.28%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 12, 36, 33;
conv2:
fire count: 0, 2, 4, 5, 11, 27, 27, 9, 0, 4;
pooling2:
fire count: 0, 2, 14, 5, 0, 11, 3, 0, 8, 6;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 19, 0, 7, 0;
output:
fire count: 0, 1, 1, 1, 1, 2, 30, 0, 2, 2;
epoch=25 time=1365.299s cost=13.524417 Momentum=0.900000 lrate=0.00019612
train performance: 99.33%
===================weight value================
conv1:
weight:0.066571, -0.277278, -0.654986;
bias  :0.000000 0.000000
conv2:
weight:-0.876095, 0.121597, 0.104458;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -0.852909;
bias  :0.000000
===================test Result================
test 99.22%/99.28%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 17, 41, 36;
conv2:
fire count: 0, 0, 0, 2, 11, 26, 25, 8, 0, 0;
pooling2:
fire count: 0, 0, 13, 4, 0, 8, 2, 0, 6, 1;
hidden_0:
fire count: 0, 0, 0, 0, 2, 0, 9, 0, 16, 0;
output:
fire count: 0, 1, 0, 0, 1, 2, 31, 1, 2, 2;
epoch=26 time=1332.843s cost=12.822300 Momentum=0.900000 lrate=0.00019245
train performance: 99.37%
===================weight value================
conv1:
weight:-0.017514, -0.355502, -0.711133;
bias  :0.000000 0.000000
conv2:
weight:-0.863600, 0.138376, 0.107739;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -0.859022;
bias  :0.000000
===================test Result================
test 99.17%/99.28%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 15, 40, 34;
conv2:
fire count: 0, 0, 0, 0, 7, 24, 24, 7, 0, 0;
pooling2:
fire count: 0, 0, 11, 4, 0, 5, 1, 0, 2, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 8, 0, 17, 0;
output:
fire count: 0, 1, 1, 0, 1, 3, 30, 0, 1, 2;
epoch=27 time=1333.506s cost=18.013500 Momentum=0.900000 lrate=0.00018898
train performance: 99.15%
===================weight value================
conv1:
weight:-0.030182, -0.383245, -0.750810;
bias  :0.000000 0.000000
conv2:
weight:-0.798084, 0.183822, 0.110474;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -0.881201;
bias  :0.000000
===================test Result================
test 99.04%/99.28%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 14, 39, 31;
conv2:
fire count: 0, 0, 0, 0, 4, 21, 21, 5, 0, 0;
pooling2:
fire count: 0, 0, 8, 2, 0, 5, 0, 0, 2, 0;
hidden_0:
fire count: 0, 0, 0, 0, 2, 0, 7, 0, 15, 0;
output:
fire count: 0, 1, 1, 0, 1, 2, 34, 0, 2, 1;
epoch=28 time=1309.549s cost=13.884367 Momentum=0.900000 lrate=0.00018570
train performance: 99.33%
===================weight value================
conv1:
weight:-0.035204, -0.382159, -0.756104;
bias  :0.000000 0.000000
conv2:
weight:-0.808992, 0.129997, 0.055951;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -0.890407;
bias  :0.000000
===================test Result================
test 99.36%/99.36%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 14, 38, 32;
conv2:
fire count: 0, 0, 0, 0, 1, 17, 16, 1, 0, 0;
pooling2:
fire count: 0, 0, 4, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 4, 0, 12, 0;
output:
fire count: 0, 1, 1, 2, 1, 4, 33, 0, 2, 1;
epoch=29 time=1316.073s cost=12.669467 Momentum=0.900000 lrate=0.00018257
train performance: 99.42%
===================weight value================
conv1:
weight:-0.034297, -0.375722, -0.758203;
bias  :0.000000 0.000000
conv2:
weight:-0.826038, 0.127155, 0.029178;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -0.890416;
bias  :0.000000
===================test Result================
test 99.34%/99.36%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 11, 35, 30;
conv2:
fire count: 0, 0, 0, 0, 1, 15, 14, 1, 0, 0;
pooling2:
fire count: 0, 0, 2, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 1, 0, 4, 0, 13, 0;
output:
fire count: 0, 1, 1, 1, 1, 2, 35, 0, 1, 1;
epoch=30 time=1278.161s cost=14.844767 Momentum=0.900000 lrate=0.00017961
train performance: 99.27%
===================weight value================
conv1:
weight:-0.061190, -0.400339, -0.784297;
bias  :0.000000 0.000000
conv2:
weight:-0.805757, 0.117675, -0.008334;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -0.911627;
bias  :0.000000
===================test Result================
test 99.21%/99.36%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 11, 34, 27;
conv2:
fire count: 0, 0, 0, 0, 0, 10, 8, 0, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 4, 0, 10, 0, 10, 0;
output:
fire count: 0, 1, 0, 1, 1, 2, 36, 1, 2, 1;
epoch=31 time=1328.566s cost=12.121134 Momentum=0.900000 lrate=0.00017678
train performance: 99.45%
===================weight value================
conv1:
weight:-0.074729, -0.409628, -0.787074;
bias  :0.000000 0.000000
conv2:
weight:-0.839534, 0.081483, -0.001632;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -0.917242;
bias  :0.000000
===================test Result================
test 99.19%/99.36%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 14, 38, 29;
conv2:
fire count: 0, 0, 0, 0, 4, 14, 12, 0, 0, 0;
pooling2:
fire count: 0, 0, 1, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 6, 0, 4, 0, 11, 0;
output:
fire count: 0, 1, 1, 1, 1, 2, 36, 1, 1, 2;
epoch=32 time=1374.540s cost=10.615817 Momentum=0.900000 lrate=0.00017408
train performance: 99.54%
===================weight value================
conv1:
weight:-0.112232, -0.473062, -0.875616;
bias  :0.000000 0.000000
conv2:
weight:-0.861853, 0.057483, -0.011507;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -0.926502;
bias  :0.000000
===================test Result================
test 99.36%/99.36%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 14, 38, 30;
conv2:
fire count: 0, 0, 0, 0, 3, 12, 9, 0, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 5, 0, 5, 0, 10, 0;
output:
fire count: 0, 1, 2, 1, 1, 2, 33, 1, 1, 1;
epoch=33 time=1342.472s cost=13.591066 Momentum=0.900000 lrate=0.00017150
train performance: 99.40%
===================weight value================
conv1:
weight:-0.098788, -0.463395, -0.901558;
bias  :0.000000 0.000000
conv2:
weight:-0.813039, 0.047516, -0.029612;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -0.932665;
bias  :0.000000
===================test Result================
test 99.38%/99.38%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 10, 34, 26;
conv2:
fire count: 0, 0, 0, 0, 0, 9, 7, 0, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 9, 0, 6, 0, 9, 0;
output:
fire count: 0, 1, 1, 1, 1, 2, 34, 1, 2, 1;
epoch=34 time=1342.390s cost=17.424850 Momentum=0.900000 lrate=0.00016903
train performance: 99.08%
===================weight value================
conv1:
weight:-0.107593, -0.444435, -0.868066;
bias  :0.000000 0.000000
conv2:
weight:-0.794077, 0.048780, -0.052774;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -0.942805;
bias  :0.000000
===================test Result================
test 99.01%/99.38%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 10, 32, 23;
conv2:
fire count: 0, 0, 0, 0, 0, 2, 1, 0, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 1, 0, 19, 0, 5, 0;
output:
fire count: 0, 1, 1, 1, 1, 2, 34, 0, 2, 1;
epoch=35 time=1396.249s cost=12.374567 Momentum=0.900000 lrate=0.00016667
train performance: 99.43%
===================weight value================
conv1:
weight:-0.081645, -0.411410, -0.880150;
bias  :0.000000 0.000000
conv2:
weight:-0.757370, 0.108449, 0.016841;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -0.969397;
bias  :0.000000
===================test Result================
test 98.81%/99.38%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 8, 30, 23;
conv2:
fire count: 0, 0, 0, 0, 0, 5, 5, 0, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 1, 0, 23, 0, 2, 0;
output:
fire count: 0, 1, 2, 1, 1, 2, 35, 0, 1, 1;
epoch=36 time=1385.120s cost=11.082933 Momentum=0.900000 lrate=0.00016440
train performance: 99.47%
===================weight value================
conv1:
weight:-0.131551, -0.461306, -0.899354;
bias  :0.000000 0.000000
conv2:
weight:-0.666779, 0.176007, 0.064448;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -0.974095;
bias  :0.000000
===================test Result================
test 99.24%/99.38%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 8, 30, 22;
conv2:
fire count: 0, 0, 0, 0, 1, 10, 10, 0, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 1, 0, 14, 0, 9, 0;
output:
fire count: 0, 1, 2, 1, 1, 2, 35, 0, 2, 1;
epoch=37 time=1365.287s cost=17.277683 Momentum=0.900000 lrate=0.00016222
train performance: 99.15%
===================weight value================
conv1:
weight:-0.173128, -0.523270, -0.900408;
bias  :0.000000 0.000000
conv2:
weight:-0.629066, 0.245195, 0.214602;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -0.979248;
bias  :0.000000
===================test Result================
test 98.80%/99.38%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 6, 26, 20;
conv2:
fire count: 0, 0, 0, 0, 0, 8, 7, 0, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 10, 0, 15, 0;
output:
fire count: 1, 0, 1, 1, 1, 2, 29, 1, 3, 1;
epoch=38 time=1372.381s cost=23.216766 Momentum=0.900000 lrate=0.00016013
train performance: 98.81%
===================weight value================
conv1:
weight:-0.163586, -0.527756, -0.995123;
bias  :0.000000 0.000000
conv2:
weight:-0.705723, 0.188596, 0.170048;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.000746;
bias  :0.000000
===================test Result================
test 97.50%/99.38%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 9, 2;
conv2:
fire count: 0, 0, 0, 0, 0, 7, 8, 0, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 1, 0, 0, 17, 0, 13, 0;
output:
fire count: 0, 1, 2, 1, 1, 1, 35, 0, 2, 1;
epoch=39 time=1340.846s cost=13.172617 Momentum=0.900000 lrate=0.00015811
train performance: 99.39%
===================weight value================
conv1:
weight:-0.211186, -0.574372, -0.995250;
bias  :0.000000 0.000000
conv2:
weight:-0.666249, 0.201031, 0.194741;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.005768;
bias  :0.000000
===================test Result================
test 99.20%/99.38%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 16, 9;
conv2:
fire count: 0, 0, 0, 0, 0, 9, 10, 0, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 8, 0, 12, 0;
output:
fire count: 1, 1, 1, 1, 1, 2, 34, 0, 1, 1;
epoch=40 time=1347.748s cost=15.831634 Momentum=0.900000 lrate=0.00015617
train performance: 99.23%
===================weight value================
conv1:
weight:-0.180477, -0.546103, -0.992507;
bias  :0.000000 0.000000
conv2:
weight:-0.582092, 0.238864, 0.191497;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.010729;
bias  :0.000000
===================test Result================
test 99.23%/99.38%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 1, 16, 9;
conv2:
fire count: 0, 0, 0, 0, 0, 13, 11, 1, 0, 0;
pooling2:
fire count: 0, 0, 3, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 3, 0, 8, 0, 12, 0;
output:
fire count: 0, 1, 0, 2, 1, 2, 38, 0, 2, 1;
epoch=41 time=1319.592s cost=10.989683 Momentum=0.900000 lrate=0.00015430
train performance: 99.46%
===================weight value================
conv1:
weight:-0.166676, -0.531846, -0.964025;
bias  :0.000000 0.000000
conv2:
weight:-0.625614, 0.220644, 0.156719;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.010729;
bias  :0.000000
===================test Result================
test 99.35%/99.38%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 2, 21, 15;
conv2:
fire count: 0, 0, 0, 0, 0, 12, 8, 0, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 8, 0, 11, 0;
output:
fire count: 0, 1, 1, 2, 1, 2, 36, 0, 2, 1;
epoch=42 time=1344.303s cost=13.983933 Momentum=0.900000 lrate=0.00015250
train performance: 99.34%
===================weight value================
conv1:
weight:-0.208681, -0.568377, -0.983525;
bias  :0.000000 0.000000
conv2:
weight:-0.615994, 0.187862, 0.127920;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.031859;
bias  :0.000000
===================test Result================
test 99.23%/99.38%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 4, 23, 15;
conv2:
fire count: 0, 0, 0, 0, 0, 8, 5, 0, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 1, 0, 6, 0, 12, 0;
output:
fire count: 1, 1, 0, 1, 0, 2, 38, 0, 1, 1;
epoch=43 time=1314.787s cost=13.353700 Momentum=0.900000 lrate=0.00015076
train performance: 99.36%
===================weight value================
conv1:
weight:-0.257633, -0.597713, -1.001897;
bias  :0.000000 0.000000
conv2:
weight:-0.583891, 0.211426, 0.169452;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.048366;
bias  :0.000000
===================test Result================
test 99.34%/99.38%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 6, 25, 16;
conv2:
fire count: 0, 0, 0, 0, 0, 10, 7, 0, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 1, 0, 5, 0, 15, 0;
output:
fire count: 1, 1, 0, 1, 0, 2, 35, 1, 2, 1;
epoch=44 time=1280.860s cost=19.649349 Momentum=0.900000 lrate=0.00014907
train performance: 99.03%
===================weight value================
conv1:
weight:-0.252479, -0.654704, -1.134362;
bias  :0.000000 0.000000
conv2:
weight:-0.528972, 0.227167, 0.179025;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.053101;
bias  :0.000000
===================test Result================
test 98.37%/99.38%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 2, 18, 11;
conv2:
fire count: 0, 0, 0, 0, 0, 8, 5, 0, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 1, 0, 14, 0, 12, 0;
output:
fire count: 0, 1, 1, 1, 1, 2, 40, 0, 1, 1;
epoch=45 time=1328.337s cost=13.437083 Momentum=0.900000 lrate=0.00014744
train performance: 99.36%
===================weight value================
conv1:
weight:-0.304125, -0.669738, -1.074977;
bias  :0.000000 0.000000
conv2:
weight:-0.449498, 0.255275, 0.223481;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.067147;
bias  :0.000000
===================test Result================
test 98.89%/99.38%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 9, 29, 19;
conv2:
fire count: 0, 0, 0, 0, 1, 12, 8, 0, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 5, 0, 10, 0;
output:
fire count: 1, 1, 1, 0, 0, 2, 34, 0, 2, 1;
epoch=46 time=1328.628s cost=15.123034 Momentum=0.900000 lrate=0.00014586
train performance: 99.28%
===================weight value================
conv1:
weight:-0.343087, -0.673501, -1.074523;
bias  :0.000000 0.000000
conv2:
weight:-0.366762, 0.290200, 0.246861;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.067147;
bias  :0.000000
===================test Result================
test 98.91%/99.38%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 7, 26, 16;
conv2:
fire count: 0, 0, 0, 0, 0, 12, 9, 0, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 1, 0, 9, 0;
output:
fire count: 1, 1, 1, 0, 1, 1, 34, 0, 1, 1;
epoch=47 time=1322.156s cost=10.762900 Momentum=0.900000 lrate=0.00014434
train performance: 99.50%
===================weight value================
conv1:
weight:-0.337326, -0.653889, -1.079416;
bias  :0.000000 0.000000
conv2:
weight:-0.376898, 0.289286, 0.261919;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.071732;
bias  :0.000000
===================test Result================
test 99.41%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 6, 25, 17;
conv2:
fire count: 0, 0, 0, 0, 0, 10, 7, 0, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 9, 0, 7, 0;
output:
fire count: 1, 1, 1, 0, 1, 1, 33, 0, 1, 1;
epoch=48 time=1359.073s cost=13.555483 Momentum=0.900000 lrate=0.00014286
train performance: 99.37%
===================weight value================
conv1:
weight:-0.419842, -0.705350, -1.106594;
bias  :0.000000 0.000000
conv2:
weight:-0.349824, 0.292354, 0.286807;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.076269;
bias  :0.000000
===================test Result================
test 99.12%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 8, 29, 19;
conv2:
fire count: 0, 0, 0, 0, 3, 13, 8, 0, 0, 0;
pooling2:
fire count: 0, 0, 1, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 9, 0, 8, 0;
output:
fire count: 1, 1, 2, 0, 1, 1, 32, 0, 2, 1;
epoch=49 time=1372.865s cost=11.960134 Momentum=0.900000 lrate=0.00014142
train performance: 99.38%
===================weight value================
conv1:
weight:-0.423097, -0.735884, -1.123489;
bias  :0.000000 0.000000
conv2:
weight:-0.294811, 0.350753, 0.322632;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.076269;
bias  :0.000000
===================test Result================
test 99.09%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 12, 33, 23;
conv2:
fire count: 0, 0, 0, 0, 3, 13, 7, 0, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 11, 0, 15, 0;
output:
fire count: 0, 1, 2, 0, 0, 1, 28, 1, 1, 1;
epoch=50 time=1328.153s cost=14.754666 Momentum=0.900000 lrate=0.00014003
train performance: 99.28%
===================weight value================
conv1:
weight:-0.373248, -0.737310, -1.179604;
bias  :0.000000 0.000000
conv2:
weight:-0.316517, 0.325681, 0.289142;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.076269;
bias  :0.000000
===================test Result================
test 97.92%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 7, 26, 17;
conv2:
fire count: 0, 0, 0, 0, 2, 12, 7, 0, 0, 0;
pooling2:
fire count: 0, 0, 1, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 19, 0, 14, 0;
output:
fire count: 0, 1, 2, 0, 1, 1, 25, 1, 1, 1;
epoch=51 time=1277.829s cost=18.963200 Momentum=0.900000 lrate=0.00013868
train performance: 99.07%
===================weight value================
conv1:
weight:-0.310777, -0.742169, -1.242985;
bias  :0.000000 0.000000
conv2:
weight:-0.319164, 0.305919, 0.297641;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.076269;
bias  :0.000000
===================test Result================
test 98.16%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 4, 22, 14;
conv2:
fire count: 0, 0, 0, 0, 2, 13, 9, 2, 0, 0;
pooling2:
fire count: 0, 0, 2, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 3, 21, 0, 6, 0;
output:
fire count: 0, 1, 1, 1, 2, 2, 29, 0, 1, 1;
epoch=52 time=1335.681s cost=13.908934 Momentum=0.900000 lrate=0.00013736
train performance: 99.30%
===================weight value================
conv1:
weight:-0.377004, -0.801496, -1.227450;
bias  :0.000000 0.000000
conv2:
weight:-0.212611, 0.442381, 0.418095;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.080632;
bias  :0.000000
===================test Result================
test 98.96%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 10, 31, 21;
conv2:
fire count: 0, 0, 0, 0, 9, 19, 14, 5, 0, 0;
pooling2:
fire count: 0, 0, 6, 1, 0, 0, 0, 0, 0, 4;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 12, 0, 21, 0;
output:
fire count: 0, 1, 1, 0, 1, 1, 28, 0, 1, 1;
epoch=53 time=1372.234s cost=13.463333 Momentum=0.900000 lrate=0.00013608
train performance: 99.36%
===================weight value================
conv1:
weight:-0.335173, -0.776398, -1.288841;
bias  :0.000000 0.000000
conv2:
weight:-0.234206, 0.407245, 0.357297;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.089229;
bias  :0.000000
===================test Result================
test 98.55%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 6, 25, 17;
conv2:
fire count: 0, 0, 0, 0, 2, 15, 11, 3, 0, 0;
pooling2:
fire count: 0, 0, 3, 0, 0, 0, 0, 0, 0, 3;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 16, 0, 15, 0;
output:
fire count: 0, 1, 1, 0, 1, 1, 31, 1, 1, 1;
epoch=54 time=1360.609s cost=14.123384 Momentum=0.900000 lrate=0.00013484
train performance: 99.35%
===================weight value================
conv1:
weight:-0.467787, -0.853744, -1.249088;
bias  :0.000000 0.000000
conv2:
weight:-0.214842, 0.392565, 0.337577;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.089229;
bias  :0.000000
===================test Result================
test 99.09%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 9, 28, 17;
conv2:
fire count: 0, 0, 0, 0, 4, 14, 9, 1, 0, 0;
pooling2:
fire count: 0, 0, 1, 0, 0, 0, 0, 0, 0, 2;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 9, 0, 18, 0;
output:
fire count: 0, 1, 1, 0, 1, 1, 29, 0, 1, 1;
epoch=55 time=1353.949s cost=26.098433 Momentum=0.900000 lrate=0.00013363
train performance: 98.67%
===================weight value================
conv1:
weight:-0.465394, -0.862369, -1.284325;
bias  :0.000000 0.000000
conv2:
weight:-0.283621, 0.356960, 0.312243;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.095132;
bias  :0.000000
===================test Result================
test 98.46%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 10, 28, 15;
conv2:
fire count: 0, 0, 0, 0, 4, 15, 9, 1, 0, 0;
pooling2:
fire count: 0, 0, 2, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 10, 0, 20, 0;
output:
fire count: 0, 1, 0, 1, 1, 1, 38, 0, 2, 1;
epoch=56 time=1254.490s cost=17.928116 Momentum=0.900000 lrate=0.00013245
train performance: 99.09%
===================weight value================
conv1:
weight:-0.448302, -0.839811, -1.218186;
bias  :0.000000 0.000000
conv2:
weight:-0.189513, 0.403118, 0.315010;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.095132;
bias  :0.000000
===================test Result================
test 98.71%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 15, 33, 19;
conv2:
fire count: 0, 0, 0, 0, 1, 12, 6, 0, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 5, 0, 16, 0;
output:
fire count: 1, 1, 0, 0, 1, 2, 29, 0, 1, 1;
epoch=57 time=1284.948s cost=14.107966 Momentum=0.900000 lrate=0.00013131
train performance: 99.31%
===================weight value================
conv1:
weight:-0.468085, -0.875857, -1.240559;
bias  :0.000000 0.000000
conv2:
weight:-0.101797, 0.495404, 0.358195;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.095132;
bias  :0.000000
===================test Result================
test 98.81%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 15, 33, 19;
conv2:
fire count: 0, 0, 0, 0, 2, 13, 7, 0, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 1, 0, 9, 0, 16, 0;
output:
fire count: 0, 1, 0, 1, 0, 1, 31, 1, 1, 1;
epoch=58 time=1327.366s cost=13.864567 Momentum=0.900000 lrate=0.00013019
train performance: 99.30%
===================weight value================
conv1:
weight:-0.424688, -0.891028, -1.337909;
bias  :0.000000 0.000000
conv2:
weight:-0.170841, 0.459781, 0.361166;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.098784;
bias  :0.000000
===================test Result================
test 97.94%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 5, 21, 10;
conv2:
fire count: 0, 0, 0, 0, 0, 11, 8, 1, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 1, 0, 15, 0, 19, 0;
output:
fire count: 0, 1, 1, 0, 1, 0, 36, 1, 1, 1;
epoch=59 time=1364.435s cost=9.732750 Momentum=0.900000 lrate=0.00012910
train performance: 99.52%
===================weight value================
conv1:
weight:-0.475107, -0.880913, -1.288447;
bias  :0.000000 0.000000
conv2:
weight:-0.190065, 0.467289, 0.351434;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.102922;
bias  :0.000000
===================test Result================
test 99.15%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 12, 30, 16;
conv2:
fire count: 0, 0, 0, 0, 2, 12, 9, 1, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 18, 0, 18, 0;
output:
fire count: 0, 1, 1, 0, 1, 1, 34, 0, 1, 1;
epoch=60 time=1380.508s cost=13.630934 Momentum=0.900000 lrate=0.00012804
train performance: 99.35%
===================weight value================
conv1:
weight:-0.513326, -0.888934, -1.284714;
bias  :0.000000 0.000000
conv2:
weight:-0.167254, 0.463658, 0.370146;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.106904;
bias  :0.000000
===================test Result================
test 99.00%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 12, 30, 17;
conv2:
fire count: 0, 0, 0, 0, 3, 11, 7, 0, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 18, 0, 25, 0;
output:
fire count: 0, 0, 1, 1, 0, 1, 34, 0, 1, 1;
epoch=61 time=1412.252s cost=13.776183 Momentum=0.900000 lrate=0.00012700
train performance: 99.33%
===================weight value================
conv1:
weight:-0.506203, -0.912531, -1.302147;
bias  :0.000000 0.000000
conv2:
weight:-0.171341, 0.448981, 0.336862;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.106904;
bias  :0.000000
===================test Result================
test 98.90%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 8, 26, 13;
conv2:
fire count: 0, 0, 0, 0, 2, 12, 8, 1, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 1, 0, 17, 0, 13, 0;
output:
fire count: 0, 0, 1, 0, 0, 1, 39, 0, 1, 1;
epoch=62 time=1375.486s cost=9.618967 Momentum=0.900000 lrate=0.00012599
train performance: 99.56%
===================weight value================
conv1:
weight:-0.548081, -0.899489, -1.254951;
bias  :0.000000 0.000000
conv2:
weight:-0.188541, 0.415674, 0.292234;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.106904;
bias  :0.000000
===================test Result================
test 99.28%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 13, 30, 16;
conv2:
fire count: 0, 0, 0, 0, 4, 12, 7, 0, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 7, 0, 23, 0;
output:
fire count: 0, 0, 1, 0, 0, 2, 35, 0, 1, 1;
epoch=63 time=1383.137s cost=11.032400 Momentum=0.900000 lrate=0.00012500
train performance: 99.45%
===================weight value================
conv1:
weight:-0.552356, -0.951223, -1.290822;
bias  :0.000000 0.000000
conv2:
weight:-0.184329, 0.388177, 0.235716;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.106904;
bias  :0.000000
===================test Result================
test 98.82%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 10, 28, 15;
conv2:
fire count: 0, 0, 0, 0, 5, 12, 5, 0, 0, 0;
pooling2:
fire count: 0, 0, 1, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 1, 0, 7, 0, 24, 0;
output:
fire count: 0, 1, 1, 0, 0, 1, 36, 1, 0, 1;
epoch=64 time=1389.060s cost=13.348017 Momentum=0.900000 lrate=0.00012403
train performance: 99.36%
===================weight value================
conv1:
weight:-0.565897, -0.934429, -1.268626;
bias  :0.000000 0.000000
conv2:
weight:-0.201567, 0.395305, 0.234691;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.139356;
bias  :0.000000
===================test Result================
test 99.22%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 7, 24, 12;
conv2:
fire count: 0, 0, 0, 0, 3, 11, 6, 0, 0, 0;
pooling2:
fire count: 0, 0, 1, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 3, 0, 26, 0;
output:
fire count: 0, 1, 0, 0, 0, 1, 35, 1, 1, 1;
epoch=65 time=1354.432s cost=9.790450 Momentum=0.900000 lrate=0.00012309
train performance: 99.57%
===================weight value================
conv1:
weight:-0.558223, -0.917303, -1.278010;
bias  :0.000000 0.000000
conv2:
weight:-0.185842, 0.396304, 0.223178;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.139891;
bias  :0.000000
===================test Result================
test 98.97%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 6, 22, 10;
conv2:
fire count: 0, 0, 0, 0, 1, 10, 6, 1, 0, 0;
pooling2:
fire count: 0, 0, 1, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 1, 0, 9, 0, 21, 0;
output:
fire count: 0, 1, 1, 0, 0, 0, 36, 1, 1, 1;
epoch=66 time=1354.113s cost=11.816517 Momentum=0.900000 lrate=0.00012217
train performance: 99.42%
===================weight value================
conv1:
weight:-0.601328, -0.981533, -1.297690;
bias  :0.000000 0.000000
conv2:
weight:-0.150488, 0.421035, 0.212351;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.139891;
bias  :0.000000
===================test Result================
test 99.10%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 14, 32, 16;
conv2:
fire count: 0, 0, 0, 0, 6, 10, 5, 0, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 8, 0, 23, 0;
output:
fire count: 0, 1, 1, 0, 0, 1, 30, 0, 1, 1;
epoch=67 time=1386.979s cost=9.837150 Momentum=0.900000 lrate=0.00012127
train performance: 99.53%
===================weight value================
conv1:
weight:-0.618684, -0.999804, -1.285956;
bias  :0.000000 0.000000
conv2:
weight:-0.111404, 0.436718, 0.236902;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.139891;
bias  :0.000000
===================test Result================
test 99.05%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 12, 31, 16;
conv2:
fire count: 0, 0, 0, 0, 6, 10, 6, 0, 0, 0;
pooling2:
fire count: 0, 0, 1, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 29, 0;
output:
fire count: 0, 1, 1, 0, 0, 1, 32, 0, 1, 1;
epoch=68 time=1386.152s cost=19.896601 Momentum=0.900000 lrate=0.00012039
train performance: 99.00%
===================weight value================
conv1:
weight:-0.597724, -0.932661, -1.211478;
bias  :0.000000 0.000000
conv2:
weight:-0.096108, 0.457992, 0.254251;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.150878;
bias  :0.000000
===================test Result================
test 98.26%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 14, 34, 19;
conv2:
fire count: 0, 0, 0, 0, 9, 14, 9, 1, 0, 0;
pooling2:
fire count: 0, 0, 4, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 2, 0, 0, 0, 19, 0;
output:
fire count: 0, 1, 1, 0, 0, 1, 30, 1, 1, 1;
epoch=69 time=1398.874s cost=14.246017 Momentum=0.900000 lrate=0.00011952
train performance: 99.29%
===================weight value================
conv1:
weight:-0.591558, -0.934115, -1.234597;
bias  :0.000000 0.000000
conv2:
weight:-0.064740, 0.508116, 0.294359;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.158425;
bias  :0.000000
===================test Result================
test 99.03%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 15, 35, 22;
conv2:
fire count: 0, 0, 0, 0, 8, 11, 7, 1, 0, 0;
pooling2:
fire count: 0, 0, 2, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 6, 0, 20, 0;
output:
fire count: 0, 1, 1, 1, 0, 1, 33, 0, 1, 1;
epoch=70 time=1409.098s cost=9.383567 Momentum=0.900000 lrate=0.00011868
train performance: 99.55%
===================weight value================
conv1:
weight:-0.559994, -0.929697, -1.271071;
bias  :0.000000 0.000000
conv2:
weight:-0.046347, 0.528517, 0.277334;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.154201;
bias  :0.000000
===================test Result================
test 99.22%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 11, 30, 19;
conv2:
fire count: 0, 0, 0, 0, 2, 8, 7, 1, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 2, 0, 24, 0;
output:
fire count: 0, 1, 1, 0, 0, 0, 35, 1, 1, 1;
epoch=71 time=1352.147s cost=10.623034 Momentum=0.900000 lrate=0.00011785
train performance: 99.50%
===================weight value================
conv1:
weight:-0.575263, -0.926118, -1.220181;
bias  :0.000000 0.000000
conv2:
weight:-0.016276, 0.529516, 0.274886;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.161687;
bias  :0.000000
===================test Result================
test 99.09%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 15, 35, 22;
conv2:
fire count: 0, 0, 0, 0, 6, 9, 5, 1, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 18, 0;
output:
fire count: 1, 1, 1, 0, 0, 0, 33, 1, 1, 1;
epoch=72 time=1365.205s cost=10.061050 Momentum=0.900000 lrate=0.00011704
train performance: 99.51%
===================weight value================
conv1:
weight:-0.590873, -0.948615, -1.236381;
bias  :0.000000 0.000000
conv2:
weight:0.041047, 0.508737, 0.255645;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.165404;
bias  :0.000000
===================test Result================
test 99.27%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 14, 34, 22;
conv2:
fire count: 0, 0, 0, 0, 6, 10, 6, 2, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 4, 0, 27, 0;
output:
fire count: 0, 1, 1, 1, 0, 2, 33, 1, 0, 1;
epoch=73 time=1362.878s cost=13.177716 Momentum=0.900000 lrate=0.00011625
train performance: 99.35%
===================weight value================
conv1:
weight:-0.600621, -0.956411, -1.256667;
bias  :0.000000 0.000000
conv2:
weight:0.085561, 0.541426, 0.267921;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.165404;
bias  :0.000000
===================test Result================
test 98.85%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 16, 36, 22;
conv2:
fire count: 0, 0, 0, 0, 7, 11, 8, 3, 0, 0;
pooling2:
fire count: 0, 0, 1, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 1, 0, 2, 0, 18, 0;
output:
fire count: 0, 1, 1, 1, 0, 1, 33, 1, 1, 1;
epoch=74 time=1397.662s cost=8.382216 Momentum=0.900000 lrate=0.00011547
train performance: 99.61%
===================weight value================
conv1:
weight:-0.598566, -0.972099, -1.293873;
bias  :0.000000 0.000000
conv2:
weight:0.090486, 0.544649, 0.239734;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.169072;
bias  :0.000000
===================test Result================
test 99.20%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 12, 31, 19;
conv2:
fire count: 0, 0, 0, 0, 1, 8, 7, 3, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 3, 0, 24, 0;
output:
fire count: 0, 1, 1, 1, 0, 1, 37, 0, 1, 1;
epoch=75 time=1375.306s cost=9.788000 Momentum=0.900000 lrate=0.00011471
train performance: 99.58%
===================weight value================
conv1:
weight:-0.650508, -1.020345, -1.317103;
bias  :0.000000 0.000000
conv2:
weight:0.096796, 0.542707, 0.238480;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.169072;
bias  :0.000000
===================test Result================
test 99.22%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 13, 31, 19;
conv2:
fire count: 0, 0, 0, 0, 4, 8, 6, 3, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 4, 0, 24, 0;
output:
fire count: 0, 1, 1, 1, 0, 1, 36, 1, 1, 1;
epoch=76 time=1362.133s cost=10.038850 Momentum=0.900000 lrate=0.00011396
train performance: 99.56%
===================weight value================
conv1:
weight:-0.692044, -1.077938, -1.336413;
bias  :0.000000 0.000000
conv2:
weight:0.114772, 0.549664, 0.217743;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.169072;
bias  :0.000000
===================test Result================
test 99.17%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 13, 31, 17;
conv2:
fire count: 0, 0, 0, 0, 5, 9, 7, 3, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 5, 0, 21, 0;
output:
fire count: 0, 1, 1, 0, 0, 1, 36, 1, 0, 1;
epoch=77 time=1354.219s cost=14.569917 Momentum=0.900000 lrate=0.00011323
train performance: 99.29%
===================weight value================
conv1:
weight:-0.711485, -1.109629, -1.334887;
bias  :0.000000 0.000000
conv2:
weight:0.153031, 0.597681, 0.246058;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.169072;
bias  :0.000000
===================test Result================
test 98.94%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 16, 36, 20;
conv2:
fire count: 0, 0, 0, 0, 10, 13, 11, 7, 0, 0;
pooling2:
fire count: 0, 0, 3, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 5, 0, 22, 0;
output:
fire count: 0, 0, 1, 1, 0, 2, 32, 0, 2, 1;
epoch=78 time=1400.103s cost=11.525066 Momentum=0.900000 lrate=0.00011251
train performance: 99.47%
===================weight value================
conv1:
weight:-0.733765, -1.155968, -1.386998;
bias  :0.000000 0.000000
conv2:
weight:0.101963, 0.515160, 0.170611;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, -0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.165498;
bias  :0.000000
===================test Result================
test 99.21%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 9, 27, 14;
conv2:
fire count: 0, 0, 0, 0, 4, 8, 8, 5, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 5, 0, 18, 0;
output:
fire count: 0, 0, 1, 1, 0, 1, 38, 0, 2, 1;
epoch=79 time=1376.535s cost=11.570400 Momentum=0.900000 lrate=0.00011180
train performance: 99.47%
===================weight value================
conv1:
weight:-0.746582, -1.170392, -1.400035;
bias  :0.000000 0.000000
conv2:
weight:0.121328, 0.532007, 0.172205;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.179676;
bias  :0.000000
===================test Result================
test 99.09%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 13, 31, 17;
conv2:
fire count: 0, 0, 0, 0, 7, 11, 9, 6, 0, 0;
pooling2:
fire count: 0, 0, 1, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 26, 0;
output:
fire count: 1, 0, 1, 1, 0, 1, 33, 0, 2, 1;
epoch=80 time=1362.919s cost=12.053050 Momentum=0.900000 lrate=0.00011111
train performance: 99.45%
===================weight value================
conv1:
weight:-0.775447, -1.213371, -1.440704;
bias  :0.000000 0.000000
conv2:
weight:0.148165, 0.555474, 0.195796;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.179676;
bias  :0.000000
===================test Result================
test 98.99%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 13, 30, 18;
conv2:
fire count: 0, 0, 0, 0, 3, 8, 8, 6, 0, 0;
pooling2:
fire count: 0, 0, 1, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 4, 0, 20, 0;
output:
fire count: 1, 0, 2, 1, 0, 1, 32, 1, 1, 1;
epoch=81 time=1366.778s cost=10.182900 Momentum=0.900000 lrate=0.00011043
train performance: 99.55%
===================weight value================
conv1:
weight:-0.740101, -1.211709, -1.454631;
bias  :0.000000 0.000000
conv2:
weight:0.166834, 0.531636, 0.180465;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.183183;
bias  :0.000000
===================test Result================
test 99.36%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 8, 27, 14;
conv2:
fire count: 0, 0, 0, 0, 4, 10, 9, 5, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 2, 0, 16, 0;
output:
fire count: 0, 1, 1, 1, 0, 1, 35, 0, 1, 1;
epoch=82 time=1336.312s cost=9.192950 Momentum=0.900000 lrate=0.00010976
train performance: 99.60%
===================weight value================
conv1:
weight:-0.746420, -1.217546, -1.467301;
bias  :0.000000 0.000000
conv2:
weight:0.180159, 0.534225, 0.175196;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.186670;
bias  :0.000000
===================test Result================
test 99.21%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 11, 29, 17;
conv2:
fire count: 0, 0, 0, 0, 6, 11, 9, 5, 0, 0;
pooling2:
fire count: 0, 0, 1, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 4, 0, 21, 0;
output:
fire count: 0, 0, 2, 1, 0, 1, 35, 1, 1, 1;
epoch=83 time=1313.710s cost=9.168734 Momentum=0.900000 lrate=0.00010911
train performance: 99.59%
===================weight value================
conv1:
weight:-0.676004, -1.171557, -1.474211;
bias  :0.000000 0.000000
conv2:
weight:0.220803, 0.539540, 0.152560;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.186670;
bias  :0.000000
===================test Result================
test 99.06%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 14, 34, 21;
conv2:
fire count: 0, 0, 0, 0, 6, 11, 10, 6, 0, 0;
pooling2:
fire count: 0, 0, 2, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 7, 0, 21, 0;
output:
fire count: 0, 0, 2, 1, 0, 1, 35, 1, 1, 1;
epoch=84 time=1289.445s cost=12.252250 Momentum=0.900000 lrate=0.00010847
train performance: 99.48%
===================weight value================
conv1:
weight:-0.669049, -1.175668, -1.498100;
bias  :0.000000 0.000000
conv2:
weight:0.195181, 0.507503, 0.148829;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.183213;
bias  :0.000000
===================test Result================
test 99.18%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 11, 31, 19;
conv2:
fire count: 0, 0, 0, 0, 5, 12, 11, 7, 0, 0;
pooling2:
fire count: 0, 0, 3, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 7, 0, 23, 0;
output:
fire count: 0, 0, 1, 1, 0, 1, 35, 1, 1, 1;
epoch=85 time=1249.206s cost=10.980850 Momentum=0.900000 lrate=0.00010783
train performance: 99.53%
===================weight value================
conv1:
weight:-0.724106, -1.195568, -1.488006;
bias  :0.000000 0.000000
conv2:
weight:0.194134, 0.525405, 0.156020;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.183213;
bias  :0.000000
===================test Result================
test 99.10%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 11, 31, 19;
conv2:
fire count: 0, 0, 0, 0, 3, 8, 9, 5, 0, 0;
pooling2:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 8, 0, 21, 0;
output:
fire count: 1, 1, 2, 1, 0, 0, 34, 1, 1, 1;
epoch=86 time=1215.898s cost=12.450983 Momentum=0.900000 lrate=0.00010721
train performance: 99.47%
===================weight value================
conv1:
weight:-0.720134, -1.197012, -1.453512;
bias  :0.000000 0.000000
conv2:
weight:0.254658, 0.563835, 0.206618;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.179984;
bias  :0.000000
===================test Result================
test 98.98%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 13, 34, 22;
conv2:
fire count: 0, 0, 0, 0, 4, 8, 10, 6, 0, 0;
pooling2:
fire count: 0, 0, 1, 0, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 8, 0, 11, 0;
output:
fire count: 0, 1, 2, 1, 0, 1, 33, 1, 0, 1;
epoch=87 time=1268.752s cost=11.125150 Momentum=0.900000 lrate=0.00010660
train performance: 99.48%
===================weight value================
conv1:
weight:-0.733713, -1.182783, -1.395290;
bias  :0.000000 0.000000
conv2:
weight:0.279696, 0.565784, 0.222335;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.190065;
bias  :0.000000
===================test Result================
test 99.18%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 16, 36, 24;
conv2:
fire count: 0, 0, 0, 0, 7, 10, 11, 7, 0, 0;
pooling2:
fire count: 0, 0, 3, 1, 0, 0, 0, 0, 0, 1;
hidden_0:
fire count: 0, 0, 0, 1, 0, 0, 3, 0, 25, 0;
output:
fire count: 0, 1, 1, 1, 0, 1, 37, 1, 1, 1;
epoch=88 time=1261.339s cost=14.509400 Momentum=0.900000 lrate=0.00010600
train performance: 99.38%
===================weight value================
conv1:
weight:-0.735913, -1.187134, -1.436413;
bias  :0.000000 0.000000
conv2:
weight:0.299148, 0.540550, 0.168679;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.197435;
bias  :0.000000
===================test Result================
test 99.09%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 9, 29, 17;
conv2:
fire count: 0, 0, 0, 0, 3, 9, 10, 7, 0, 0;
pooling2:
fire count: 0, 0, 1, 1, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 1, 0, 4, 0, 19, 0;
output:
fire count: 0, 1, 2, 1, 0, 1, 34, 1, 1, 1;
epoch=89 time=1209.909s cost=19.825951 Momentum=0.900000 lrate=0.00010541
train performance: 99.05%
===================weight value================
conv1:
weight:-0.761225, -1.126629, -1.353390;
bias  :0.000000 0.000000
conv2:
weight:0.324554, 0.579189, 0.166706;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.214134;
bias  :0.000000
===================test Result================
test 98.55%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 18, 39, 25;
conv2:
fire count: 0, 0, 0, 0, 8, 15, 15, 10, 0, 0;
pooling2:
fire count: 0, 0, 5, 2, 0, 0, 0, 0, 0, 1;
hidden_0:
fire count: 0, 0, 0, 0, 2, 0, 1, 0, 20, 0;
output:
fire count: 1, 1, 0, 1, 0, 1, 34, 1, 1, 2;
epoch=90 time=1204.396s cost=11.422017 Momentum=0.900000 lrate=0.00010483
train performance: 99.49%
===================weight value================
conv1:
weight:-0.791089, -1.168690, -1.388050;
bias  :0.000000 0.000000
conv2:
weight:0.334105, 0.600381, 0.166775;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.220797;
bias  :0.000000
===================test Result================
test 99.26%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 16, 36, 22;
conv2:
fire count: 0, 0, 0, 0, 5, 11, 13, 10, 0, 0;
pooling2:
fire count: 0, 0, 3, 2, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 1, 0, 20, 0;
output:
fire count: 0, 1, 1, 1, 0, 1, 36, 1, 1, 2;
epoch=91 time=1188.307s cost=25.865000 Momentum=0.900000 lrate=0.00010426
train performance: 98.66%
===================weight value================
conv1:
weight:-0.752047, -1.207367, -1.434355;
bias  :0.000000 0.000000
conv2:
weight:0.346411, 0.587845, 0.120808;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.230593;
bias  :0.000000
===================test Result================
test 98.32%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 12, 31, 18;
conv2:
fire count: 0, 0, 0, 0, 6, 14, 14, 10, 0, 0;
pooling2:
fire count: 0, 0, 5, 3, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 2, 0, 9, 0, 8, 0;
output:
fire count: 1, 0, 1, 1, 0, 1, 36, 1, 1, 1;
epoch=92 time=1173.103s cost=13.968500 Momentum=0.900000 lrate=0.00010370
train performance: 99.36%
===================weight value================
conv1:
weight:-0.775402, -1.175482, -1.415197;
bias  :0.000000 0.000000
conv2:
weight:0.355923, 0.650063, 0.185203;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.241019;
bias  :0.000000
===================test Result================
test 99.22%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 14, 34, 20;
conv2:
fire count: 0, 0, 0, 0, 7, 13, 14, 11, 0, 0;
pooling2:
fire count: 0, 0, 5, 3, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 1, 0, 5, 0, 25, 0;
output:
fire count: 0, 1, 1, 1, 0, 1, 36, 1, 1, 1;
epoch=93 time=1294.049s cost=17.049232 Momentum=0.900000 lrate=0.00010314
train performance: 99.19%
===================weight value================
conv1:
weight:-0.842778, -1.168098, -1.354785;
bias  :0.000000 0.000000
conv2:
weight:0.366951, 0.702410, 0.287317;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.275652;
bias  :0.000000
===================test Result================
test 99.21%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 21, 42, 27;
conv2:
fire count: 0, 0, 0, 1, 11, 17, 18, 14, 0, 0;
pooling2:
fire count: 0, 0, 8, 5, 0, 0, 0, 0, 2, 3;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 9, 0, 25, 0;
output:
fire count: 0, 1, 1, 0, 1, 1, 38, 1, 0, 1;
epoch=94 time=1240.850s cost=10.273283 Momentum=0.900000 lrate=0.00010260
train performance: 99.53%
===================weight value================
conv1:
weight:-0.854290, -1.178909, -1.394193;
bias  :0.000000 0.000000
conv2:
weight:0.334352, 0.684477, 0.267589;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.282087;
bias  :0.000000
===================test Result================
test 99.21%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 19, 39, 26;
conv2:
fire count: 0, 0, 0, 0, 8, 15, 16, 12, 0, 0;
pooling2:
fire count: 0, 0, 5, 4, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 9, 0, 23, 0;
output:
fire count: 0, 1, 1, 1, 1, 1, 37, 1, 0, 1;
epoch=95 time=1250.845s cost=14.372066 Momentum=0.900000 lrate=0.00010206
train performance: 99.33%
===================weight value================
conv1:
weight:-0.896943, -1.202173, -1.341747;
bias  :0.000000 0.000000
conv2:
weight:0.324986, 0.679780, 0.260058;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.278458;
bias  :0.000000
===================test Result================
test 99.11%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 22, 43, 27;
conv2:
fire count: 0, 0, 0, 0, 8, 14, 15, 10, 0, 0;
pooling2:
fire count: 0, 0, 5, 3, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 1, 0, 21, 0;
output:
fire count: 0, 1, 1, 1, 1, 1, 34, 1, 0, 1;
epoch=96 time=1291.633s cost=11.101950 Momentum=0.900000 lrate=0.00010153
train performance: 99.49%
===================weight value================
conv1:
weight:-0.930997, -1.246593, -1.400927;
bias  :0.000000 0.000000
conv2:
weight:0.342130, 0.700399, 0.247530;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.278458;
bias  :0.000000
===================test Result================
test 99.17%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 21, 41, 25;
conv2:
fire count: 0, 0, 0, 0, 4, 11, 14, 11, 0, 0;
pooling2:
fire count: 0, 0, 3, 3, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 4, 0, 18, 0;
output:
fire count: 0, 1, 1, 1, 1, 1, 35, 1, 0, 1;
epoch=97 time=1315.848s cost=9.256967 Momentum=0.900000 lrate=0.00010102
train performance: 99.60%
===================weight value================
conv1:
weight:-0.943735, -1.277900, -1.443184;
bias  :0.000000 0.000000
conv2:
weight:0.323561, 0.701290, 0.254646;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.281659;
bias  :0.000000
===================test Result================
test 99.15%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 18, 39, 23;
conv2:
fire count: 0, 0, 0, 0, 3, 10, 14, 12, 0, 0;
pooling2:
fire count: 0, 0, 2, 4, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 8, 0, 20, 0;
output:
fire count: 0, 0, 1, 1, 0, 1, 35, 1, 0, 1;
epoch=98 time=1335.796s cost=12.583167 Momentum=0.900000 lrate=0.00010050
train performance: 99.43%
===================weight value================
conv1:
weight:-0.933261, -1.268048, -1.457671;
bias  :0.000000 0.000000
conv2:
weight:0.341966, 0.711691, 0.282532;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, -0.000000, -0.000004;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.280764;
bias  :0.000000
===================test Result================
test 99.23%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 20, 40, 25;
conv2:
fire count: 0, 0, 0, 0, 6, 12, 14, 11, 0, 0;
pooling2:
fire count: 0, 0, 3, 3, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 6, 0, 25, 0;
output:
fire count: 0, 0, 0, 1, 0, 2, 35, 1, 1, 1;
epoch=99 time=1366.409s cost=11.329000 Momentum=0.900000 lrate=0.00010000
train performance: 99.45%
===================weight value================
conv1:
weight:-0.916570, -1.275285, -1.518847;
bias  :0.000000 0.000000
conv2:
weight:0.381824, 0.753867, 0.319621;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.289354;
bias  :0.000000
===================test Result================
test 99.08%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 18, 38, 23;
conv2:
fire count: 0, 0, 0, 0, 4, 11, 15, 12, 0, 0;
pooling2:
fire count: 0, 0, 3, 3, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 6, 0, 23, 0;
output:
fire count: 0, 0, 1, 1, 1, 1, 35, 0, 1, 1;
epoch=100 time=1307.394s cost=11.978050 Momentum=0.900000 lrate=0.00009950
train performance: 99.46%
===================weight value================
conv1:
weight:-0.956804, -1.314420, -1.529417;
bias  :0.000000 0.000000
conv2:
weight:0.402882, 0.768465, 0.308361;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.289354;
bias  :0.000000
===================test Result================
test 99.02%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 16, 37, 22;
conv2:
fire count: 0, 0, 0, 0, 4, 11, 15, 11, 0, 0;
pooling2:
fire count: 0, 0, 3, 4, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 11, 0, 18, 0;
output:
fire count: 0, 0, 1, 1, 0, 1, 32, 0, 0, 1;
epoch=101 time=1373.716s cost=8.879333 Momentum=0.900000 lrate=0.00009901
train performance: 99.62%
===================weight value================
conv1:
weight:-0.916775, -1.274582, -1.501244;
bias  :0.000000 0.000000
conv2:
weight:0.410539, 0.734125, 0.269061;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.292499;
bias  :0.000000
===================test Result================
test 99.17%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 16, 36, 22;
conv2:
fire count: 0, 0, 0, 0, 4, 11, 15, 12, 0, 0;
pooling2:
fire count: 0, 0, 3, 4, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 8, 0, 24, 0;
output:
fire count: 0, 0, 2, 1, 1, 1, 33, 0, 1, 1;
epoch=102 time=1337.393s cost=10.473967 Momentum=0.900000 lrate=0.00009853
train performance: 99.52%
===================weight value================
conv1:
weight:-0.860661, -1.190307, -1.465973;
bias  :0.000000 0.000000
conv2:
weight:0.425125, 0.724095, 0.267330;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000015;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.298758;
bias  :0.000000
===================test Result================
test 99.21%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 18, 39, 23;
conv2:
fire count: 0, 0, 0, 0, 6, 14, 16, 12, 0, 0;
pooling2:
fire count: 0, 0, 5, 4, 0, 0, 0, 0, 1, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 9, 0, 25, 0;
output:
fire count: 0, 0, 1, 1, 1, 1, 34, 1, 1, 1;
epoch=103 time=1304.691s cost=10.254000 Momentum=0.900000 lrate=0.00009806
train performance: 99.54%
===================weight value================
conv1:
weight:-0.884301, -1.202593, -1.469542;
bias  :0.000000 0.000000
conv2:
weight:0.417287, 0.710396, 0.249430;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, -0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.298758;
bias  :0.000000
===================test Result================
test 99.21%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 16, 36, 21;
conv2:
fire count: 0, 0, 0, 0, 2, 11, 15, 12, 0, 0;
pooling2:
fire count: 0, 0, 3, 4, 0, 0, 0, 0, 1, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 9, 0, 18, 0;
output:
fire count: 0, 0, 1, 1, 1, 1, 35, 1, 0, 1;
epoch=104 time=1311.244s cost=13.030733 Momentum=0.900000 lrate=0.00009759
train performance: 99.40%
===================weight value================
conv1:
weight:-0.859205, -1.171130, -1.496008;
bias  :0.000000 0.000000
conv2:
weight:0.351846, 0.672819, 0.255795;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, -0.000018;
bias  :0.000000
output:
weight:-0.907647, -0.695483, -1.298758;
bias  :0.000000
===================test Result================
test 98.90%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 15, 34, 21;
conv2:
fire count: 0, 0, 0, 0, 1, 13, 18, 14, 0, 0;
pooling2:
fire count: 0, 0, 4, 6, 0, 0, 2, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 15, 0, 17, 0;
output:
fire count: 0, 1, 2, 1, 1, 1, 32, 0, 0, 1;
epoch=105 time=1299.218s cost=12.750700 Momentum=0.900000 lrate=0.00009713
train performance: 99.41%
===================weight value================
conv1:
weight:-0.911047, -1.188178, -1.456244;
bias  :0.000000 0.000000
conv2:
weight:0.368656, 0.688501, 0.253739;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, -0.000000;
bias  :0.000000
output:
weight:-0.910732, -0.695483, -1.301843;
bias  :0.000000
===================test Result================
test 99.10%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 17, 38, 21;
conv2:
fire count: 0, 0, 0, 0, 3, 12, 17, 13, 0, 0;
pooling2:
fire count: 0, 0, 4, 5, 0, 0, 0, 0, 1, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 10, 0, 19, 0;
output:
fire count: 0, 0, 1, 1, 1, 1, 32, 1, 0, 1;
epoch=106 time=1332.871s cost=9.370883 Momentum=0.900000 lrate=0.00009667
train performance: 99.59%
===================weight value================
conv1:
weight:-0.893372, -1.161388, -1.402728;
bias  :0.000000 0.000000
conv2:
weight:0.419428, 0.725567, 0.266565;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.910732, -0.695483, -1.307909;
bias  :0.000000
===================test Result================
test 99.19%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 20, 40, 23;
conv2:
fire count: 0, 0, 0, 0, 5, 15, 18, 13, 0, 0;
pooling2:
fire count: 0, 0, 6, 6, 0, 0, 1, 0, 1, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 7, 0, 22, 0;
output:
fire count: 0, 0, 1, 1, 1, 1, 35, 0, 1, 1;
epoch=107 time=1352.237s cost=9.031333 Momentum=0.900000 lrate=0.00009623
train performance: 99.61%
===================weight value================
conv1:
weight:-0.877786, -1.153820, -1.420792;
bias  :0.000000 0.000000
conv2:
weight:0.422009, 0.731807, 0.267438;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.301656;
bias  :0.000000
===================test Result================
test 99.34%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 18, 39, 23;
conv2:
fire count: 0, 0, 0, 0, 3, 14, 18, 14, 0, 0;
pooling2:
fire count: 0, 0, 5, 6, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 8, 0, 17, 0;
output:
fire count: 0, 0, 1, 1, 1, 1, 33, 0, 1, 1;
epoch=108 time=1287.356s cost=17.089500 Momentum=0.900000 lrate=0.00009578
train performance: 99.18%
===================weight value================
conv1:
weight:-0.886440, -1.168432, -1.438307;
bias  :0.000000 0.000000
conv2:
weight:0.472503, 0.761470, 0.256682;
bias  :0.000000 0.000000
hidden_0:
weight:-0.000000, -0.000000, 0.000001;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.301807;
bias  :0.000000
===================test Result================
test 98.69%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 20, 40, 26;
conv2:
fire count: 0, 0, 0, 0, 3, 13, 19, 15, 0, 0;
pooling2:
fire count: 0, 0, 6, 7, 0, 0, 2, 0, 1, 2;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 8, 0, 15, 0;
output:
fire count: 0, 1, 2, 1, 1, 1, 28, 0, 0, 1;
epoch=109 time=1389.724s cost=14.426567 Momentum=0.900000 lrate=0.00009535
train performance: 99.32%
===================weight value================
conv1:
weight:-0.919731, -1.222028, -1.496012;
bias  :0.000000 0.000000
conv2:
weight:0.493640, 0.765738, 0.238403;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.310401;
bias  :0.000000
===================test Result================
test 99.05%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 19, 38, 24;
conv2:
fire count: 0, 0, 0, 0, 1, 13, 20, 16, 0, 0;
pooling2:
fire count: 0, 0, 5, 8, 0, 0, 2, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 8, 0, 29, 0;
output:
fire count: 0, 1, 1, 1, 1, 0, 34, 0, 1, 1;
epoch=110 time=1373.569s cost=8.847934 Momentum=0.900000 lrate=0.00009492
train performance: 99.62%
===================weight value================
conv1:
weight:-0.876690, -1.175950, -1.476668;
bias  :0.000000 0.000000
conv2:
weight:0.503312, 0.761003, 0.232762;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.308122;
bias  :0.000000
===================test Result================
test 99.27%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 22, 41, 27;
conv2:
fire count: 0, 0, 0, 0, 3, 14, 19, 14, 0, 0;
pooling2:
fire count: 0, 0, 5, 7, 0, 0, 1, 0, 0, 1;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 7, 0, 23, 0;
output:
fire count: 0, 0, 1, 1, 1, 1, 34, 1, 1, 1;
epoch=111 time=1316.127s cost=15.848967 Momentum=0.900000 lrate=0.00009449
train performance: 99.24%
===================weight value================
conv1:
weight:-0.884869, -1.149025, -1.414189;
bias  :0.000000 0.000000
conv2:
weight:0.516594, 0.785457, 0.232665;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.308122;
bias  :0.000000
===================test Result================
test 98.92%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 24, 44, 27;
conv2:
fire count: 0, 0, 0, 0, 3, 15, 22, 16, 0, 0;
pooling2:
fire count: 0, 0, 7, 9, 0, 0, 3, 0, 1, 3;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 21, 0;
output:
fire count: 0, 0, 0, 1, 1, 1, 33, 1, 1, 1;
epoch=112 time=1319.256s cost=10.387000 Momentum=0.900000 lrate=0.00009407
train performance: 99.50%
===================weight value================
conv1:
weight:-0.907230, -1.186723, -1.486057;
bias  :0.000000 0.000000
conv2:
weight:0.511084, 0.771527, 0.229723;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.323050;
bias  :0.000000
===================test Result================
test 99.12%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 21, 41, 26;
conv2:
fire count: 0, 0, 0, 0, 3, 15, 21, 16, 0, 0;
pooling2:
fire count: 0, 0, 7, 9, 0, 0, 5, 0, 1, 3;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 28, 0;
output:
fire count: 0, 1, 0, 1, 1, 1, 39, 0, 0, 1;
epoch=113 time=1333.428s cost=11.506383 Momentum=0.900000 lrate=0.00009366
train performance: 99.50%
===================weight value================
conv1:
weight:-0.932135, -1.240059, -1.506375;
bias  :0.000000 0.000000
conv2:
weight:0.542962, 0.818679, 0.269063;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.323059;
bias  :0.000000
===================test Result================
test 99.27%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 21, 41, 25;
conv2:
fire count: 0, 0, 0, 0, 2, 16, 23, 17, 0, 0;
pooling2:
fire count: 0, 0, 8, 10, 0, 2, 5, 0, 1, 4;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 22, 0;
output:
fire count: 0, 1, 1, 0, 1, 1, 36, 0, 1, 1;
epoch=114 time=1349.354s cost=12.825483 Momentum=0.900000 lrate=0.00009325
train performance: 99.43%
===================weight value================
conv1:
weight:-0.929148, -1.202050, -1.511587;
bias  :0.000000 0.000000
conv2:
weight:0.541607, 0.805182, 0.240384;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.326399;
bias  :0.000000
===================test Result================
test 99.15%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 19, 39, 24;
conv2:
fire count: 0, 0, 0, 0, 1, 14, 21, 17, 0, 0;
pooling2:
fire count: 0, 0, 6, 10, 0, 1, 4, 0, 0, 3;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 6, 0, 20, 0;
output:
fire count: 0, 1, 1, 0, 1, 1, 37, 0, 1, 1;
epoch=115 time=1300.824s cost=9.977350 Momentum=0.900000 lrate=0.00009285
train performance: 99.54%
===================weight value================
conv1:
weight:-0.942452, -1.224997, -1.536502;
bias  :0.000000 0.000000
conv2:
weight:0.547909, 0.804044, 0.228226;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.329348;
bias  :0.000000
===================test Result================
test 98.98%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 19, 39, 24;
conv2:
fire count: 0, 0, 0, 0, 0, 13, 21, 16, 0, 0;
pooling2:
fire count: 0, 0, 6, 10, 0, 0, 4, 0, 0, 3;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 5, 0, 19, 0;
output:
fire count: 0, 0, 1, 1, 1, 1, 36, 0, 1, 1;
epoch=116 time=1340.604s cost=14.027133 Momentum=0.900000 lrate=0.00009245
train performance: 99.31%
===================weight value================
conv1:
weight:-0.909071, -1.183841, -1.500686;
bias  :0.000000 0.000000
conv2:
weight:0.530180, 0.764923, 0.201784;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.329348;
bias  :0.000000
===================test Result================
test 99.00%/99.41%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 20, 40, 26;
conv2:
fire count: 0, 0, 0, 0, 1, 17, 25, 18, 0, 0;
pooling2:
fire count: 0, 0, 9, 11, 0, 4, 6, 0, 0, 4;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 25, 0;
output:
fire count: 0, 0, 1, 0, 0, 1, 35, 1, 1, 1;
epoch=117 time=1359.757s cost=9.181033 Momentum=0.900000 lrate=0.00009206
train performance: 99.57%
===================weight value================
conv1:
weight:-0.947494, -1.211069, -1.491014;
bias  :0.000000 0.000000
conv2:
weight:0.511393, 0.751213, 0.194040;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.332272;
bias  :0.000000
===================test Result================
test 99.45%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 20, 39, 23;
conv2:
fire count: 0, 0, 0, 0, 0, 14, 21, 17, 0, 0;
pooling2:
fire count: 0, 0, 6, 9, 0, 2, 4, 0, 0, 2;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 2, 0, 23, 0;
output:
fire count: 0, 1, 0, 1, 1, 2, 37, 0, 0, 1;
epoch=118 time=1342.947s cost=9.796766 Momentum=0.900000 lrate=0.00009167
train performance: 99.53%
===================weight value================
conv1:
weight:-0.987308, -1.246602, -1.504451;
bias  :0.000000 0.000000
conv2:
weight:0.509917, 0.769422, 0.207595;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.335184;
bias  :0.000000
===================test Result================
test 99.36%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 22, 40, 23;
conv2:
fire count: 0, 0, 0, 0, 3, 16, 23, 17, 0, 0;
pooling2:
fire count: 0, 0, 8, 10, 0, 2, 5, 0, 0, 3;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 27, 0;
output:
fire count: 0, 0, 0, 1, 1, 1, 32, 0, 1, 1;
epoch=119 time=1310.425s cost=16.398733 Momentum=0.900000 lrate=0.00009129
train performance: 99.20%
===================weight value================
conv1:
weight:-0.950955, -1.271431, -1.570742;
bias  :0.000000 0.000000
conv2:
weight:0.486964, 0.750253, 0.208905;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, -0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.323215;
bias  :0.000000
===================test Result================
test 98.97%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 14, 33, 18;
conv2:
fire count: 0, 0, 0, 0, 1, 16, 22, 16, 0, 0;
pooling2:
fire count: 0, 0, 7, 9, 0, 2, 4, 1, 0, 3;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 7, 0, 22, 0;
output:
fire count: 0, 1, 0, 1, 1, 1, 37, 0, 1, 1;
epoch=120 time=1259.930s cost=10.590567 Momentum=0.900000 lrate=0.00009091
train performance: 99.50%
===================weight value================
conv1:
weight:-0.954571, -1.254151, -1.567383;
bias  :0.000000 0.000000
conv2:
weight:0.499628, 0.753337, 0.203533;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.328744;
bias  :0.000000
===================test Result================
test 99.13%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 16, 35, 20;
conv2:
fire count: 0, 0, 0, 0, 1, 15, 21, 16, 0, 0;
pooling2:
fire count: 0, 0, 6, 9, 0, 2, 3, 0, 1, 3;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 11, 0, 22, 0;
output:
fire count: 0, 1, 1, 1, 1, 1, 36, 0, 0, 1;
epoch=121 time=1261.175s cost=9.242017 Momentum=0.900000 lrate=0.00009054
train performance: 99.61%
===================weight value================
conv1:
weight:-0.975995, -1.244224, -1.528015;
bias  :0.000000 0.000000
conv2:
weight:0.477521, 0.746768, 0.232402;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.331820;
bias  :0.000000
===================test Result================
test 99.30%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 19, 39, 22;
conv2:
fire count: 0, 0, 0, 0, 2, 16, 21, 16, 0, 0;
pooling2:
fire count: 0, 0, 6, 8, 0, 1, 2, 0, 0, 3;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 9, 0, 20, 0;
output:
fire count: 0, 1, 0, 1, 0, 2, 37, 0, 1, 1;
epoch=122 time=1273.184s cost=8.754200 Momentum=0.900000 lrate=0.00009017
train performance: 99.61%
===================weight value================
conv1:
weight:-0.992008, -1.277092, -1.528875;
bias  :0.000000 0.000000
conv2:
weight:0.493254, 0.759650, 0.218665;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.337543;
bias  :0.000000
===================test Result================
test 99.31%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 20, 40, 22;
conv2:
fire count: 0, 0, 0, 0, 1, 15, 20, 15, 0, 0;
pooling2:
fire count: 0, 0, 6, 8, 0, 0, 3, 0, 0, 1;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 10, 0, 26, 0;
output:
fire count: 0, 0, 2, 2, 1, 1, 35, 0, 1, 1;
epoch=123 time=1331.216s cost=7.420183 Momentum=0.900000 lrate=0.00008980
train performance: 99.67%
===================weight value================
conv1:
weight:-1.018137, -1.290951, -1.572550;
bias  :0.000000 0.000000
conv2:
weight:0.426159, 0.683867, 0.195002;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.340395;
bias  :0.000000
===================test Result================
test 99.42%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 19, 38, 21;
conv2:
fire count: 0, 0, 0, 0, 1, 14, 19, 14, 0, 0;
pooling2:
fire count: 0, 0, 5, 8, 0, 1, 3, 0, 0, 2;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 15, 0, 24, 0;
output:
fire count: 0, 0, 1, 1, 1, 1, 37, 0, 1, 1;
epoch=124 time=1253.818s cost=10.011267 Momentum=0.900000 lrate=0.00008944
train performance: 99.52%
===================weight value================
conv1:
weight:-1.028075, -1.307708, -1.569264;
bias  :0.000000 0.000000
conv2:
weight:0.404216, 0.660553, 0.167997;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.340395;
bias  :0.000000
===================test Result================
test 99.16%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 21, 39, 21;
conv2:
fire count: 0, 0, 0, 0, 1, 13, 18, 13, 0, 0;
pooling2:
fire count: 0, 0, 3, 6, 0, 0, 0, 0, 0, 1;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 13, 0, 17, 0;
output:
fire count: 0, 1, 1, 1, 1, 1, 33, 0, 0, 1;
epoch=125 time=1316.962s cost=9.877916 Momentum=0.900000 lrate=0.00008909
train performance: 99.55%
===================weight value================
conv1:
weight:-1.063690, -1.310541, -1.587684;
bias  :0.000000 0.000000
conv2:
weight:0.449868, 0.723739, 0.196265;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, -0.000000, -0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.341251;
bias  :0.000000
===================test Result================
test 99.27%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 23, 42, 23;
conv2:
fire count: 0, 0, 0, 0, 2, 15, 19, 14, 0, 0;
pooling2:
fire count: 0, 0, 5, 7, 0, 0, 2, 0, 0, 2;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 10, 0, 28, 0;
output:
fire count: 0, 1, 1, 0, 1, 1, 36, 0, 1, 1;
epoch=126 time=1275.101s cost=10.521533 Momentum=0.900000 lrate=0.00008874
train performance: 99.53%
===================weight value================
conv1:
weight:-1.051579, -1.299031, -1.566320;
bias  :0.000000 0.000000
conv2:
weight:0.477906, 0.736533, 0.176527;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.349689;
bias  :0.000000
===================test Result================
test 99.28%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 24, 43, 24;
conv2:
fire count: 0, 0, 0, 0, 3, 15, 19, 14, 0, 0;
pooling2:
fire count: 0, 0, 5, 7, 0, 0, 0, 0, 0, 1;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 4, 0, 23, 0;
output:
fire count: 0, 0, 1, 1, 0, 2, 35, 0, 2, 1;
epoch=127 time=1223.754s cost=12.589084 Momentum=0.900000 lrate=0.00008839
train performance: 99.39%
===================weight value================
conv1:
weight:-1.039725, -1.300187, -1.568719;
bias  :0.000000 0.000000
conv2:
weight:0.498764, 0.751343, 0.154085;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.355303;
bias  :0.000000
===================test Result================
test 98.83%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 1, 25, 44, 25;
conv2:
fire count: 0, 0, 0, 0, 2, 14, 18, 13, 0, 0;
pooling2:
fire count: 0, 0, 3, 6, 0, 0, 1, 0, 0, 1;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 6, 0, 19, 0;
output:
fire count: 0, 1, 1, 1, 0, 2, 32, 0, 1, 1;
epoch=128 time=1230.012s cost=9.021934 Momentum=0.900000 lrate=0.00008805
train performance: 99.60%
===================weight value================
conv1:
weight:-1.025911, -1.305233, -1.617872;
bias  :0.000000 0.000000
conv2:
weight:0.527364, 0.767626, 0.156546;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.358100;
bias  :0.000000
===================test Result================
test 99.34%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 23, 42, 25;
conv2:
fire count: 0, 0, 0, 0, 2, 15, 20, 15, 0, 0;
pooling2:
fire count: 0, 0, 6, 9, 0, 2, 3, 0, 0, 1;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 4, 0, 27, 0;
output:
fire count: 1, 1, 1, 1, 0, 1, 36, 1, 0, 1;
epoch=129 time=1215.660s cost=9.696234 Momentum=0.900000 lrate=0.00008771
train performance: 99.56%
===================weight value================
conv1:
weight:-1.050757, -1.324091, -1.637137;
bias  :0.000000 0.000000
conv2:
weight:0.509071, 0.758637, 0.160918;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, -0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.366457;
bias  :0.000000
===================test Result================
test 99.17%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 23, 41, 24;
conv2:
fire count: 0, 0, 0, 0, 3, 16, 21, 15, 0, 0;
pooling2:
fire count: 0, 0, 7, 9, 0, 4, 4, 1, 0, 2;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 29, 0;
output:
fire count: 0, 1, 1, 1, 1, 2, 38, 0, 1, 1;
epoch=130 time=1261.765s cost=16.608084 Momentum=0.900000 lrate=0.00008737
train performance: 99.19%
===================weight value================
conv1:
weight:-1.090522, -1.374344, -1.692362;
bias  :0.000000 0.000000
conv2:
weight:0.421077, 0.667882, 0.074897;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.374313;
bias  :0.000000
===================test Result================
test 98.79%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 18, 36, 19;
conv2:
fire count: 0, 0, 0, 0, 0, 12, 17, 12, 0, 0;
pooling2:
fire count: 0, 0, 4, 7, 0, 2, 3, 1, 0, 2;
hidden_0:
fire count: 0, 0, 0, 0, 1, 0, 15, 0, 18, 0;
output:
fire count: 0, 1, 1, 1, 1, 1, 37, 0, 1, 1;
epoch=131 time=1230.029s cost=26.410017 Momentum=0.900000 lrate=0.00008704
train performance: 98.59%
===================weight value================
conv1:
weight:-1.049413, -1.341643, -1.661539;
bias  :0.000000 0.000000
conv2:
weight:0.390569, 0.645192, 0.084906;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.385245;
bias  :0.000000
===================test Result================
test 98.84%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 20, 39, 23;
conv2:
fire count: 0, 0, 0, 0, 2, 15, 20, 14, 0, 0;
pooling2:
fire count: 0, 0, 8, 9, 0, 5, 7, 1, 0, 4;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 6, 0, 21, 0;
output:
fire count: 0, 1, 2, 2, 1, 0, 33, 1, 0, 1;
epoch=132 time=1282.359s cost=7.680267 Momentum=0.900000 lrate=0.00008671
train performance: 99.64%
===================weight value================
conv1:
weight:-1.056427, -1.343136, -1.654197;
bias  :0.000000 0.000000
conv2:
weight:0.382209, 0.651140, 0.087414;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.385245;
bias  :0.000000
===================test Result================
test 99.18%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 23, 41, 24;
conv2:
fire count: 0, 0, 0, 0, 1, 13, 18, 13, 0, 0;
pooling2:
fire count: 0, 0, 6, 8, 0, 3, 5, 0, 0, 4;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 13, 0, 27, 0;
output:
fire count: 1, 1, 2, 2, 0, 1, 38, 0, 0, 1;
epoch=133 time=1300.414s cost=16.377317 Momentum=0.900000 lrate=0.00008639
train performance: 99.23%
===================weight value================
conv1:
weight:-1.084287, -1.376306, -1.696014;
bias  :0.000000 0.000000
conv2:
weight:0.320868, 0.588745, 0.040974;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.388020;
bias  :0.000000
===================test Result================
test 98.30%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 15, 33, 17;
conv2:
fire count: 0, 0, 0, 0, 0, 9, 14, 11, 0, 0;
pooling2:
fire count: 0, 0, 1, 6, 0, 2, 3, 1, 0, 2;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 26, 0, 16, 0;
output:
fire count: 0, 1, 2, 2, 0, 0, 37, 0, 1, 1;
epoch=134 time=1275.085s cost=16.149433 Momentum=0.900000 lrate=0.00008607
train performance: 99.20%
===================weight value================
conv1:
weight:-1.065701, -1.348765, -1.679038;
bias  :0.000000 0.000000
conv2:
weight:0.317659, 0.618930, 0.090651;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.393738;
bias  :0.000000
===================test Result================
test 98.83%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 15, 34, 19;
conv2:
fire count: 0, 0, 0, 0, 0, 12, 17, 12, 0, 0;
pooling2:
fire count: 0, 0, 5, 7, 0, 3, 4, 0, 0, 3;
hidden_0:
fire count: 0, 0, 0, 0, 1, 0, 20, 0, 17, 0;
output:
fire count: 1, 1, 2, 1, 0, 1, 35, 0, 0, 1;
epoch=135 time=1285.112s cost=8.427983 Momentum=0.900000 lrate=0.00008575
train performance: 99.62%
===================weight value================
conv1:
weight:-1.090430, -1.358728, -1.684975;
bias  :0.000000 0.000000
conv2:
weight:0.353158, 0.661252, 0.127778;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.407201;
bias  :0.000000
===================test Result================
test 99.27%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 17, 35, 21;
conv2:
fire count: 0, 0, 0, 0, 0, 13, 18, 13, 0, 0;
pooling2:
fire count: 0, 0, 6, 7, 0, 3, 5, 0, 0, 2;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 17, 0, 26, 0;
output:
fire count: 0, 1, 3, 1, 0, 2, 38, 0, 1, 1;
epoch=136 time=1287.619s cost=9.195066 Momentum=0.900000 lrate=0.00008544
train performance: 99.62%
===================weight value================
conv1:
weight:-1.111493, -1.396342, -1.707347;
bias  :0.000000 0.000000
conv2:
weight:0.343017, 0.676961, 0.135629;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.417961;
bias  :0.000000
===================test Result================
test 99.29%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 17, 36, 21;
conv2:
fire count: 0, 0, 0, 0, 0, 13, 18, 13, 0, 0;
pooling2:
fire count: 0, 0, 6, 7, 0, 4, 4, 1, 0, 3;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 10, 0, 25, 0;
output:
fire count: 1, 1, 2, 1, 0, 1, 39, 0, 1, 1;
epoch=137 time=1348.665s cost=8.389767 Momentum=0.900000 lrate=0.00008513
train performance: 99.62%
===================weight value================
conv1:
weight:-1.117200, -1.412476, -1.716501;
bias  :0.000000 0.000000
conv2:
weight:0.360534, 0.693771, 0.139121;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.417961;
bias  :0.000000
===================test Result================
test 99.32%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 22, 41, 23;
conv2:
fire count: 0, 0, 0, 0, 3, 17, 21, 15, 0, 0;
pooling2:
fire count: 0, 0, 8, 9, 0, 6, 6, 2, 0, 5;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 4, 0, 27, 0;
output:
fire count: 0, 1, 2, 0, 1, 2, 41, 0, 1, 1;
epoch=138 time=1319.240s cost=8.459784 Momentum=0.900000 lrate=0.00008482
train performance: 99.60%
===================weight value================
conv1:
weight:-1.125394, -1.411500, -1.736854;
bias  :0.000000 0.000000
conv2:
weight:0.374027, 0.693302, 0.132647;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.425945;
bias  :0.000000
===================test Result================
test 99.31%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 20, 39, 22;
conv2:
fire count: 0, 0, 0, 0, 0, 15, 19, 13, 0, 0;
pooling2:
fire count: 0, 0, 6, 8, 0, 5, 5, 2, 0, 4;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 7, 0, 20, 0;
output:
fire count: 0, 1, 1, 1, 0, 1, 39, 0, 1, 1;
epoch=139 time=1341.309s cost=10.931233 Momentum=0.900000 lrate=0.00008452
train performance: 99.51%
===================weight value================
conv1:
weight:-1.163258, -1.401722, -1.711933;
bias  :0.000000 0.000000
conv2:
weight:0.402941, 0.723716, 0.155428;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.425945;
bias  :0.000000
===================test Result================
test 99.30%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 23, 42, 24;
conv2:
fire count: 0, 0, 0, 0, 1, 16, 20, 14, 0, 0;
pooling2:
fire count: 0, 0, 7, 8, 0, 5, 5, 1, 0, 4;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 26, 0;
output:
fire count: 1, 1, 1, 1, 0, 1, 40, 0, 1, 1;
epoch=140 time=1331.970s cost=12.158050 Momentum=0.900000 lrate=0.00008422
train performance: 99.42%
===================weight value================
conv1:
weight:-1.197966, -1.436325, -1.752362;
bias  :0.000000 0.000000
conv2:
weight:0.362185, 0.656531, 0.094835;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.417637;
bias  :0.000000
===================test Result================
test 98.97%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 17, 36, 21;
conv2:
fire count: 0, 0, 0, 0, 0, 12, 17, 13, 0, 0;
pooling2:
fire count: 0, 0, 5, 7, 0, 4, 4, 3, 0, 3;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 12, 0, 18, 0;
output:
fire count: 1, 1, 1, 1, 0, 1, 36, 0, 1, 1;
epoch=141 time=1306.083s cost=9.162534 Momentum=0.900000 lrate=0.00008392
train performance: 99.63%
===================weight value================
conv1:
weight:-1.204137, -1.430326, -1.735094;
bias  :0.000000 0.000000
conv2:
weight:0.365426, 0.665579, 0.075403;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.417637;
bias  :0.000000
===================test Result================
test 99.30%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 20, 39, 22;
conv2:
fire count: 0, 0, 0, 0, 0, 12, 16, 12, 0, 0;
pooling2:
fire count: 0, 0, 5, 7, 0, 4, 3, 2, 0, 1;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 5, 0, 19, 0;
output:
fire count: 1, 1, 2, 1, 0, 1, 38, 0, 1, 1;
epoch=142 time=1294.221s cost=8.744083 Momentum=0.900000 lrate=0.00008362
train performance: 99.62%
===================weight value================
conv1:
weight:-1.229874, -1.461963, -1.785203;
bias  :0.000000 0.000000
conv2:
weight:0.309615, 0.625129, 0.070732;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.417637;
bias  :0.000000
===================test Result================
test 99.29%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 18, 36, 20;
conv2:
fire count: 0, 0, 0, 0, 0, 8, 14, 10, 0, 0;
pooling2:
fire count: 0, 0, 3, 5, 0, 2, 2, 1, 0, 1;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 14, 0, 12, 0;
output:
fire count: 0, 1, 2, 1, 1, 1, 36, 0, 1, 1;
epoch=143 time=1310.130s cost=11.294333 Momentum=0.900000 lrate=0.00008333
train performance: 99.49%
===================weight value================
conv1:
weight:-1.202691, -1.444235, -1.804162;
bias  :0.000000 0.000000
conv2:
weight:0.325394, 0.644604, 0.078541;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.422931;
bias  :0.000000
===================test Result================
test 99.30%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 18, 36, 21;
conv2:
fire count: 0, 0, 0, 0, 0, 11, 16, 13, 0, 0;
pooling2:
fire count: 0, 0, 4, 6, 0, 3, 3, 2, 0, 2;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 15, 0, 16, 0;
output:
fire count: 0, 1, 2, 1, 1, 1, 35, 0, 1, 1;
epoch=144 time=1296.777s cost=17.594650 Momentum=0.900000 lrate=0.00008305
train performance: 99.15%
===================weight value================
conv1:
weight:-1.200439, -1.430343, -1.846313;
bias  :0.000000 0.000000
conv2:
weight:0.383397, 0.702087, 0.106330;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.425569;
bias  :0.000000
===================test Result================
test 99.01%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 15, 34, 20;
conv2:
fire count: 0, 0, 0, 0, 0, 8, 16, 12, 0, 0;
pooling2:
fire count: 0, 0, 3, 7, 0, 2, 4, 2, 0, 1;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 13, 0, 22, 0;
output:
fire count: 0, 0, 2, 1, 1, 1, 36, 0, 1, 1;
epoch=145 time=1298.022s cost=9.245934 Momentum=0.900000 lrate=0.00008276
train performance: 99.64%
===================weight value================
conv1:
weight:-1.179345, -1.377624, -1.807526;
bias  :0.000000 0.000000
conv2:
weight:0.371156, 0.701326, 0.121877;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.432976;
bias  :0.000000
===================test Result================
test 99.31%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 19, 39, 24;
conv2:
fire count: 0, 0, 0, 0, 0, 12, 18, 13, 0, 0;
pooling2:
fire count: 0, 0, 5, 7, 0, 2, 3, 1, 0, 2;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 5, 0, 27, 0;
output:
fire count: 0, 0, 2, 1, 1, 0, 39, 0, 2, 1;
epoch=146 time=1268.285s cost=8.326016 Momentum=0.900000 lrate=0.00008248
train performance: 99.66%
===================weight value================
conv1:
weight:-1.193879, -1.405183, -1.821993;
bias  :0.000000 0.000000
conv2:
weight:0.343981, 0.671233, 0.093580;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.430356;
bias  :0.000000
===================test Result================
test 99.29%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 15, 35, 20;
conv2:
fire count: 0, 0, 0, 0, 0, 7, 13, 9, 0, 0;
pooling2:
fire count: 0, 0, 0, 4, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 13, 0, 18, 0;
output:
fire count: 0, 1, 2, 1, 1, 2, 37, 0, 1, 1;
epoch=147 time=1275.494s cost=10.670200 Momentum=0.900000 lrate=0.00008220
train performance: 99.54%
===================weight value================
conv1:
weight:-1.210555, -1.422365, -1.823048;
bias  :0.000000 0.000000
conv2:
weight:0.333785, 0.662402, 0.109228;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.432967;
bias  :0.000000
===================test Result================
test 99.31%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 18, 36, 21;
conv2:
fire count: 0, 0, 0, 0, 0, 9, 15, 11, 0, 0;
pooling2:
fire count: 0, 0, 3, 5, 0, 2, 1, 1, 0, 1;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 5, 0, 21, 0;
output:
fire count: 0, 0, 0, 1, 1, 2, 38, 1, 1, 1;
epoch=148 time=1260.651s cost=11.238650 Momentum=0.900000 lrate=0.00008192
train performance: 99.51%
===================weight value================
conv1:
weight:-1.215455, -1.429113, -1.836685;
bias  :0.000000 0.000000
conv2:
weight:0.332739, 0.643640, 0.097408;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.435569;
bias  :0.000000
===================test Result================
test 99.31%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 14, 32, 17;
conv2:
fire count: 0, 0, 0, 0, 0, 6, 13, 9, 0, 0;
pooling2:
fire count: 0, 0, 0, 4, 0, 0, 1, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 11, 0, 14, 0;
output:
fire count: 1, 0, 1, 1, 0, 2, 35, 1, 1, 1;
epoch=149 time=1256.358s cost=15.039166 Momentum=0.900000 lrate=0.00008165
train performance: 99.28%
===================weight value================
conv1:
weight:-1.207285, -1.443631, -1.834904;
bias  :0.000000 0.000000
conv2:
weight:0.364369, 0.663320, 0.090595;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.432976;
bias  :0.000000
===================test Result================
test 99.26%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 16, 36, 19;
conv2:
fire count: 0, 0, 0, 0, 0, 7, 15, 11, 0, 0;
pooling2:
fire count: 0, 0, 2, 6, 0, 2, 2, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 5, 0, 25, 0;
output:
fire count: 0, 1, 1, 1, 1, 2, 35, 0, 1, 1;
epoch=150 time=1233.420s cost=20.160084 Momentum=0.900000 lrate=0.00008138
train performance: 99.01%
===================weight value================
conv1:
weight:-1.244600, -1.456944, -1.814363;
bias  :0.000000 0.000000
conv2:
weight:0.347225, 0.630406, 0.082153;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.435560;
bias  :0.000000
===================test Result================
test 98.92%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 17, 36, 19;
conv2:
fire count: 0, 0, 0, 0, 0, 6, 14, 11, 0, 0;
pooling2:
fire count: 0, 0, 0, 4, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 10, 0, 14, 0;
output:
fire count: 1, 1, 0, 0, 1, 2, 30, 0, 1, 2;
epoch=151 time=1288.831s cost=9.243900 Momentum=0.900000 lrate=0.00008111
train performance: 99.61%
===================weight value================
conv1:
weight:-1.203876, -1.422566, -1.808635;
bias  :0.000000 0.000000
conv2:
weight:0.415368, 0.682404, 0.114950;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.438136;
bias  :0.000000
===================test Result================
test 99.20%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 22, 40, 24;
conv2:
fire count: 0, 0, 0, 0, 3, 15, 21, 15, 0, 0;
pooling2:
fire count: 0, 0, 7, 8, 0, 4, 5, 1, 0, 3;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 29, 0;
output:
fire count: 0, 1, 0, 1, 1, 1, 38, 1, 1, 2;
epoch=152 time=1258.897s cost=13.668417 Momentum=0.900000 lrate=0.00008085
train performance: 99.33%
===================weight value================
conv1:
weight:-1.198597, -1.460946, -1.870819;
bias  :0.000000 0.000000
conv2:
weight:0.357121, 0.636093, 0.089104;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.440438;
bias  :0.000000
===================test Result================
test 98.87%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 15, 34, 19;
conv2:
fire count: 0, 0, 0, 0, 0, 6, 13, 10, 0, 0;
pooling2:
fire count: 0, 0, 0, 4, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 17, 0, 14, 0;
output:
fire count: 0, 1, 1, 1, 1, 0, 36, 0, 1, 1;
epoch=153 time=1267.122s cost=19.254984 Momentum=0.900000 lrate=0.00008058
train performance: 99.04%
===================weight value================
conv1:
weight:-1.211599, -1.491394, -1.922920;
bias  :0.000000 0.000000
conv2:
weight:0.401938, 0.669503, 0.108070;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, -0.000003, 0.000027;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.458680;
bias  :0.000000
===================test Result================
test 98.66%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 11, 28, 15;
conv2:
fire count: 0, 0, 0, 0, 0, 7, 14, 11, 0, 0;
pooling2:
fire count: 0, 0, 2, 5, 0, 2, 2, 1, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 18, 0, 16, 0;
output:
fire count: 0, 1, 1, 1, 1, 0, 38, 0, 1, 1;
epoch=154 time=1285.587s cost=10.361417 Momentum=0.900000 lrate=0.00008032
train performance: 99.55%
===================weight value================
conv1:
weight:-1.231935, -1.516436, -1.884747;
bias  :0.000000 0.000000
conv2:
weight:0.418353, 0.691432, 0.083178;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.461231;
bias  :0.000000
===================test Result================
test 99.26%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 17, 36, 20;
conv2:
fire count: 0, 0, 0, 0, 0, 10, 17, 13, 0, 0;
pooling2:
fire count: 0, 0, 3, 7, 0, 2, 3, 1, 0, 1;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 7, 0, 25, 0;
output:
fire count: 0, 1, 0, 1, 1, 3, 35, 0, 1, 1;
epoch=155 time=1274.282s cost=11.475667 Momentum=0.900000 lrate=0.00008006
train performance: 99.51%
===================weight value================
conv1:
weight:-1.238149, -1.542891, -1.950502;
bias  :0.000000 0.000000
conv2:
weight:0.398337, 0.665323, 0.060140;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.461231;
bias  :0.000000
===================test Result================
test 99.25%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 14, 31, 16;
conv2:
fire count: 0, 0, 0, 0, 0, 5, 12, 9, 0, 0;
pooling2:
fire count: 0, 0, 0, 3, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 18, 0, 16, 0;
output:
fire count: 0, 1, 1, 0, 1, 1, 34, 0, 1, 1;
epoch=156 time=1258.684s cost=7.810550 Momentum=0.900000 lrate=0.00007981
train performance: 99.68%
===================weight value================
conv1:
weight:-1.220637, -1.544421, -1.956888;
bias  :0.000000 0.000000
conv2:
weight:0.412390, 0.702228, 0.104370;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, -0.000001, -0.000001;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.463766;
bias  :0.000000
===================test Result================
test 99.32%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 15, 33, 17;
conv2:
fire count: 0, 0, 0, 0, 0, 8, 15, 12, 0, 0;
pooling2:
fire count: 0, 0, 1, 6, 0, 1, 1, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 15, 0, 23, 0;
output:
fire count: 0, 1, 1, 0, 1, 1, 34, 0, 1, 1;
epoch=157 time=1323.860s cost=11.977734 Momentum=0.900000 lrate=0.00007956
train performance: 99.42%
===================weight value================
conv1:
weight:-1.244280, -1.562153, -1.974661;
bias  :0.000000 0.000000
conv2:
weight:0.406133, 0.700415, 0.109301;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.468819;
bias  :0.000000
===================test Result================
test 99.17%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 13, 31, 16;
conv2:
fire count: 0, 0, 0, 0, 0, 8, 15, 12, 0, 0;
pooling2:
fire count: 0, 0, 2, 6, 0, 2, 2, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 19, 0, 21, 0;
output:
fire count: 0, 1, 1, 0, 1, 0, 35, 1, 1, 1;
epoch=158 time=1324.466s cost=6.097133 Momentum=0.900000 lrate=0.00007931
train performance: 99.75%
===================weight value================
conv1:
weight:-1.254894, -1.566793, -1.964504;
bias  :0.000000 0.000000
conv2:
weight:0.407114, 0.742044, 0.154216;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.468819;
bias  :0.000000
===================test Result================
test 99.37%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 15, 32, 16;
conv2:
fire count: 0, 0, 0, 0, 0, 7, 16, 13, 0, 0;
pooling2:
fire count: 0, 0, 0, 6, 0, 1, 2, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 16, 0, 19, 0;
output:
fire count: 0, 1, 1, 0, 1, 1, 36, 0, 1, 1;
epoch=159 time=1307.410s cost=8.881150 Momentum=0.900000 lrate=0.00007906
train performance: 99.59%
===================weight value================
conv1:
weight:-1.266356, -1.569412, -1.981087;
bias  :0.000000 0.000000
conv2:
weight:0.438614, 0.784978, 0.195212;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.473183;
bias  :0.000000
===================test Result================
test 99.20%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 13, 29, 15;
conv2:
fire count: 0, 0, 0, 0, 0, 8, 17, 14, 0, 0;
pooling2:
fire count: 0, 0, 2, 7, 0, 2, 3, 1, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 17, 0, 21, 0;
output:
fire count: 0, 1, 1, 0, 1, 0, 35, 1, 1, 1;
epoch=160 time=1264.697s cost=7.792233 Momentum=0.900000 lrate=0.00007881
train performance: 99.66%
===================weight value================
conv1:
weight:-1.282345, -1.590994, -1.975569;
bias  :0.000000 0.000000
conv2:
weight:0.430151, 0.776756, 0.192848;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.480686;
bias  :0.000000
===================test Result================
test 99.06%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 16, 34, 17;
conv2:
fire count: 0, 0, 0, 0, 0, 8, 16, 12, 0, 0;
pooling2:
fire count: 0, 0, 0, 4, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 16, 0, 19, 0;
output:
fire count: 0, 1, 1, 1, 1, 0, 35, 0, 1, 1;
epoch=161 time=1326.252s cost=9.470950 Momentum=0.900000 lrate=0.00007857
train performance: 99.58%
===================weight value================
conv1:
weight:-1.322149, -1.578849, -1.934813;
bias  :0.000000 0.000000
conv2:
weight:0.501750, 0.843745, 0.232792;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.483182;
bias  :0.000000
===================test Result================
test 99.27%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 20, 37, 21;
conv2:
fire count: 0, 0, 0, 0, 0, 10, 18, 14, 0, 0;
pooling2:
fire count: 0, 0, 3, 7, 0, 0, 2, 1, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 18, 0, 26, 0;
output:
fire count: 0, 1, 1, 0, 1, 0, 34, 0, 1, 1;
epoch=162 time=1316.094s cost=11.766633 Momentum=0.900000 lrate=0.00007833
train performance: 99.41%
===================weight value================
conv1:
weight:-1.332286, -1.581410, -1.944535;
bias  :0.000000 0.000000
conv2:
weight:0.520007, 0.836484, 0.229395;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.483176;
bias  :0.000000
===================test Result================
test 99.09%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 19, 36, 18;
conv2:
fire count: 0, 0, 0, 0, 0, 12, 19, 14, 0, 0;
pooling2:
fire count: 0, 0, 5, 7, 0, 2, 3, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 12, 0, 25, 0;
output:
fire count: 0, 1, 2, 1, 1, 0, 31, 0, 1, 1;
epoch=163 time=1331.626s cost=13.629517 Momentum=0.900000 lrate=0.00007809
train performance: 99.31%
===================weight value================
conv1:
weight:-1.330041, -1.562317, -1.968371;
bias  :0.000000 0.000000
conv2:
weight:0.524729, 0.859648, 0.247240;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.483176;
bias  :0.000000
===================test Result================
test 98.82%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 19, 35, 20;
conv2:
fire count: 0, 0, 0, 0, 0, 10, 18, 14, 0, 0;
pooling2:
fire count: 0, 0, 3, 7, 0, 0, 1, 1, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 21, 0, 17, 0;
output:
fire count: 0, 1, 1, 0, 1, 1, 34, 0, 1, 1;
epoch=164 time=1260.667s cost=13.019550 Momentum=0.900000 lrate=0.00007785
train performance: 99.38%
===================weight value================
conv1:
weight:-1.344446, -1.565248, -1.939932;
bias  :0.000000 0.000000
conv2:
weight:0.564098, 0.886984, 0.255939;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.485648;
bias  :0.000000
===================test Result================
test 99.01%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 21, 38, 21;
conv2:
fire count: 0, 0, 0, 0, 1, 11, 18, 13, 0, 0;
pooling2:
fire count: 0, 0, 3, 6, 0, 0, 1, 1, 0, 1;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 14, 0, 26, 0;
output:
fire count: 0, 1, 1, 0, 1, 1, 31, 0, 1, 1;
epoch=165 time=1367.654s cost=11.092800 Momentum=0.900000 lrate=0.00007762
train performance: 99.49%
===================weight value================
conv1:
weight:-1.342423, -1.577136, -1.973299;
bias  :0.000000 0.000000
conv2:
weight:0.521405, 0.835851, 0.221493;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.485648;
bias  :0.000000
===================test Result================
test 99.08%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 17, 33, 17;
conv2:
fire count: 0, 0, 0, 0, 0, 8, 16, 12, 0, 0;
pooling2:
fire count: 0, 0, 2, 5, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 20, 0, 13, 0;
output:
fire count: 0, 1, 1, 0, 1, 0, 37, 0, 1, 1;
epoch=166 time=1292.747s cost=8.189867 Momentum=0.900000 lrate=0.00007738
train performance: 99.64%
===================weight value================
conv1:
weight:-1.343303, -1.565141, -1.959185;
bias  :0.000000 0.000000
conv2:
weight:0.549844, 0.843703, 0.214054;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.488106;
bias  :0.000000
===================test Result================
test 99.25%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 19, 35, 18;
conv2:
fire count: 0, 0, 0, 0, 0, 9, 15, 11, 0, 0;
pooling2:
fire count: 0, 0, 2, 4, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 14, 0, 21, 0;
output:
fire count: 0, 0, 1, 0, 1, 1, 35, 0, 1, 1;
epoch=167 time=1259.471s cost=7.509050 Momentum=0.900000 lrate=0.00007715
train performance: 99.68%
===================weight value================
conv1:
weight:-1.378792, -1.586209, -1.953351;
bias  :0.000000 0.000000
conv2:
weight:0.573406, 0.866876, 0.244579;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.490556;
bias  :0.000000
===================test Result================
test 99.28%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 20, 37, 17;
conv2:
fire count: 0, 0, 0, 0, 0, 8, 15, 12, 0, 0;
pooling2:
fire count: 0, 0, 2, 5, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 13, 0, 19, 0;
output:
fire count: 0, 0, 1, 0, 1, 1, 34, 0, 1, 1;
epoch=168 time=1326.612s cost=11.552283 Momentum=0.900000 lrate=0.00007692
train performance: 99.47%
===================weight value================
conv1:
weight:-1.387307, -1.607719, -1.973054;
bias  :0.000000 0.000000
conv2:
weight:0.587296, 0.901644, 0.267256;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.485669;
bias  :0.000000
===================test Result================
test 99.07%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 20, 34, 17;
conv2:
fire count: 0, 0, 0, 0, 0, 9, 17, 12, 0, 0;
pooling2:
fire count: 0, 0, 3, 5, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 20, 0, 16, 0;
output:
fire count: 0, 0, 1, 0, 1, 1, 37, 0, 0, 1;
epoch=169 time=1307.902s cost=8.807983 Momentum=0.900000 lrate=0.00007670
train performance: 99.58%
===================weight value================
conv1:
weight:-1.359159, -1.560397, -1.963427;
bias  :0.000000 0.000000
conv2:
weight:0.610046, 0.907277, 0.247883;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.492978;
bias  :0.000000
===================test Result================
test 99.06%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 21, 36, 18;
conv2:
fire count: 0, 0, 0, 0, 0, 9, 16, 12, 0, 0;
pooling2:
fire count: 0, 0, 3, 5, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 16, 0, 21, 0;
output:
fire count: 0, 0, 1, 0, 1, 1, 34, 0, 1, 1;
epoch=170 time=1350.631s cost=11.580383 Momentum=0.900000 lrate=0.00007647
train performance: 99.43%
===================weight value================
conv1:
weight:-1.381562, -1.567015, -1.964736;
bias  :0.000000 0.000000
conv2:
weight:0.604351, 0.900699, 0.244347;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000001, 0.000076;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.497834;
bias  :0.000000
===================test Result================
test 99.08%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 21, 36, 17;
conv2:
fire count: 0, 0, 0, 0, 0, 7, 14, 11, 0, 0;
pooling2:
fire count: 0, 0, 2, 3, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 22, 0, 11, 0;
output:
fire count: 0, 0, 1, 0, 0, 0, 33, 0, 1, 1;
epoch=171 time=1354.744s cost=12.425117 Momentum=0.900000 lrate=0.00007625
train performance: 99.41%
===================weight value================
conv1:
weight:-1.434313, -1.585432, -1.903903;
bias  :0.000000 0.000000
conv2:
weight:0.635217, 0.931839, 0.262545;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.511912;
bias  :0.000000
===================test Result================
test 99.12%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 3, 27, 41, 20;
conv2:
fire count: 0, 0, 0, 0, 1, 11, 17, 14, 0, 0;
pooling2:
fire count: 0, 0, 4, 5, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 9, 0, 30, 0;
output:
fire count: 0, 0, 1, 0, 0, 2, 32, 0, 1, 1;
epoch=172 time=1314.554s cost=8.503933 Momentum=0.900000 lrate=0.00007603
train performance: 99.60%
===================weight value================
conv1:
weight:-1.411383, -1.586753, -1.913256;
bias  :0.000000 0.000000
conv2:
weight:0.658223, 0.943817, 0.257496;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.511912;
bias  :0.000000
===================test Result================
test 99.14%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 2, 26, 41, 19;
conv2:
fire count: 0, 0, 0, 0, 1, 9, 14, 12, 0, 0;
pooling2:
fire count: 0, 0, 1, 4, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 11, 0, 31, 0;
output:
fire count: 0, 0, 1, 0, 0, 2, 34, 0, 1, 1;
epoch=173 time=1331.069s cost=15.572350 Momentum=0.900000 lrate=0.00007581
train performance: 99.22%
===================weight value================
conv1:
weight:-1.431392, -1.601793, -1.933102;
bias  :0.000000 0.000000
conv2:
weight:0.671410, 0.950450, 0.259658;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.514320;
bias  :0.000000
===================test Result================
test 98.87%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 2, 25, 41, 20;
conv2:
fire count: 0, 0, 0, 0, 0, 9, 16, 14, 0, 0;
pooling2:
fire count: 0, 0, 3, 6, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 14, 0, 28, 0;
output:
fire count: 0, 0, 1, 0, 0, 1, 32, 0, 1, 1;
epoch=174 time=1396.769s cost=9.971884 Momentum=0.900000 lrate=0.00007559
train performance: 99.55%
===================weight value================
conv1:
weight:-1.423109, -1.577718, -1.940438;
bias  :0.000000 0.000000
conv2:
weight:0.651886, 0.925988, 0.234934;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.516721;
bias  :0.000000
===================test Result================
test 99.12%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 22, 37, 17;
conv2:
fire count: 0, 0, 0, 0, 0, 6, 13, 10, 0, 0;
pooling2:
fire count: 0, 0, 0, 3, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 18, 0, 18, 0;
output:
fire count: 0, 0, 1, 1, 0, 1, 34, 0, 1, 1;
epoch=175 time=1334.051s cost=9.580684 Momentum=0.900000 lrate=0.00007538
train performance: 99.56%
===================weight value================
conv1:
weight:-1.427927, -1.564696, -1.927512;
bias  :0.000000 0.000000
conv2:
weight:0.664739, 0.949660, 0.243961;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.519116;
bias  :0.000000
===================test Result================
test 99.18%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 22, 36, 16;
conv2:
fire count: 0, 0, 0, 0, 0, 6, 14, 11, 0, 0;
pooling2:
fire count: 0, 0, 0, 4, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 16, 0, 21, 0;
output:
fire count: 0, 0, 1, 1, 0, 1, 31, 0, 1, 1;
epoch=176 time=1345.274s cost=9.725550 Momentum=0.900000 lrate=0.00007516
train performance: 99.59%
===================weight value================
conv1:
weight:-1.468351, -1.584511, -1.919127;
bias  :0.000000 0.000000
conv2:
weight:0.684354, 0.958765, 0.235179;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.519116;
bias  :0.000000
===================test Result================
test 99.25%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 19, 33, 13;
conv2:
fire count: 0, 0, 0, 0, 0, 6, 14, 13, 0, 0;
pooling2:
fire count: 0, 0, 2, 5, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 19, 0, 17, 0;
output:
fire count: 0, 0, 1, 1, 0, 2, 34, 0, 1, 1;
epoch=177 time=1372.471s cost=9.501166 Momentum=0.900000 lrate=0.00007495
train performance: 99.57%
===================weight value================
conv1:
weight:-1.455285, -1.581508, -1.898945;
bias  :0.000000 0.000000
conv2:
weight:0.729430, 0.990735, 0.238397;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.526103;
bias  :0.000000
===================test Result================
test 99.09%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 21, 34, 14;
conv2:
fire count: 0, 0, 0, 0, 0, 7, 16, 14, 0, 0;
pooling2:
fire count: 0, 0, 3, 7, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 17, 0, 21, 0;
output:
fire count: 0, 0, 1, 1, 0, 2, 34, 0, 1, 1;
epoch=178 time=1393.803s cost=10.515050 Momentum=0.900000 lrate=0.00007474
train performance: 99.54%
===================weight value================
conv1:
weight:-1.482667, -1.583486, -1.886879;
bias  :0.000000 0.000000
conv2:
weight:0.726822, 0.977813, 0.212473;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.530851;
bias  :0.000000
===================test Result================
test 99.05%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 22, 36, 14;
conv2:
fire count: 0, 0, 0, 0, 1, 10, 16, 13, 0, 0;
pooling2:
fire count: 0, 0, 4, 5, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 14, 0, 19, 0;
output:
fire count: 0, 0, 1, 1, 0, 1, 37, 0, 1, 1;
epoch=179 time=1422.049s cost=7.814100 Momentum=0.900000 lrate=0.00007454
train performance: 99.68%
===================weight value================
conv1:
weight:-1.517706, -1.608883, -1.914859;
bias  :0.000000 0.000000
conv2:
weight:0.735178, 0.993827, 0.225490;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.544860;
bias  :0.000000
===================test Result================
test 99.28%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 20, 34, 14;
conv2:
fire count: 0, 0, 0, 0, 0, 8, 15, 13, 0, 0;
pooling2:
fire count: 0, 0, 3, 5, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 16, 0, 20, 0;
output:
fire count: 0, 0, 1, 1, 0, 0, 36, 0, 1, 1;
epoch=180 time=1385.415s cost=7.860250 Momentum=0.900000 lrate=0.00007433
train performance: 99.68%
===================weight value================
conv1:
weight:-1.526288, -1.594308, -1.913299;
bias  :0.000000 0.000000
conv2:
weight:0.758942, 1.007496, 0.220892;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.549581;
bias  :0.000000
===================test Result================
test 99.16%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 20, 34, 15;
conv2:
fire count: 0, 0, 0, 0, 1, 9, 15, 13, 0, 0;
pooling2:
fire count: 0, 0, 3, 5, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 13, 0, 24, 0;
output:
fire count: 0, 0, 1, 0, 0, 1, 36, 0, 1, 1;
epoch=181 time=1414.644s cost=10.536867 Momentum=0.900000 lrate=0.00007412
train performance: 99.54%
===================weight value================
conv1:
weight:-1.561771, -1.609438, -1.907484;
bias  :0.000000 0.000000
conv2:
weight:0.797135, 1.065210, 0.286931;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.549581;
bias  :0.000000
===================test Result================
test 99.25%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 22, 37, 16;
conv2:
fire count: 0, 0, 0, 0, 4, 13, 18, 15, 0, 0;
pooling2:
fire count: 0, 0, 6, 8, 0, 0, 1, 1, 0, 1;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 15, 0, 27, 0;
output:
fire count: 0, 0, 1, 0, 0, 1, 36, 0, 1, 1;
epoch=182 time=1384.907s cost=8.994333 Momentum=0.900000 lrate=0.00007392
train performance: 99.61%
===================weight value================
conv1:
weight:-1.572960, -1.606177, -1.915744;
bias  :0.000000 0.000000
conv2:
weight:0.805009, 1.058248, 0.276423;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.547233;
bias  :0.000000
===================test Result================
test 99.21%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 21, 34, 14;
conv2:
fire count: 0, 0, 0, 0, 3, 10, 16, 14, 0, 0;
pooling2:
fire count: 0, 0, 5, 7, 0, 0, 0, 0, 0, 0;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 11, 0, 21, 0;
output:
fire count: 0, 0, 2, 0, 0, 1, 34, 0, 1, 1;
epoch=183 time=1375.322s cost=15.652634 Momentum=0.900000 lrate=0.00007372
train performance: 99.27%
===================weight value================
conv1:
weight:-1.595133, -1.619243, -1.892311;
bias  :0.000000 0.000000
conv2:
weight:0.834496, 1.082706, 0.277750;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.547233;
bias  :0.000000
===================test Result================
test 98.96%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 1, 24, 39, 16;
conv2:
fire count: 0, 0, 0, 0, 3, 10, 17, 15, 0, 0;
pooling2:
fire count: 0, 0, 5, 7, 0, 0, 0, 1, 0, 1;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 15, 0, 18, 0;
output:
fire count: 0, 0, 1, 0, 0, 1, 33, 0, 1, 1;
epoch=184 time=1426.096s cost=13.862600 Momentum=0.900000 lrate=0.00007352
train performance: 99.39%
===================weight value================
conv1:
weight:-1.617027, -1.603037, -1.903922;
bias  :0.000000 0.000000
conv2:
weight:0.859764, 1.103334, 0.309203;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.556747;
bias  :0.000000
===================test Result================
test 99.18%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 21, 36, 16;
conv2:
fire count: 0, 0, 0, 0, 6, 14, 21, 18, 0, 0;
pooling2:
fire count: 0, 0, 8, 9, 0, 0, 3, 1, 0, 2;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 9, 0, 24, 0;
output:
fire count: 0, 0, 1, 1, 0, 1, 34, 0, 1, 0;
epoch=185 time=1366.983s cost=17.250517 Momentum=0.900000 lrate=0.00007332
train performance: 99.22%
===================weight value================
conv1:
weight:-1.651181, -1.622987, -1.869800;
bias  :0.000000 0.000000
conv2:
weight:0.825674, 1.059118, 0.270081;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.559075;
bias  :0.000000
===================test Result================
test 99.00%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 1, 25, 39, 17;
conv2:
fire count: 0, 0, 0, 0, 5, 12, 18, 15, 0, 0;
pooling2:
fire count: 0, 0, 7, 7, 0, 0, 1, 0, 0, 2;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 13, 0, 16, 0;
output:
fire count: 0, 0, 1, 0, 0, 1, 35, 0, 1, 1;
epoch=186 time=1456.488s cost=18.024384 Momentum=0.900000 lrate=0.00007313
train performance: 99.14%
===================weight value================
conv1:
weight:-1.684408, -1.612658, -1.833079;
bias  :0.000000 0.000000
conv2:
weight:0.838321, 1.059983, 0.264538;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.568268;
bias  :0.000000
===================test Result================
test 98.79%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 3, 27, 41, 18;
conv2:
fire count: 0, 0, 0, 0, 9, 14, 21, 17, 0, 0;
pooling2:
fire count: 0, 0, 9, 9, 0, 1, 3, 2, 0, 3;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 8, 0, 21, 0;
output:
fire count: 0, 0, 1, 1, 0, 2, 31, 0, 1, 1;
epoch=187 time=1473.348s cost=12.274016 Momentum=0.900000 lrate=0.00007293
train performance: 99.43%
===================weight value================
conv1:
weight:-1.662190, -1.616442, -1.881677;
bias  :0.000000 0.000000
conv2:
weight:0.830435, 1.061477, 0.265503;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.580937;
bias  :0.000000
===================test Result================
test 99.08%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 1, 24, 38, 17;
conv2:
fire count: 0, 0, 0, 0, 7, 15, 21, 17, 0, 0;
pooling2:
fire count: 0, 0, 10, 8, 0, 0, 3, 2, 0, 3;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 17, 0, 24, 0;
output:
fire count: 0, 0, 2, 1, 0, 0, 33, 0, 1, 1;
epoch=188 time=1412.825s cost=11.295116 Momentum=0.900000 lrate=0.00007274
train performance: 99.52%
===================weight value================
conv1:
weight:-1.694413, -1.644092, -1.890320;
bias  :0.000000 0.000000
conv2:
weight:0.849090, 1.106999, 0.288767;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.583247;
bias  :0.000000
===================test Result================
test 99.24%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 2, 26, 39, 18;
conv2:
fire count: 0, 0, 0, 0, 8, 15, 21, 18, 0, 0;
pooling2:
fire count: 0, 0, 10, 10, 0, 1, 4, 2, 1, 3;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 18, 0, 21, 0;
output:
fire count: 0, 0, 2, 0, 0, 1, 36, 0, 1, 1;
epoch=189 time=1442.365s cost=13.637667 Momentum=0.900000 lrate=0.00007255
train performance: 99.38%
===================weight value================
conv1:
weight:-1.713373, -1.638897, -1.868933;
bias  :0.000000 0.000000
conv2:
weight:0.858793, 1.127609, 0.293561;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.580943;
bias  :0.000000
===================test Result================
test 98.94%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 2, 26, 38, 16;
conv2:
fire count: 0, 0, 0, 0, 6, 14, 21, 17, 0, 0;
pooling2:
fire count: 0, 0, 9, 9, 0, 0, 3, 2, 0, 3;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 11, 0, 17, 0;
output:
fire count: 0, 0, 1, 1, 0, 1, 31, 0, 1, 1;
epoch=190 time=1506.001s cost=12.908400 Momentum=0.900000 lrate=0.00007236
train performance: 99.47%
===================weight value================
conv1:
weight:-1.728005, -1.597624, -1.850715;
bias  :0.000000 0.000000
conv2:
weight:0.892590, 1.161948, 0.341365;
bias  :0.000000 0.000000
hidden_0:
weight:0.000001, 0.000000, 0.000020;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.583241;
bias  :0.000000
===================test Result================
test 99.16%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 1, 21, 35, 15;
conv2:
fire count: 0, 0, 0, 0, 7, 15, 23, 19, 0, 0;
pooling2:
fire count: 0, 0, 10, 11, 0, 2, 5, 4, 1, 3;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 15, 0, 19, 0;
output:
fire count: 0, 0, 2, 0, 0, 0, 36, 0, 1, 0;
epoch=191 time=1510.375s cost=9.645634 Momentum=0.900000 lrate=0.00007217
train performance: 99.59%
===================weight value================
conv1:
weight:-1.741538, -1.581892, -1.826295;
bias  :0.000000 0.000000
conv2:
weight:0.902289, 1.150910, 0.318703;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.590118;
bias  :0.000000
===================test Result================
test 99.19%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 1, 24, 37, 16;
conv2:
fire count: 0, 0, 0, 0, 8, 16, 22, 18, 0, 0;
pooling2:
fire count: 0, 0, 11, 10, 0, 1, 5, 4, 1, 3;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 12, 0, 18, 0;
output:
fire count: 0, 1, 2, 1, 0, 0, 32, 0, 1, 0;
epoch=192 time=1542.914s cost=7.446466 Momentum=0.900000 lrate=0.00007198
train performance: 99.68%
===================weight value================
conv1:
weight:-1.741503, -1.571104, -1.815856;
bias  :0.000000 0.000000
conv2:
weight:0.922811, 1.154714, 0.313126;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.594686;
bias  :0.000000
===================test Result================
test 99.26%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 1, 23, 37, 15;
conv2:
fire count: 0, 0, 0, 0, 7, 16, 22, 19, 0, 0;
pooling2:
fire count: 0, 0, 10, 11, 0, 2, 5, 5, 1, 3;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 10, 0, 15, 0;
output:
fire count: 0, 0, 2, 1, 0, 0, 33, 0, 1, 1;
epoch=193 time=1535.246s cost=17.002899 Momentum=0.900000 lrate=0.00007180
train performance: 99.18%
===================weight value================
conv1:
weight:-1.745705, -1.606277, -1.873251;
bias  :0.000000 0.000000
conv2:
weight:0.922088, 1.142624, 0.315772;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.599246;
bias  :0.000000
===================test Result================
test 98.69%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 16, 28, 10;
conv2:
fire count: 0, 0, 0, 0, 5, 12, 19, 16, 0, 0;
pooling2:
fire count: 0, 0, 8, 9, 0, 1, 4, 4, 1, 2;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 21, 0, 16, 0;
output:
fire count: 0, 0, 2, 1, 0, 0, 35, 0, 1, 0;
epoch=194 time=1495.876s cost=7.906050 Momentum=0.900000 lrate=0.00007161
train performance: 99.67%
===================weight value================
conv1:
weight:-1.760518, -1.618932, -1.861366;
bias  :0.000000 0.000000
conv2:
weight:0.919210, 1.151851, 0.316491;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.601521;
bias  :0.000000
===================test Result================
test 99.16%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 18, 31, 11;
conv2:
fire count: 0, 0, 0, 0, 5, 14, 20, 18, 0, 0;
pooling2:
fire count: 0, 0, 9, 10, 0, 1, 5, 3, 1, 2;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 14, 0, 18, 0;
output:
fire count: 0, 0, 2, 1, 0, 0, 32, 0, 1, 0;
epoch=195 time=1446.822s cost=9.692284 Momentum=0.900000 lrate=0.00007143
train performance: 99.60%
===================weight value================
conv1:
weight:-1.759172, -1.634444, -1.877448;
bias  :0.000000 0.000000
conv2:
weight:0.889546, 1.118820, 0.316161;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.603790;
bias  :0.000000
===================test Result================
test 99.13%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 18, 31, 11;
conv2:
fire count: 0, 0, 0, 0, 5, 14, 21, 18, 0, 0;
pooling2:
fire count: 0, 0, 9, 11, 0, 1, 5, 3, 1, 3;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 13, 0, 14, 0;
output:
fire count: 0, 0, 2, 0, 0, 1, 35, 0, 1, 0;
epoch=196 time=1476.985s cost=10.456166 Momentum=0.900000 lrate=0.00007125
train performance: 99.53%
===================weight value================
conv1:
weight:-1.728348, -1.598972, -1.878538;
bias  :0.000000 0.000000
conv2:
weight:0.906557, 1.113028, 0.291001;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.608315;
bias  :0.000000
===================test Result================
test 99.11%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 17, 30, 11;
conv2:
fire count: 0, 0, 0, 0, 4, 12, 19, 16, 0, 0;
pooling2:
fire count: 0, 0, 8, 8, 0, 0, 3, 3, 0, 2;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 12, 0, 16, 0;
output:
fire count: 0, 0, 2, 1, 0, 0, 36, 0, 1, 1;
epoch=197 time=1449.738s cost=13.213767 Momentum=0.900000 lrate=0.00007107
train performance: 99.38%
===================weight value================
conv1:
weight:-1.746518, -1.582838, -1.878509;
bias  :0.000000 0.000000
conv2:
weight:0.938327, 1.155919, 0.336968;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.608315;
bias  :0.000000
===================test Result================
test 98.71%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 12, 25, 9;
conv2:
fire count: 0, 0, 0, 0, 4, 12, 19, 16, 0, 0;
pooling2:
fire count: 0, 0, 8, 9, 0, 1, 4, 3, 0, 1;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 12, 0, 20, 0;
output:
fire count: 0, 0, 3, 1, 1, 0, 32, 0, 1, 0;
epoch=198 time=1454.244s cost=9.276300 Momentum=0.900000 lrate=0.00007089
train performance: 99.59%
===================weight value================
conv1:
weight:-1.766537, -1.570734, -1.851944;
bias  :0.000000 0.000000
conv2:
weight:0.932943, 1.175509, 0.393936;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.610566;
bias  :0.000000
===================test Result================
test 99.22%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 19, 32, 13;
conv2:
fire count: 0, 0, 0, 0, 8, 16, 22, 19, 0, 0;
pooling2:
fire count: 0, 0, 11, 11, 0, 2, 4, 4, 1, 3;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 12, 0, 25, 0;
output:
fire count: 0, 0, 1, 0, 1, 0, 37, 0, 1, 0;
epoch=199 time=1455.260s cost=12.497500 Momentum=0.900000 lrate=0.00007071
train performance: 99.45%
===================weight value================
conv1:
weight:-1.783075, -1.575245, -1.838051;
bias  :0.000000 0.000000
conv2:
weight:0.887451, 1.151151, 0.370675;
bias  :0.000000 0.000000
hidden_0:
weight:0.000000, 0.000000, 0.000000;
bias  :0.000000
output:
weight:-0.919886, -0.695483, -1.615041;
bias  :0.000000
===================test Result================
test 99.31%/99.45%
===================output fire counts================
The last sample label: 6
conv1:
fire count: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0;
pooling1:
fire count: 0, 0, 0, 0, 0, 0, 0, 19, 33, 13;
conv2:
fire count: 0, 0, 0, 0, 6, 14, 21, 17, 0, 0;
pooling2:
fire count: 0, 0, 9, 10, 0, 1, 4, 4, 1, 4;
hidden_0:
fire count: 0, 0, 0, 0, 0, 0, 6, 0, 13, 0;
output:
fire count: 0, 0, 1, 0, 1, 0, 36, 0, 1, 1;
training time hours = 77.468849
