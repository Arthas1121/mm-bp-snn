#Comment#
#NON_LINEARITY = NL_SIGMOID , NL_TANH , NL_RELU#
IS_GRADIENT_CHECKING = false;   #is true when debug#
BOOST_METHOD = true;            #allow boost weight train#
EFFECT_RATIO = true;            #use e^k_{i|j}/o^{k-1}_j for estimate the grad of syn effect#
                                #need to set batch = 1 in this case#
OPTIMIZER = adam;               # use adam as the optimizer , by default is sgd with momentum #


SHOWIMAGE = false;              #show the images after transformation#
TEST_EPOCH = 100;                 #the period to get the test dataset's error rate#
WHITE_NOISE = 0.0;  
LAMBDA_REG  = 10;               # param for weight regularization #
BETA_REG    = 0.04;               

WEIGHT_LIMIT= 8.0;


BATCH_SIZE = 1;                
CHANNELS = 1;                   #1, 3, 4#
END_TIME =  800;                 #The spike train duration#


TRAIN_SAMPLES = 4142;              # number of train/test samples#
TEST_SAMPLES = 3317;
TRAIN_DATA_PATH = speech/ti_alpha/train/;  # train and test path for the speech samples #
TEST_DATA_PATH = speech/ti_alpha/test/;    

[
LAYER = DATASPIKING;
NAME  = data;
NUM_NEURONS = 83;
]


[
LAYER = SPIKING;
NAME  = hidden_0;
NUM_NEURONS = 400;
INPUT = data;
VTH = 10;
T_REFRAC = 2;
TAU_M = 64;
TAU_S = 8;
initW = 1;
initType = Bernoulli;
]

[
LAYER = SPIKING;
NAME  = hidden_1;
NUM_NEURONS = 400;
INPUT = hidden_0;
VTH = 10;
T_REFRAC = 2;
TAU_M = 64;
TAU_S = 8;
initW = 1;
initType = Bernoulli;
]

[
LAYER = SPIKING;
NUM_CLASSES = 26;
NAME  = output;
NUM_NEURONS = 26;
INPUT = hidden_1;
VTH = 5;
T_REFRAC = 2;
TAU_M = 64;
TAU_S = 8;
initW = 1;
initType = Bernoulli;
laterialType = LOCAL_INHIBITION;
localInbStrength = 1;
DESIRED_LEVEL = 35;
UNDESIRED_LEVEL = 5;
MARGIN = 5;
]
